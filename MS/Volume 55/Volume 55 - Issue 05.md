# Volume 55, Issue 5
- May 2009
- Pages iv-873
- David Simchi-Levi

## 1. Management Insights
### Author(s):
### Published:
- 1 May 2009
### Abstract:
None
### Link:
- https://doi.org/10.1287/mnsc.1090.1039

## 2. Blockbuster Culture's Next Rise or Fall: The Impact of Recommender Systems on Sales Diversity
### Author(s):
- Daniel Fleder
- Kartik Hosanagar
### Published:
- 6 Mar 2009
### Abstract:
This paper examines the effect of recommender systems on the diversity of sales. Two anecdotal views exist about such effects. Some believe recommenders help consumers discover new products and thus increase sales diversity. Others believe recommenders only reinforce the popularity of already-popular products. This paper seeks to reconcile these seemingly incompatible views. We explore the question in two ways. First, modeling recommender systems analytically allows us to explore their path-dependent effects. Second, turning to simulation, we increase the realism of our results by combining choice models with actual implementations of recommender systems. We arrive at three main results. First, some well-known recommenders can lead to a reduction in sales diversity. Because common recommenders (e.g., collaborative filters) recommend products based on sales and ratings, they cannot recommend products with limited historical data, even if they would be rated favorably. In turn, these recommenders can create a rich-get-richer effect for popular products and vice versa for unpopular ones. This bias toward popularity can prevent what may otherwise be better consumer-product matches. That diversity can decrease is surprising to consumers who express that recommendations have helped them discover new products. In line with this, result two shows that it is possible for individual-level diversity to increase but aggregate diversity to decrease. Recommenders can push each person to new products, but they often push users toward the same products. Third, we show how basic design choices affect the outcome, and thus managers can choose recommender designs that are more consistent with their sales goals and consumers' preferences.
### Link:
- https://doi.org/10.1287/mnsc.1080.0974

## 3. On the Value of Commitment and Availability Guarantees When Selling to Strategic Consumers
### Author(s):
- Xuanming Su
- Fuqiang Zhang
### Published:
- 6 Mar 2009
### Abstract:
This paper studies the role of product availability in attracting consumer demand. We start with a newsvendor model, but additionally assume that stockouts are costly to consumers. The seller sets an observable price and an unobservable stocking quantity. Consumers anticipate the likelihood of stockouts and determine whether to visit the seller. We characterize the rational expectations equilibrium in this game. We propose two strategies that the seller can use to improve profits: (i) commitment (i.e., the seller, ex ante, commits to a particular quantity) and (ii) availability guarantees (i.e., the seller promises to compensate consumers, ex post, if the product is out of stock). Interestingly, the seller has an incentive to overcompensate consumers during stockouts, relative to the first-best benchmark under which social welfare is maximized. We find that first-best outcomes do not arise in equilibrium, but can be supported when the seller uses a combination of commitment and availability guarantees. Finally, we examine the robustness of these conclusions by extending our analysis to incorporate dynamic learning, multiple products, and consumer heterogeneity.
### Link:
- https://doi.org/10.1287/mnsc.1080.0991

## 4. An Optimal Contact Model for Maximizing Online Panel Response Rates
### Author(s):
- Scott A. Neslin
- Thomas P. Novak
- Kenneth R. Baker
- Donna L. Hoffman
### Published:
- 12 Feb 2009
### Abstract:
We develop and test an optimization model for maximizing response rates for online marketing research survey panels. The model consists of (1) a decision tree predictive model that classifies panelists into states and forecasts the response rate for panelists in each state and (2) a linear program that specifies how many panelists should be solicited from each state to maximize response rate. The model is forward looking in that it optimizes over a finite horizon during which S studies are to be fielded. It takes into account the desired number of responses for each study, the likely migration pattern of panelists between states as they are invited and respond or do not respond, as well as demographic requirements. The model is implemented using a rolling horizon whereby the optimal solution for S successive studies is derived and implemented for the first study. Then, as results are observed, an optimal solution is derived for the next S studies, and the solution is implemented for the first of these studies, etc. The procedure is field tested and shown to increase response rates significantly compared to the heuristic currently being used by panel management. Further analysis suggests that the improvement was due to the predictive model and that a greedy algorithm would have done equally well in the field test. However, further Monte Carlo simulations suggest circumstances under which the model would outperform the greedy algorithm.
### Link:
- https://doi.org/10.1287/mnsc.1080.0969

## 5. Contagion of Wishful Thinking in Markets
### Author(s):
- Nicholas Seybert
- Robert Bloomfield
### Published:
- 12 Feb 2009
### Abstract:
Prior research provides only weak and controversial evidence that people overestimate the likelihood of desirable events (wishful thinking), but strong evidence that people bet more heavily on those events (wishful betting). Two experiments show that wishful betting contaminates beliefs in laboratory financial markets because wishful betters appear to possess more favorable information than they actually do. As a consequence, market interaction exacerbates rather than mitigates wishful thinking. This phenomenon, contagion of wishful thinking, could be problematic in many settings where people infer others' beliefs from their behavior.
### Link:
- https://doi.org/10.1287/mnsc.1080.0973

## 6. Quasi-Robust Multiagent Contracts
### Author(s):
- Anil Arya
- Joel Demski
- Jonathan Glover
- Pierre Liang
### Published:
- 12 Feb 2009
### Abstract:
A criticism of mechanism design theory is that the optimal mechanism designed for one environment can produce drastically different actions, outcomes, and payoffs in a second, even slightly different, environment. In this sense, the theoretically optimal mechanisms usually studied are not robust. To study robust mechanisms while maintaining an expected utility maximization approach, we study a multiagent model in which the mechanism must be designed before the environment is as well understood as is usually assumed. The particular model is of an auction setting with binary private values. Our main result is that if the prior belief about the correlation in the agents' values is diffuse enough, the optimal Bayesian-Nash auction must also satisfy dominant strategy incentive constraints. Furthermore, when the optimal auction does provide dominant strategy incentives, it takes one of two forms: (i) if perfect correlation and negative correlation are excluded as possibilities, the auction incorporates all information about the prior belief over the possible correlations, and (ii) if either perfect correlation or negative correlation is a possibility, the auction does not incorporate any correlation information and can be described as a modified Vickrey auction.
### Link:
- https://doi.org/10.1287/mnsc.1080.0967

## 7. Multiple Sourcing and Procurement Process Selection with Bidding Events
### Author(s):
- Tunay I. Tunca
- Qiong Wu
### Published:
- 19 Feb 2009
### Abstract:
We examine the procurement process selection problem of a large industrial buyer who employs reverse auctions for awarding procurement contracts. We contrast two classes of commonly used strategies under multiple sourcing; namely, single-stage reverse auctions, and two-stage processes where price-quantity adjustments between the buyer and the suppliers follow a first-stage reverse auction. Deriving bounds of efficiency for these two classes of procurement processes under convex supplier production costs, we present insights on the conditions under which each class is preferable for the buyer. Considering the effect of contracting and processing costs, a single-stage process is likely to be preferable to a two-stage process when the number of bidding suppliers is high, especially when capacity is rigid. A two-stage process with one information transfer in the second stage may be the preferred procurement mode when production is highly scalable, i.e., when the marginal production cost increase with increased production is small. When the number of suppliers is low, the effect of a decrease in production scalability depends on the current scalability level. For high scalability levels, a decrease in production scalability may decrease the efficiency of both single-stage and simple two-stage processes, whereas for low scalability levels, it tends to increase efficiency for both of these process classes. A decrease in production costs makes employing simple processes more attractive when production is highly scalable or when supplier capacity is rigid. For intermediate production scalability, however, a cost decrease may make employing two-stage processes with multiple information transfers in the second round preferable for the buyer.
### Link:
- https://doi.org/10.1287/mnsc.1080.0972

## 8. Information Sharing and Order Variability Control Under a Generalized Demand Model
### Author(s):
- Li Chen
- Hau L. Lee
### Published:
- 19 Feb 2009
### Abstract:
The value of information sharing and how it could address the bullwhip effect have been the subject of studies in the literature. Most of these studies used different forms of demand models, assuming that no order smoothing was used by the retailer and that the supplier has full knowledge of the retailer's demand model and order policy. In this paper, we contribute to the literature by starting with a most general demand model, coupled with a smoothing policy for order variability control. In addition, we do not require that the supplier has full knowledge of the retailer's demand model and order policy, but instead let the retailer share its projected future orders (and freely revise them as the retailer sees fit). Under such a setting, we first obtain a unifying formula for the magnitude of the bullwhip effect. The formula indicates that it is the forecast correlation over the exposure period as a whole that determines the magnitude of the bullwhip effect. We then quantify the value of information sharing and generalize the existing results in the literature. Finally, we explore the optimal smoothing parameters that could benefit the total supply chain. The resulting optimal policy resembles the postponement strategy. We find that information sharing together with order postponement improves the supply chain performance, even though the order variability may amplify in some cases.
### Link:
- https://doi.org/10.1287/mnsc.1080.0983

## 9. A Generalized Approach to Portfolio Optimization: Improving Performance by Constraining Portfolio Norms
### Author(s):
- Victor DeMiguel
- Lorenzo Garlappi
- Francisco J. Nogales
- Raman Uppal
### Published:
- 6 Mar 2009
### Abstract:
We provide a general framework for finding portfolios that perform well out-of-sample in the presence of estimation error. This framework relies on solving the traditional minimum-variance problem but subject to the additional constraint that the norm of the portfolio-weight vector be smaller than a given threshold. We show that our framework nests as special cases the shrinkage approaches of Jagannathan and Ma (Jagannathan, R., T. Ma. 2003. Risk reduction in large portfolios: Why imposing the wrong constraints helps. J. Finance58 16511684) and Ledoit and Wolf (Ledoit, O., M. Wolf. 2003. Improved estimation of the covariance matrix of stock returns with an application to portfolio selection. J. Empirical Finance10 603621, and Ledoit, O., M. Wolf. 2004. A well-conditioned estimator for large-dimensional covariance matrices. J. Multivariate Anal.88 365411) and the 1/N portfolio studied in DeMiguel et al. (DeMiguel, V., L. Garlappi, R. Uppal. 2009. Optimal versus naive diversification: How inefficient is the 1/N portfolio strategy? Rev. Financial Stud.22 19151953). We also use our framework to propose several new portfolio strategies. For the proposed portfolios, we provide a moment-shrinkage interpretation and a Bayesian interpretation where the investor has a prior belief on portfolio weights rather than on moments of asset returns. Finally, we compare empirically the out-of-sample performance of the new portfolios we propose to 10 strategies in the literature across five data sets. We find that the norm-constrained portfolios often have a higher Sharpe ratio than the portfolio strategies in Jagannathan and Ma (2003), Ledoit and Wolf (2003, 2004), the 1/N portfolio, and other strategies in the literature, such as factor portfolios.
### Link:
- https://doi.org/10.1287/mnsc.1080.0986

## 10. Optimal Policies and Approximations for a Bayesian Linear Regression Inventory Model
### Author(s):
- Katy S. Azoury
- Julia Miyaoka
### Published:
- 6 Mar 2009
### Abstract:
In this paper, we consider a periodic review inventory problem where demand in each period is modeled by linear regression. We use a Bayesian formulation to update the regression parameters as new information becomes available. We find that a state-dependent base-stock policy is optimal and we give structural results. One interesting finding is that our structural results are not analogous to classical results in Bayesian inventory research. This departure from classical results is due to the role that the independent variables play in the Bayesian regression formulation. Because of the computational complexity of the optimal policy, we propose a combination of two heuristics that simplifies the Bayesian inventory problem. Through analytical and numerical evaluation, we find that the heuristics provide near-optimal results.
### Link:
- https://doi.org/10.1287/mnsc.1080.0980

## 11. Information Market-Based Decision Fusion
### Author(s):
- Johan Perols
- Kaushal Chari
- Manish Agrawal
### Published:
- 19 Feb 2009
### Abstract:
Improved classification performance has practical real-world benefits ranging from improved effectiveness in detecting diseases to increased efficiency in identifying firms that are committing financial fraud. Multiclassifier combination (MCC) aims to improve classification performance by combining the decisions of multiple individual classifiers. In this paper, we present information market-based fusion (IMF), a novel multiclassifier combiner method for decision fusion that is based on information markets. In IMF, the individual classifiers are implemented as participants in an information market where they place bets on different object classes. The reciprocals of the market odds that minimize the difference between the total betting amount and the potential payouts for different classes represent the MCC probability estimates of each class being the true object class. By using a market-based approach, IMF can adjust to changes in base-classifier performance without requiring offline training data or a static ensemble composition. Experimental results show that when the true classes of objects are only revealed for objects classified as positive, for low positive ratios, IMF outperforms three benchmarks combiner methods, majority, average, and weighted average; for high positive ratios, IMF outperforms majority and performs on par with average and weighted average. When the true classes of all objects are revealed, IMF outperforms weighted average and majority and marginally outperforms average.
### Link:
- https://doi.org/10.1287/mnsc.1080.0977

## 12. Private Network EDI vs. Internet Electronic Markets: A Direct Comparison of Fulfillment Performance
### Author(s):
- Yuliang Yao
- Martin Dresner
- Jonathan Palmer
### Published:
- 19 Feb 2009
### Abstract:
Prior literature has documented the performance benefits from the use of electronic data interchange (EDI) and the Internet. Using purchase and fulfillment records from the U.S. government's Federal Supply Service, we provide a direct comparison of performance between a private network EDI channel and an Internet electronic market. Performance is measured using order cycle time and complete orders fulfilled. Our findings show that the Internet-based electronic market outperforms the EDI-based channel on these two important measures. Order cycle times were significantly lower when using the Internet-based electronic market, whereas the percentage of complete shipments was significantly higher after controlling for product, transaction, seller, and buyer-specific factors. The electronic market even outperforms the EDI channel when buyer and transaction characteristics favor the use of EDI. Because EDI is still prevalent in many industries, these results point to the gains that may be realized by switching to the newer technology.
### Link:
- https://doi.org/10.1287/mnsc.1080.0990

## 13. Loss Functions in Option Valuation: A Framework for Selection
### Author(s):
- Dennis Bams
- Thorsten Lehnert
- Christian C. P. Wolff
### Published:
- 12 Feb 2009
### Abstract:
In this paper, we investigate the importance of different loss functions when estimating and evaluating option pricing models. Our analysis shows that it is important to take into account parameter uncertainty, because this leads to uncertainty in the predicted option price. We illustrate the effect on the out-of-sample pricing errors in an application of the ad hoc Black-Scholes model to DAX index options. We confirm the empirical results of Christoffersen and Jacobs (Christoffersen, P., K. Jacobs. 2004. The importance of the loss function in option valuation. J. Financial Econom.72 291318) and find strong evidence for their conjecture that the squared pricing error criterion may serve as a general-purpose loss function in option valuation applications. At the same time, we provide a first yardstick to evaluate the adequacy of the loss function. This is accomplished through a data-driven method to deliver not just a point estimate of the root mean squared pricing error, but a distribution.
### Link:
- https://doi.org/10.1287/mnsc.1080.0976

## 14. Additive Utility in Prospect Theory
### Author(s):
- Han Bleichrodt
- Ulrich Schmidt
- Horst Zank
### Published:
- 12 Feb 2009
### Abstract:
Prospect theory is currently the main descriptive theory of decision under uncertainty. It generalizes expected utility by introducing nonlinear decision weighting and loss aversion. A difficulty in the study of multiattribute utility under prospect theory is to determine when an attribute yields a gain or a loss. One possibility, adopted in the theoretical literature on multiattribute utility under prospect theory, is to assume that a decision maker determines whether the complete outcome is a gain or a loss. In this holistic evaluation, decision weighting and loss aversion are general and attribute-independent. Another possibility, more common in the empirical literature, is to assume that a decision maker has a reference point for each attribute. We give preference foundations for this attribute-specific evaluation where decision weighting and loss aversion are depending on the attributes.
### Link:
- https://doi.org/10.1287/mnsc.1080.0978

