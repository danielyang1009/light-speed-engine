# Volume 48, Issue 12
- December 2002
- Pages 1517-1644
- David Simchi-Levi

## 1. The Transfer of Experience in Groups of Organizations: Implications for Performance and Competition
### Author(s):
- Paul Ingram
- Tal Simons
### Published:
- 1 Dec 2002
### Abstract:
Groups of organizations are pervasive, although there is little systematic knowledge about how they affect their members. We examine one dimension of the operation of organization groups, the transfer of experience. Our core argument is that organization groups may create benefits for their members, but problems for those outside the group. Within the group they can facilitate the transfer of experience among their members by creating mechanisms for communication, incentives for helping, and by promoting understanding. The predicted pattern of experience transfer should improve performance of those within the group, but also has implications for those outside it. Experience accumulated in one organization group strengthens the competitiveness of its organizations, and thereby harms competitors outside the group. Thus, organization groups are fundamental both for the functioning of their members and the competitive dynamics of their industries. Our longitudinal analysis of the profitability of kibbutz agriculture supports both these claims. Between 1954 and 1965 (the years of this study), almost all kibbutzim were part of organization groups. Kibbutzim became more profitable as a function of the experience of others in their group. Their profitability was reduced, however, as a function of experience of others outside their group.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1517.437

## 2. Knowledge Seeking and Location Choice of Foreign Direct Investment in the United States
### Author(s):
- Wilbur Chung
- Juan Alcácer
### Published:
- 1 Dec 2002
### Abstract:
To what extent do firms go abroad to access technology available in other locations? This paper examines whether and when state technical capabilities attract foreign investment in manufacturing from 1987-1993. We find that on average state R&D intensity does not attract foreign direct investment. Most investing firms are in lower-tech industries and locate in low R&D intensity states, suggesting little interest in state technical capabilities. In contrast, we find that firms in research-intensive industries are more likely to locate in states with high R&D intensity. Foreign firms in the pharmaceutical industry value state R&D intensity the most, at a level twice that of firms in the semiconductor industry, and four times that of electronics firms. Interestingly, not only firms from technically lagging nations, but also some firms from technically leading nations are attracted to R&D intensive states. This suggests that beyond catching up, firms use knowledge-seeking investments also to source technical diversity.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1534.440

## 3. Using a Bayesian Approach to Quantify Scale Compatibility Bias
### Author(s):
- Richard M. Anderson
- Benjamin F. Hobbs
### Published:
- 1 Dec 2002
### Abstract:
This paper proposes a new analytical framework to quantify and correct for scale compatibility bias in the assessment of trade-off weights in multiattribute value analysis. The procedure is demonstrated with an application to a fisheries management problem. Trade-off judgments are elicited from a group of fisheries experts with management responsibility in the Lake Erie basin. Then we use a Bayesian method to compute posterior probability distributions of attribute weights. In computing the Bayesian weights, our measurement model assumes that the weight ratios produced by each respondent's judgments are subject to random error and an unknown scale compatibility bias. Ratios are log-transformed and analyzed by a Bayesian linear model with a noninformative prior distribution. Posterior distributions are then developed for the weights and the bias. We estimate the compatibility bias for each person and, in most cases, it is found to be large and in the predicted direction, suggesting the importance of its consideration in deriving trade-off weights. In addition, the Bayesian framework is shown to be useful for quantifying the value of additional information about multiattribute weights. Finally, a simple heuristic procedure for assessing the weights appears to be effective in eliminating the bias.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1555.444

## 4. An Improved Batch Means Procedure for Simulation Output Analysis
### Author(s):
- Natalie M. Steiger
- James R. Wilson
### Published:
- 1 Dec 2002
### Abstract:
We formulate and evaluate the Automated Simulation Analysis Procedure (ASAP), an algorithm for steady-state simulation output analysis based on the method of nonover-lapping batch means (NOBM). ASAP delivers a confidence interval for an expected response that is centered on the sample mean of a portion of a simulation-generated time series and satisfies a user-specified absolute or relative precision requirement. ASAP operates as follows: The batch size is progressively increased until either (a) the batch means pass the von Neumann test for independence, and then ASAP delivers a classical NOBM confidence interval; or (b) the batch means pass the Shapiro-Wilk test for multivariate normality, and then ASAP delivers a correlation-adjusted confidence interval. The latter adjustment is based on an inverted Cornish-Fisher expansion for the classical NOBM t-ratio, where the terms of the expansion are estimated via an autoregressive-moving average time series model of the batch means. After determining the batch size and confidence-interval type, ASAP sequentially increases the number of batches until the precision requirement is satisfied. An extensive experimental study demonstrates the performance improvements achieved by ASAP versus well-known batch means procedures, especially in confidence-interval coverage probability.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1569.438

## 5. Solving Multi-Item Lot-Sizing Problems with an MIP Solver Using Classification and Reformulation
### Author(s):
- Laurence A. Wolsey
### Published:
- 1 Dec 2002
### Abstract:
Based on research on the polyhedral structure of lot-sizing models over the last 20 years, we claim that there is a nontrivial fraction of practical lot-sizing problems that can now be solved by nonspecialists just by taking an appropriate a priori reformulation of the problem, and then feeding the resulting formulation into a commercial mixed-integer programming solver.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1587.442

## 6. Approximating Multiobjective Knapsack Problems
### Author(s):
- Thomas Erlebach
- Hans Kellerer
- Ulrich Pferschy
### Published:
- 1 Dec 2002
### Abstract:
For multiobjective optimization problems, it is meaningful to compute a set of solutions covering all possible trade-offs between the different objectives. The multiobjective knapsack problem is a generalization of the classical knapsack problem in which each item has several profit values. For this problem, efficient algorithms for computing a provably good approximation to the set of all nondominated feasible solutions, the Pareto frontier, are studied.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1603.445

## 7. Perturbing Nonnormal Confidential Attributes: The Copula Approach
### Author(s):
- Rathindra Sarathy
- Krishnamurty Muralidhar
- Rahul Parsa
### Published:
- 1 Dec 2002
### Abstract:
Protecting confidential, numerical data in databases from disclosure is an important issue both for commercial organizations as well as data-gathering and disseminating organizations (such as the Census Bureau). Prior studies have shown that perturbation methods are effective in protecting such confidential data from snoopers. Perturbation methods have to provide legitimate users with accurate (unbiased) information, and also provide adequate security against disclosure of confidential information to snoopers. For databases described by nonnormal multivariate distributions, existing perturbation methods do not provide unbiased characteristics. In this study, we develop a copula-based perturbation method capable of maintaining the marginal distribution of perturbed attributes to be the same before and after perturbation. In addition, this method also preserves the rank order correlation between the confidential and nonconfidential attributes, thereby maintaining monotonic relationships between attributes. The method proposed in this study provides a high level of protection against inferential disclosure. An investigation of the new perturbation method for simulated databases shows that the method performs effectively. The methodology presented in this study represents a signicant step toward improving the practical applicability of data perturbation methods.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1613.439

## 8. Capacity Management in Decentralized Networks
### Author(s):
- Yasushi Masuda
- Seungjin Whang
### Published:
- 1 Dec 2002
### Abstract:
Bottleneck analysis is a useful tool in capacity planning for centrally controlled network systems. However, under a decentralized network where individual users are allowed to select their own routes, straightforward application of bottleneck analysis does not necessarily yield an optimal performance. It may even hurt the system performance—an aspect of Braess's paradox. We investigate the capacity expansion problem for a decentralized system with general network topology. To this end, we first discuss the short-run problem and show that the externality pricing solves the joint problem of demand and routing control. We then study the capacity expansion/reduction problem for decentralized systems that may or may not be optimally controlled in the short run.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1628.446

## 9. Note: Optimality Conditions for an (s, S) Policy with Proportional and Lump-Sum Penalty Costs
### Author(s):
- Sila Çetinkaya
- Mahmut Parlar
### Published:
- 1 Dec 2002
### Abstract:
We consider the optimality of the (s, S) policy for a periodic-review stochastic inventory problem with two types of shortage costs. The problem may arise in a rush-order application at a bank branch where the emergency provision costs during a foreign currency stockout are represented by proportional and lump-sum penalties. Aneja and Noori (1987) analyzed this problem and presented a set of conditions for the convexity of a particular function and made a claim about the K-convexity of another function to prove the optimality of the (s, S) policy. We show that because the function that is claimed to be K-convex is actually concave over a subset of its domain, Aneja and Noori's arguments cannot be used to prove the optimality of the (s, S) policy. However, we argue that Aneja and Noori's problem is equivalent to the typical lost-sales problem, and using this equivalence, we .nd a simple convexity condition that assures the optimality of the (s, S) policy.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1635.443

## 10. Note on “Guarantees in Auctions: The Auction House as Negotiator and Managerial Decision Maker”
### Author(s):
- Eric A. Greenleaf
- Jun. Ma
- Wanhua. Qiu
- Ambar G. Rao
- Atanu R. Sinha
### Published:
- 1 Dec 2002
### Abstract:
In this note, we identify two errors in Greenleaf, Rao, and Sinha's (1993) analysis of negotiation of guarantees in auctions. This note provides a high-level but self-contained summary of the revised results. We find that, in contrast with the earlier claim, guaranteed auctions lead to greater total expected revenue than conventional auctions. The ability to bargain over guarantee values and commissions certainly benefits sellers but may hurt the profits of auction houses. We relate these results to recent events in auction markets.
### Link:
- https://doi.org/10.1287/mnsc.48.12.1640.441

