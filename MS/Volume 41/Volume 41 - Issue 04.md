# Volume 41, Issue 04
- April 1995
- Pages 561-747
- David Simchi-Levi

## 1. Bidding for Contests
### Author(s):
- Sudhindra Seshadri
### Published:
- 1 Apr 1995
### Abstract:
The procurement of product development and production services brings special strategic considerations to the buyer-seller relationship in industrial and institutional markets. Multiple sourcing, in particular dual sourcing, is a likely way of dealing with the increased risks faced by buyers. However, there is lack of dual sourcing models that analyze the selection and control process in an integrated fashion. This omission had led to apparently contradictory findings in agency and auction theory. The paper models the strategic issues for a cost containment contest between two suppliers. The suppliers are drawn from several vendors who participate in a bidding competition. The supplier with the lower final cost in the contest wins a larger share of the pooled profit fee. Propositions are derived for the optimal cost-plus contest, and comparisons are made with the common incentive contract for the integrated selection and control model. The larger the winner's share, the greater the effort. The buyer can make a credible commitment to the optimal winner's share. As the winner's share rises, however, the bid prices increase due to increased contract risk. This incentive-risk tradeoff determines (a) the optimal winner's share that minimizes expected procurement price, (b) the corresponding profit fee bid by suppliers, (c) the ensuing cost control effort, and (d) the final price for the procurement. Comparisons with the common incentive contract tell us when the cost-plus contest induces more effort, and when bidding for a contest results in a lower final procurement price.
### Link:
- https://doi.org/10.1287/mnsc.41.4.561

## 2. Principles on the Benefits of Manufacturing Process Flexibility
### Author(s):
- William C. Jordan
- Stephen C. Graves
### Published:
- 1 Apr 1995
### Abstract:
Increasing manufacturing flexibility is a key strategy for efficiently improving market responsiveness in the face of uncertain future product demand. Process flexibility results from being able to build different types of products in the same plant or production facility at the same time. In Part I of this paper, we develop several principles on the benefits of process flexibility. These principles are that 1) limited flexibility (i.e., each plant builds only a few products), configured in the right way, yields most of the benefits of total flexibility (i.e., each plant builds all products) and 2) limited flexibility has the greatest benefits when configured to chain products and plants together to the greatest extent possible. In Part II, we provide analytic support and justification for these principles. Based on a planning model for assigning production to plants, we demonstrate that, for realistic assumptions on demand uncertainty, limited flexibility configurations (i.e., how products are assigned to plants) have sales benefits that are approximately equivalent to those for total flexibility.
### Link:
- https://doi.org/10.1287/mnsc.41.4.577

## 3. Improved Implicit Optimal Modeling of the Labor Shift Scheduling Problem
### Author(s):
- Gary M. Thompson
### Published:
- 1 Apr 1995
### Abstract:
This paper presents an integer programming model for developing optimal shift schedules while allowing extensive flexibility in terms of alternative shift starting times, shift lengths, and break placement. The model combines the work of Moondra (Moondra, S. L. 1976. An L. P. model for work force scheduling for banks. J. Bank Res.7(4) 299301.) and Bechtold and Jacobs (Bechtold, S. E., L. W. Jacobs. 1990. Implicit optimal modeling of flexible break assignments in labor staffing decisions for service operations. Management Sci.36(11) 13391351.) by implicitly matching meal breaks to implicitly represented shifts. Moreover, the new model extends the work of these authors to enable the scheduling of overtime and the scheduling of rest breaks.
### Link:
- https://doi.org/10.1287/mnsc.41.4.595

## 4. Single Facility Due Date Setting with Multiple Customer Classes
### Author(s):
- Izak Duenyas
### Published:
- 1 Apr 1995
### Abstract:
We consider the interrelated problems of (1) quoting a due date to each customer arriving to a production system modeled as a single-server queue and (2) sequencing customer orders once they are in the system. We allow several different classes of customers, each with different preferences for lead time and price. We first formulate the problem of quoting due dates under the assumption that customer orders are processed on a FCFS basis. Next, we consider the case where the firm has the option to schedule orders in other than FCFS order. For this case, we develop a heuristic for quoting due dates and sequencing orders. Simulation results suggest that policies that take into account customer price and due date preferences in scheduling and quoting due dates significantly outperform due date setting policies that do not.
### Link:
- https://doi.org/10.1287/mnsc.41.4.608

## 5. Optimal Operating Policy for a Bottleneck with Random Rework
### Author(s):
- Kut C. So
- Christopher S. Tang
### Published:
- 1 Apr 1995
### Abstract:
This paper presents a model of a bottleneck facility that performs two distinct types of operations: regular and rework. Each job is subjected to a test after completing the regular operation at the bottleneck. If the job passes the test, then it continues its process downstream. Otherwise, the job will cycle back to the bottleneck stage for rework operation. Upon the completion of a batch of regular jobs, the decision maker observes the amount of rework and decides on whether to switch over to process the reworks or continue to process another batch of regular jobs. It is assumed that both switch-over time and cost are incurred when the facility switches from performing one type of operation to a different type. The goal of the analysis is to characterize the optimal operating policy for the bottleneck so that the average operating cost is minimized. In order to characterize the optimal operating policy, we first formulate the problem as a semi-Markov decision process. Then we show that there exists an optimal threshold operating policy that can be described as follows: upon completion of a batch of regular jobs, switch over to process the reworks only if the number of reworks exceeds a critical value. In addition, we develop a simple procedure to compute the critical value that specifies the optimal threshold policy. Moreover, we evaluate the impact of batch sizes, yield, and switch-over time on the optimal threshold policy.
### Link:
- https://doi.org/10.1287/mnsc.41.4.620

## 6. Bayesian Process Control for Attributes
### Author(s):
- Joel M. Calabrese
### Published:
- 1 Apr 1995
### Abstract:
We consider a process control procedure with fixed sample sizes and sampling intervals, where the fraction defective is the quality variable of interest, a standard attributes control chart methodology. We show that relatively standard cost assumptions lead to formulation of the process control problem as a partially observed Markov decision process, where the posterior probability of a process shift is a sufficient statistic for decision making. We characterize features of the optimal solution and show that the optimal policy has a simple control limit structure. Numerical results are provided which indicate that the procedure may provide significant savings over non-Bayesian techniques.
### Link:
- https://doi.org/10.1287/mnsc.41.4.637

## 7. Delay Cost and Incentive Schemes for Multiple Users
### Author(s):
- Suresh Radhakrishnan
- Kashi R. Balachandran
### Published:
- 1 Apr 1995
### Abstract:
This paper examines the role of cost application in the presence of delay and agency costs. Two risk neutral division managers share a common (production) facility and decide on (a) the demand (usage) rates, and (b) productive action. Each division manager causes costly delays at the common production facility for the other division manager. The expected delay depends on the demand rates chosen by the division managers. An M/G/1 queuing framework is used to characterize delay costs. The unobservability of demand rates leads to stochastic choice hazard, and the unobservability of productive actions leads to moral hazard problems. The headquarters designs incentive schemes such that the use of the common facility is optimal for the firm.
### Link:
- https://doi.org/10.1287/mnsc.41.4.646

## 8. Insider Trading, Earnings Changes, and Stock Prices
### Author(s):
- Steven Allen
- Ramachandran Ramanan
### Published:
- 1 Apr 1995
### Abstract:
This study empirically examines the relation between reportable insider trading and the information captured by annual unexpected earnings for a large sample of firms, spanning a ten-year period (197887). Each observation is assigned to one of four groups based on the direction of net insider trading (Buy, Sell) and the sign (+, ) of unexpected earnings. For each of these groups, 15-month cumulative abnormal returns are regressed on annual unexpected earnings. The slope coefficient is the largest for the group where insiders are net purchasers and the sign of unexpected earnings is positive. This is consistent with an inference that insider buying interactively confirms the favorable information captured by positive unexpected earnings and this interaction reduces the noise in unexpected earnings. The result with regard to the unfavorable information captured by the group with insider selling and negative unexpected earnings is similar but less pronounced. The analysis also suggests that insider trading conveys information not fully captured by the year's earnings.
### Link:
- https://doi.org/10.1287/mnsc.41.4.653

## 9. Single-Facility Resource Allocation Under Capacity-Based Economies and Diseconomies of Scope
### Author(s):
- Joseph B. Mazzola
- Robert H. Schantz
### Published:
- 1 Apr 1995
### Abstract:
We consider the optimal allocation of a resource in a single-facility production environment in the presence of capacity-based economies and diseconomies of scope. This setting generalizes the usual approach to single-facility resource allocation by allowing for the effective capacity of a facility to be a (nonlinear) function of the number of different items produced or the services delivered by the facility. Economies or diseconomies of scope are attributable to factors such as production changeover time, overall process management requirements, and complementary production requirements that vary with the product or service mix. We consider the problem setting in which the effective capacity depends on the number of tasks assigned to the facility. The resulting model (SCOPE) generalizes the well-known 01 knapsack problem. We also consider the more general problem (GENCAP) in which capacity consumption depends on the specific set of tasks assigned to the facility. We define tabu-search heuristics, as well as exact branch-and-bound algorithms for SCOPE and GENCAP. On the basis of extensive computational experience, the solution procedures are seen to be extremely effective. In particular, the heuristics consistently obtain high-quality solutions to the test problems. Furthermore, the tractability of solving problems to optimality is demonstrated through the solution of SCOPE problems having as many as 500 tasks and GENCAP problems involving as many as 50 tasks and more than 16,500 nonlinear capacity interactions.
### Link:
- https://doi.org/10.1287/mnsc.41.4.669

## 10. Performance Analysis of a Multi-Item Production-Inventory System Under Alternative Policies
### Author(s):
- Paul H. Zipkin
### Published:
- 1 Apr 1995
### Abstract:
This paper explores the performance of a multi-item production-inventory system. We compare two alternative policies, representing different modes of collecting and utilizing information. We derive a closed-form measure of performance for one of them, the familiar first-come-first-served (FCFS) policy, and propose a comparable approximation for the other, the longest-queue (LQ) policy. These results are illustrated and tested through simulations. In this way we address several basic managerial issues: What is the value of centralized information in complex systems? How does the breadth of the product line affect performance?
### Link:
- https://doi.org/10.1287/mnsc.41.4.690

## 11. A Decomposition Method for Quadratic Zero-One Programming
### Author(s):
- Pierre Chardaire
- Alain Sutter
### Published:
- 1 Apr 1995
### Abstract:
This paper proposes a decomposition method to compute a lower bound for unconstrained quadratic zero-one minimization. First, we show that any quadratic function can be expressed as a sum of particular quadratic functions whose minima can be computed by a simple branch and bound algorithm. Then, assuming some hypothesis, we prove that, among all possible decompositions, the best one can be found by a Lagrangian decomposition method. Moreover, we show that our algorithm gives at least the roof dual bound and should give better results in practice. Eventually, computational results and comparison with Pardalos and Rodgers' algorithm demonstrate the efficiency of our method for medium size problems (up to 100 variables).
### Link:
- https://doi.org/10.1287/mnsc.41.4.704

## 12. Lower Bounds for the Hub Location Problem
### Author(s):
- Morton O'Kelly
- Darko Skorin-Kapov
- Jadranka Skorin-Kapov
### Published:
- 1 Apr 1995
### Abstract:
We present a new lower bound for the Hub Location Problem (HLP) where distances satisfy the triangle inequality. Our lower bound is based on a linearization of the problem and its modification obtained by incorporating the knowledge of a known heuristic solution. A lower bound was computed for some standard data sets from the literature ranging between 10 and 25 nodes, with 2, 3, and 4 hubs, and for different values for the parameter , representing the discount for the flow between hubs. The novel approach of using a known heuristic solution to derive a lower bound in all cases reduced the difference between the upper and lower bound. This difference measures the quality of the best known heuristic solution in percentages above the best lower bound. As a result of this research, for smaller problems (all instances with 10 and 15 nodes) the average difference is reduced to 3.3%. For larger sets (20 and 25 nodes) the average difference is reduced to 5.9%.
### Link:
- https://doi.org/10.1287/mnsc.41.4.713

## 13. Quadratic-Variation-Based Dynamic Strategies
### Author(s):
- Avi Bick
### Published:
- 1 Apr 1995
### Abstract:
The paper analyzes a family of dynamic trading strategies which do not rely on any stochastic process assumptions (aside from continuity and positivity) and in particular do not require predicting future volatilities. Derivative payoffs can still be replicated, except that this occurs at the stopping time at which the realized cumulative squared volatility hits a predetermined level. The application of these results to portfolio insurance is emphasized, and hedging strategies studied by Black and Jones and by Brennan and Schwartz are generalized. Classical results on European-style options arise as special cases. For example, the initial cost of replicating a call or a put under the new method is given by a generalized Black-Scholes formula, which yields the ordinary Black-Scholes formula when the volatility is derterministic.
### Link:
- https://doi.org/10.1287/mnsc.41.4.722

## 14. Note: On the Value of Function Evaluation Location Information in Monte Carlo Simulation
### Author(s):
- Thomas J. DiCiccio
- Peter W. Glynn
### Published:
- 1 Apr 1995
### Abstract:
The point estimator used in naive Monte Carlo sampling weights all the computed function evaluations equally, and it does not take into account the precise locations at which the function evaluations are made. In this note, we consider one-dimensional integration problems in which the integrand is twice continuously differentiable. It is shown that if the weights are suitably modified to reflect the location information present in the sample, then the convergence rate of the Monte Carlo estimator can be dramatically improved from order n1/2 to order n2, where n is the number of function evaluations computed.
### Link:
- https://doi.org/10.1287/mnsc.41.4.733

## 15. Note: On the Interchange of Derivative and Expectation for Likelihood Ratio Derivative Estimators
### Author(s):
- Pierre L'Ecuyer
### Published:
- 1 Apr 1995
### Abstract:
Sufficient conditions for the validity of interchange between derivative and expectation, in the context of likelihood ratio gradient estimation, were given in L'Ecuyer (1990). The aim of this paper is to shed additional light on these conditions and introduce specific variants of them, which are often easier to check. Sufficient conditions for the derivative estimator to have finite moments up to a given order are also given and illustrated by examples. In particular, we give an example of an unbiased derivative estimator which satisfies the interchange conditions but which has infinite variance.
### Link:
- https://doi.org/10.1287/mnsc.41.4.738

