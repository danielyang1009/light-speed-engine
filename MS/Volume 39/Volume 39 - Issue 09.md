# Volume 39, Issue 09
- September 1993
- Pages 1039-1178
- David Simchi-Levi

## 1. Internal Pricing and Cost Allocation in a Model of Multiproduct Competition with Finite Capacity Increments
### Author(s):
- Uday Karmarkar
- Richard Pitbladdo
### Published:
- 1 Sep 1993
### Abstract:
Internal prices are used in practice to allocate central resources to a firms' profit centers. The fixed costs of capacity acquisitions are often included in these prices. We examine the interaction between capacity acquisition and competition when capacity is available in fixed increments. We find predictably that if the increments are small, unit capacity cost is a good approximation for the internal price, and if the increments are large, the internal price is zero. However, the relationship between the internal price and the capacity increment for intermediate cases is quite irregular, to the extent that it is not possible to approximate the internal price with accounting data. The analysis also suggests that full cost allocation overcharges for the opportunity cost of capacity. Furthermore, the right internal price does not act either as a way of recovering fixed costs or as a proxy for externalities such as congestion costs. The conclusions are not materially altered in the case where variable costs increase at the margin, and where these costs rather than hard capacity constraints are the reason to restrict output.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1039

## 2. Greenfield vs. Acquisition: The Strategy of Japanese Investors in the United States
### Author(s):
- Jean-Franois Hennart
- Young-Ryeol Park
### Published:
- 1 Sep 1993
### Abstract:
Multinational firms can enter a foreign market by taking over existing local firms (acquisitions) or by setting up new ventures (greenfield investments). Surprisingly, there has been limited empirical work on this topic. This paper examines the determinants of this choice by looking at Japanese entries into the United States. By focusing on firms of one country entering a single market, we are able to separate the impact of a firm's strategy from that of the characteristics of the target industry or country.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1054

## 3. The Identification of Solution Ideas During Organizational Decision Making
### Author(s):
- Paul C. Nutt
### Published:
- 1 Sep 1993
### Abstract:
This research investigated the idea development stage of a strategic decision making process. The tactics that decision makers apply to identify ideas were uncovered from a systematic study of 168 decision cases. These tactics and contextual factors describing the decision situation were analyzed to determine how each influences success measured by decision merit, development time, initial adoption, and sustained adoption. A synthesized template which integrated useful practices and procedures from several sources had the most success, but this tactic was seldom used. A cyclical search in which repeated searches were carried out to learn about opportunities was quite successful when used under conditions of low importance, low urgency, and good staff support. The success of the design tactic, which calls for innovation, improved when urgency was present and multiple alternatives were sought. The idea tactic which imposed a fully developed solution was widely used and seldom successful.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1071

## 4. Better Estimation of PERT Activity Time Parameters
### Author(s):
- Donald L. Keefer
- William A. Verdini
### Published:
- 1 Sep 1993
### Abstract:
This paper builds upon earlier work from the decision/risk analysis area in presenting simple, easy-to-use approximations for the mean and variance of PERT activity times. These approximations offer significant advantages over the PERT formulas currently being taught and used, as well as over recently proposed modifications. For instance, they are several orders of magnitude more accurate than their PERT counterparts in estimating means and variances of beta distributions if the data required for all methods are obtained accurately. Moreover, they utilize probability data that can be assessed more reliably than those required by the PERT formulas, while still requiring just three points from each activity time probability distribution. Using the proposed approximations can significantly improve the accuracy of probability statements about project completion time, and their use complements ongoing efforts to improve PERT analyses of networks involving multiple critical paths.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1086

## 5. Two-Interval Inventory-Allocation Policies in a One-Warehouse N-Identical-Retailer Distribution System
### Author(s):
- Edward J. McGavin
- Leroy B. Schwarz
- James E. Ward
### Published:
- 1 Sep 1993
### Abstract:
For a system of N-identical-retailers we construct a model for determining warehouse inventory-allocation policies which minimize system lost sales per retailer between system replenishments. An allocation policy is specified by: (a) the number of withdrawals from warehouse stock; (b) the intervals between successive withdrawals; (c) the quantity of stock to be withdrawn from the warehouse in each interval; and (d) the division of withdrawn stock among the retailers. We show that in the case of two withdrawals, available stock in each interval should be divided to balance retailer inventories.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1092

## 6. Notes: Conditions for the Applicability of the Regenerative Method
### Author(s):
- Peter W. Glynn
- Donald L. Iglehart
### Published:
- 1 Sep 1993
### Abstract:
The regenerative method for estimating steady-state parameters is one of the basic methods in simulation output analysis. This method depends on central limit theorems for regenerative processes and weakly consistent estimates for the variance constants arising in the central limit theorems. A weak sufficient condition for both the central limit theorems and consistent estimates is given. Previous authors have implicitly made stronger moment assumptions which have led to strongly consistent variance estimates, more than is needed for the regenerative method to hold. The relationship between conditions for the validity of the regenerative method and those for the validity of standardized time series methods is also discussed.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1108

## 7. Multivariate Autoregressive Techniques for Constructing Confidence Regions on the Mean Vector
### Author(s):
- John M. Charnes
- W. David Kelton
### Published:
- 1 Sep 1993
### Abstract:
We develop a method for constructing confidence regions on the mean vectors of multivariate processes that is based on a vector autoregressive (VAR) representation of the data-generating process. A confidence-region-construction algorithm for a general autoregressive model is given. We establish the asymptotic validity of the confidence-region estimator (that is, the exact achievement of nominal coverage probability as the sample size tends to infinity) when the output process is a stationary vector autoregressive process of known, finite order. With respect to confidence-region volume, coverage probability, and execution time, we carry out an experimental performance comparison of VAR versus the methods of Bonferroni Batch Means (BBM), Multivariate Batch Means (MBM), and Multivariate Spectral Analysis (SPA). The experimental results indicate that (i) VAR delivered confidence regions with the smallest volume; (ii) BBM delivered confidence regions with the largest volume, the highest coverage and the smallest execution time; (iii) in small samples, all of the methods might yield confidence-region estimators whose coverage differs significantly from the nominal level; and (iv) in large samples for which the sample autocorrelation function indicates a vector autoregressive dependence structure, VAR is a viable technique for simulation output analysis.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1112

## 8. Guarantees in Auctions: The Auction House as Negotiator and Managerial Decision Maker
### Author(s):
- Eric A. Greenleaf
- Ambar G. Rao
- Atanu R. Sinha
### Published:
- 1 Sep 1993
### Abstract:
The multimillion dollar price guarantees that an auction house can offer for paintings have already had a large impact on auction house profits, and place new demands on the auctioneer's decision making and negotiating skills. Yet auctioneers have not been studied as independent entities and decision makers. To create a price guarantee, the auction house and the seller must negotiate both the guarantee amount and the extra commission the seller pays if the auction price exceeds the guarantee. We present a normative model of negotiations and find the frontier of guarantee and commission that is the Nash bargaining solution. We also determine the optimal reserve that the auctioneer should place on guaranteed property. We find that guarantees decrease the auction house's expected revenue compared to a conventional auction, but do allow it to attract business which might otherwise be lost. Guarantees benefit sellers, increasing the expected value and lowering the variance of their auction revenue. The auctioneer's optimal strategy depends not only on the distribution of the artwork's auction price, but also the price it will bring if it fails to sell at auction. In the latter case the auction house must pay the seller the guarantee and then sell the artwork, which it now owns, in a private secondary market where buyers regard the property as damaged goods and lower their offers. Although all points on the frontier produce equal expected revenue, several frequently used decision making rules suggest that both parties may prefer a guarantee arrangement where the seller pays no additional commission and the guarantee has the lowest value on the frontier.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1130

## 9. Investigating the Sensitivity of Equilibrium Profits to Advertising Dynamics and Competitive Effects
### Author(s):
- Pradeep K. Chintagunta
### Published:
- 1 Sep 1993
### Abstract:
The author investigates the validity of the flat maximum principlethe insensitivity of a firm's profits to changes in its optimal advertising levelin a duopolistic market in which advertising by the two firms has carryover effects. Two alternative competitive scenarios are examined (i) in which total industry sales are allowed to vary over time, and (ii) where firms are engaged in market share rivalry. For (i), the open-loop Nash equilibrium advertising strategies for the firms are derived assuming a specific sales response function and an infinite time horizon. A numerical analysis of the sensitivity of firms' profit functions to advertising expenditures is performed at different levels of the (a) discount rate, (b) advertising elasticity, and (c) advertising decay rate. An empirical illustration from the pharmaceutical industry is provided. Special cases of the model formulation are examined analytically in order to highlight the intuition behind the flatness of the maximum and to study the sensitivity of results obtained to choice of equilibrium strategy (closed-loop vs. open-loop). For the market share game, closed-loop policies are considered and the flat maximum principle is illustrated in the context of CokePepsi rivalry in the soft drinks market.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1146

## 10. On the Extensive Number of Plays to Achieve Superior Performance with the Geometric Mean Strategy
### Author(s):
- Donald C. Aucamp
### Published:
- 1 Sep 1993
### Abstract:
The advantages of the Geometric Mean or Log Strategy have been well documented and recommended by many because a follower of this strategy will ultimately outperform in the long-run any other significantly different strategy, almost surely. This paper provides both theory and evidence to indicate that the long-run can be quite long in risky situations. These cases are typified by many business ventures and undiversified speculative investments in OTC securities. On the other hand, it is shown that the Log Strategy can virtually dominate in a moderate number of plays in cases when risk is low.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1163

## 11. Bounds for Different Arrangements of Tandem Queues with Nonoverlapping Service Times
### Author(s):
- Yat-wah Wan
- Ronald W. Wolff
### Published:
- 1 Sep 1993
### Abstract:
We bound the difference in performance measures among different orders of tandem queues when service times are nonoverlapping. Two types of nonoverlapping service times, with respect to (w.r.t.) tasks and w.r.t. customers, are defined; it is not required that service times be independent. For nonoverlapping service times w.r.t. tasks, we bound the sample-path difference in number of customers in system by one, and bound the corresponding time-average difference by the traffic intensity of the longest station. For nonoverlapping service times w.r.t. customers, we bound the difference in mean sojourn time when the service times are bounded random variables. While we are motivated by probabilistic results, our methods and results are entirely deterministic.
### Link:
- https://doi.org/10.1287/mnsc.39.9.1173

