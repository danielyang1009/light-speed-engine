# Volume 39, Issue 03
- March 1993
- Pages 255-394
- David Simchi-Levi

## 1. Selecting Product Development Projects: Pioneering versus Incremental Innovation Strategies
### Author(s):
- Abdul Ali
- Manohar U. Kalwani
- Dan Kovenock
### Published:
- 1 Mar 1993
### Abstract:
In this paper, we investigate project selection choices of duopolists facing two alternatives: undertaking a pioneering type project (Type A) aimed to develop a highly innovative product, or an incremental innovation type project (Type B) aimed to develop a less innovative product such as the modification of an existing product. A key objective of our research is to examine how firm characteristics such as their differential efficiencies in completing projects, differences in the degree of substitutability between Type A and B products, and first mover advantages affect product development strategies. We develop a game-theoretic model to obtain insights into the project selection problem taking into account competitive reactions to a firm's choice of project development strategies and technical uncertainties associated with project completion times. We report model findings on recommended project selection strategies for efficient and disadvantaged firms. Further, we examine how a firm's choice of a Type A project is affected by an increase in the variance of the project completion time of a Type A project relative to that of a Type B project, while the ratio of their mean completion times is held constant.
### Link:
- https://doi.org/10.1287/mnsc.39.3.255

## 2. Bayesian Forecasting for Seemingly Unrelated Time Series: Application to Local Government Revenue Forecasting
### Author(s):
- George Duncan
- Wilpen Gorr
- Janusz Szczypula
### Published:
- 1 Mar 1993
### Abstract:
One important implementation of Bayesian forecasting is the Multi-State Kalman Filter (MSKF) method. It is particularly suited for short and irregular time series data. In certain applications, time series data are available on numerous parallel observational units which, while not having cause-and-effect relationships between them, are subject to the same external forces (e.g., business cycles). Treating them separately may lose useful information for forecasting. For such situations, involving seemingly unrelated time series, this article develops a Bayesian forecasting method called C-MSKF that combines the MSKF method with the Conditionally Independent Hierarchical method. A case study on forecasting income tax revenue for each of forty school districts in Allegheny County, Pennsylvania, based on fifteen years of data, is used to illustrate the application of C-MSKF in comparison with univariate MSKF. Results show that C-MSKF is more accurate than MSKF. The relative accuracy of C-MSKF increases with decreasing length of historical time series data, increasing forecasting horizon, and sensitivity of school districts to the economic cycle.
### Link:
- https://doi.org/10.1287/mnsc.39.3.275

## 3. Flow Management in Flexible Manufacturing Cells with Pipeline Operations
### Author(s):
- A. Agnetis
- M. Lucertini
- F. Nicolo
### Published:
- 1 Mar 1993
### Abstract:
The problem of flow management for a class of flexible manufacturing cells is considered. The cell is designed for cyclic production of one product. This product is characterized by a sequence of operations of given length and each requiring a set of resources; the problem is therefore to allocate such resources and scheduling the operations in order to maximize the throughput. A general model is proposed and several special cases are discussed, corresponding to either polynomial or NP-complete problems. The cases analyzed differ from each other in the number of operating machines and in the number of product units present at the same time in the cell. The solution to the polynomial problems is given in terms of shortest path on particular networks.
### Link:
- https://doi.org/10.1287/mnsc.39.3.294

## 4. A Multistage Screening Model for Evaluation and Control of Misclassification Error in the Detection of Hypertension
### Author(s):
- Herbert Moskowitz
- Robert Plante
- Hsien-Tang Tsai
### Published:
- 1 Mar 1993
### Abstract:
Hypertension is one of the most important risk factors with respect to coronary heart disease and stroke. The benefits of early detection of hypertension and the subsequent design of follow-up treatment programs are well documented. Consequently, screening programs have been designed to identify subjects as normotensive (normal) or hypertensive (abnormal). In order for these programs to be effective, full participation of the subject population is required. However, such classification programs can incur massive risks of incorrectly classifying subjects as normotensive who are truly hypertensive and incorrectly classifying subjects as hypertensive who are truly normotensive. To date, the only means to reduce these risks of misclassification is to require subjects to make numerous visits for blood pressure measurement before they can be classified. Such requirements reduce the level of participation in screening programs and also delay the identification of subjects who are truly hypertensive, thereby depriving them of the benefits of early detection and immediate follow-up treatment.
### Link:
- https://doi.org/10.1287/mnsc.39.3.307

## 5. The Impact of Autocorrelation on Queuing Systems
### Author(s):
- Miron Livny
- Benjamin Melamed
- Athanassios K. Tsiolis
### Published:
- 1 Mar 1993
### Abstract:
The performance of single-server queues with independent interarrival intervals and service demands is well understood, and often analytically tractable. In particular, the M/M/1 queue has been thoroughly studied, due to its analytical tractability. Little is known, though, when autocorrelation is introduced into interarrival times or service demands, resulting in loss of analytical tractability. Even the simple case of an M/M/1 queue with autocorrelations does not appear to be well understood. Such autocorrelations do, in fact, abound in real-life systems, and worse, simplifying independence assumptions can lead to very poor estimates of performance measures. This paper reports the results of a simulation study of the impact of autocorrelation on performance in an FIFO queue. The study used two computer methods for generating autocorrelated random sequences, with different autocorrelation characteristics. The simulation results show that the injection of autocorrelation into interarrival times, and to a lesser extent into service demands, can have a dramatic impact on performance measures. From a performance viewpoint, these effects are generally deleterious, and their magnitude depends on the method used to generate the autocorrelated process. The paper discusses these empirical results and makes some recommendations to practitioners of performance analysis of queuing systems.
### Link:
- https://doi.org/10.1287/mnsc.39.3.322

## 6. Moment Methods for Decision Analysis
### Author(s):
- James E. Smith
### Published:
- 1 Mar 1993
### Abstract:
Decision models involving continuous probability distributions almost always require some form of approximation. The usual approach to evaluating these kinds of models is to construct a discrete approximation for each continuous distribution and compute value lotteries and certain equivalents using these discrete approximations. Although decision analysts are quite comfortable with this approach, there has been relatively little consideration of how these discrete approximations affect the results of the analysis. In the first part of this paper, we review three common methods of constructing discrete approximations and compare their performance in a simple example.
### Link:
- https://doi.org/10.1287/mnsc.39.3.340

## 7. Second Derivative Sample Path Estimators for the GI/G/m Queue
### Author(s):
- Michael C. Fu
- Jian-Qiang Hu
### Published:
- 1 Mar 1993
### Abstract:
Applying the technique of smoothed perturbation analysis (SPA) to the GI/G/m queue with first-come, first-served (FCFS) queue discipline, we derive sample path estimators for the second derivative of mean steady-state system time with respect to a parameter of the service time distribution. Such estimators provide a possible means for speeding up the convergence of gradient-based stochastic optimization algorithms. The derivation of the estimators sheds some new light on the complications encountered in applying the technique of SPA. The most general cases require the simulation of additional sample subpaths; however, an approximation procedure is also introduced which eliminates the need for additional simulation. Simulation results indicate that the approximation procedure is reasonably accurate. When the service times are exponential or deterministic, the estimator simplifies and the approximation procedure becomes exact. For the M/M/2 queue, the estimator is proved to be strongly consistent.
### Link:
- https://doi.org/10.1287/mnsc.39.3.359

## 8. Notes: Categorical Outputs in Data Envelopment Analysis
### Author(s):
- John J. Rousseau
- John H. Semple
### Published:
- 1 Mar 1993
### Abstract:
A new linear programming formulation for handling categorical outputs in DEA is presented which eliminates the difficulties of interpretation and computation that accompanied earlier mixed integer models.
### Link:
- https://doi.org/10.1287/mnsc.39.3.384

## 9. Comments on the Two-Product, Single-Machine, Static Demand, Infinite Horizon Lot Scheduling Problem
### Author(s):
- Chen Shaoxiang
### Published:
- 1 Mar 1993
### Abstract:
One of the necessary and sufficient conditions derived by F. F. Boctor (1982) for feasibility of a repetitive two-product schedule is that the cycle times (T1 and T2) must be integer multiples of some time interval T (Propositions 2, 3 and 4). This result also holds for N-product schedules. However, the proof for Propositions 3 and 4 in [1] is not exactly valid and therefore a correction has to be made.
### Link:
- https://doi.org/10.1287/mnsc.39.3.387

## 10. Multiattribute Risk Linearity
### Author(s):
- Charles M. Harvey
### Published:
- 1 Mar 1993
### Abstract:
In applying multiattribute utility theory, one typically assumes the condition of mutual utility independence and uses a multiattribute utility function that is additive or multiplicative. This paper proposes a model in which this condition is not satisfied, that is, the risk attitude for one attribute depends on the amounts of the other attributes. We introduce a condition on this dependence called multiattribute risk linearity that implies a logarithmic form for the multiattribute utility function, and we show that a logarithmic utility function can be determined by assessment procedures that require the same number of indifference assessments as those for a multiplicative utility function.
### Link:
- https://doi.org/10.1287/mnsc.39.3.389

