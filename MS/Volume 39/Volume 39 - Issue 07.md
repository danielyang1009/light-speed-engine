# Volume 39, Issue 07
- July 1993
- Pages 777-913
- David Simchi-Levi

## 1. Compensation Plans for Single- and Multi-Product Salesforces: An Application of the Holmstrom-Milgrom Model
### Author(s):
- Rajiv Lal
- V. Srinivasan
### Published:
- 1 Jul 1993
### Abstract:
The agency theory approach to understanding salesforce compensation plans is modified to incorporate the intratemporal nature of the salesperson's effort-rate decision, i.e., the decision about the effort-rate at any given point in time potentially depends upon the sales performance up to that point in time in the accounting period. Under the assumptions considered in this paper, Holmstrom and Milgrom (1987) have shown that the optimal compensation plan is linear in total sales over the accounting period. The comparative statics results obtained here corroborate most of the corresponding results in the salesforce compensation literature; moreover, we derive many additional results not available in the literature. It is demonstrated that the commission income as a fraction of total compensation goes up with an increase in the effectiveness of the sales-effort or an increase in base sales. On the other hand, the salary component of the total compensation goes up with increases in uncertainty, absolute risk aversion, marginal cost of production, perceived cost of effort, and/or alternative job opportunities for the salesperson. We provide a discussion of different selling situations where our results may be more or less applicable. An examination of empirical studies already available in the literature reveals support for our findings regarding the relative emphasis of salary and incentive pay in the compensation plan. We also extend the agency theory approach to compare commission rates across products for a multiproduct salesperson. Here it is shown that commission rates are higher for products with higher sales-effort effectiveness, lower levels of uncertainty, and/or lower marginal costs.
### Link:
- https://doi.org/10.1287/mnsc.39.7.777

## 2. The Effects of Risk Aversion on Production Decisions in Decentralized Organizations
### Author(s):
- Anil Arya
- John C. Fellingham
- Richard A. Young
### Published:
- 1 Jul 1993
### Abstract:
This paper presents a principal-agent model in which subsequent to contracting the risk averse agent becomes informed about the production process. Communication of the agent's information is always valuable. The optimal contract given this information asymmetry is characterized by less production and a larger risk premium than when information is symmetric, leading to an efficiency loss. Comparative statics show that the loss in expected production increases as the agent becomes more risk averse.
### Link:
- https://doi.org/10.1287/mnsc.39.7.794

## 3. Outcome Signs, Question Frames and Discount Rates
### Author(s):
- Marjorie K. Shelley
### Published:
- 1 Jul 1993
### Abstract:
This study explains why gain/loss discount rate differences reported in previous studies cannot be attributed to outcome sign alone, but rather, must be associated with particular outcome-sign/question-frame combinations. To do so, it extends Loewenstein's (1988) framing model of intertemporal choice to negative outcomes and uses the resulting predictions to interpret and integrate the results of three previous studies comparing subjective discount rates (Thaler 1981, Loewenstein 1988, Benzion et al. 1989). The new framework reveals previously unidentified linkages among outcome signs, question frames, and discount rates. To investigate whether losses and gains are, in fact, discounted differently, an experiment is conducted that includes a neutral-frame intertemporal choice scenario (no proposed change in outcome timing) for each outcome sign. The results show that subjective discount rates vary in a predictable way according to the outcome sign and question frame combination examined.
### Link:
- https://doi.org/10.1287/mnsc.39.7.806

## 4. Covariance Structure Models and Influence Diagrams
### Author(s):
- William J. Burns
- Robert T. Clemen
### Published:
- 1 Jul 1993
### Abstract:
Statisticians use covariance structure modeling as a versatile tool for modeling and testing theory. The models that result provide explicit and detailed descriptions of stochastic systems. We show how covariance structure models are relatedmathematically, conceptually, philosophically and practicallyto Gaussian influence diagrams as described by Shachter and Kenley (1989). This relationship suggests ways in which covariance structure modeling can be used to advantage in the prescriptive domain of decision analysis. The paper includes an example concerning the management of hazardous materials, in which a covariance structure model is converted to an influence diagram for use in a prescriptive analysis.
### Link:
- https://doi.org/10.1287/mnsc.39.7.816

## 5. Were the Returns from Stocks and Bonds of Different Countries Really Different in the 1980s?
### Author(s):
- Andrew L. Turner
- Chris R. Hensel
### Published:
- 1 Jul 1993
### Abstract:
We analyzed the total equity returns of indexes from Australia, Canada, Germany, Japan, the UK, and the US and total fixed income returns of indexes from all but Australia (excluded due to lack of data) to see if the returns of stocks and bonds were statistically different across markets during the 1980s. At the end of 1989, these countries represented over 87% of the market capitalization of the Morgan Stanley Capital International (MSCI) World Equity Index and over 88% of the Salomon Brothers World Bond Index. This study used monthly observations from January 1980 through December 1989 and examined returns based in local currency and hedged and unhedged US dollars.
### Link:
- https://doi.org/10.1287/mnsc.39.7.835

## 6. Massaging Mean-Variance Inputs: Returns from Alternative Global Investment Strategies in the 1980s
### Author(s):
- Vijay K. Chopra
- Chris R. Hensel
- Andrew L. Turner
### Published:
- 1 Jul 1993
### Abstract:
This paper explores the impact of adjustments to the inputs on total returns, terminal wealth, and portfolio turnover in an unconstrained monthly mean-variance (MV) asset allocation over time. It is well known that MV allocations are very sensitive to small forecast errors in the means and covariances. This sensitivity is especially pronounced for errors in means. One way to control this sensitivity to forecast errors is to use Stein estimation. We examined three naive applications of Stein estimation for six individual country stock indexes, five country bond indexes and five cash indexes.
### Link:
- https://doi.org/10.1287/mnsc.39.7.845

## 7. On the Use of Mean-Variance and Quadratic Approximations in Implementing Dynamic Investment Strategies: A Comparison of Returns and Investment Policies
### Author(s):
- Robert R. Grauer
- Nils H. Hakansson
### Published:
- 1 Jul 1993
### Abstract:
This paper compares two approximation schemes for calculating the optimal portfolios in the discrete-time dynamic investment model, specifically, the mean-variance (MV) and the quadratic approximations, to the exact power function method. Future returns are estimated via the empirical probability assessment approach. The results show that (i) with quarterly revision, the MV model approximates the dynamic model very well; (ii) with annual revision, there are often sharp differences between the power function model and the MV approximation; and (iii) these differences become even larger when the quadratic approximation is used.
### Link:
- https://doi.org/10.1287/mnsc.39.7.856

## 8. Common Cycle Lot-Size Scheduling for Multi-Product, Multi-Stage Production
### Author(s):
- Mohammad K. El-Najdawi
- Paul R. Kleindorfer
### Published:
- 1 Jul 1993
### Abstract:
In this paper we study the Common Cycle Scheduling Problem (CCSP). This classic production problem is concerned with determining optimal production lot sizes for a given set of products using a common facility. CCSP is based on scheduling all products using a common (base) cycle time, so that the lot size for each product is the forecasted demand for that product over the base cycle time. This research provides an optimizing framework for CCSP for a multi-stage, multi-product, flow-shop environment under deterministic and stationary conditions, assuming a fixed sequence is maintained across all processing stages. The framework presented considers the costs of work-in-process inventory and determines a jointly optimal common cycle time and production schedule (start and finish times for each product's production lot-size) for the multi-stage facility in question. The paper also reports some results on the impact of alternative sequencing rules for the CCSP context.
### Link:
- https://doi.org/10.1287/mnsc.39.7.872

## 9. Filtered Sampling from Populations with Heterogeneous Event Frequencies
### Author(s):
- Alfred Blumstein
- Jos A. Canela-Cacho
- Jacqueline Cohen
### Published:
- 1 Jul 1993
### Abstract:
A hierarchical model is developed to account for selection biases that result from processes in which events have a fixed probability of being sampled, but individuals in the population generate events at varying rates. It is shown that inferences about the population parameters from such unrepresentative samples are not only possible but can be statistically powerful, provided the selection biases are adequately controlled for and the specification of the model is appropriate. The model assumptions are sufficiently flexible to accommodate a variety of stochastic processes with heterogeneous event frequencies. In an example, the model is applied to data on robbery rates for prison inmates in order to estimate the robbery rates for all offenders. The model fits the data well, and the results show that the bias toward high rate offenders among prison inmates is substantial.
### Link:
- https://doi.org/10.1287/mnsc.39.7.886

## 10. An Algebraic Approach to Formulating and Solving Large Models for Sequential Decisions Under Uncertainty
### Author(s):
- Craig W. Kirkwood
### Published:
- 1 Jul 1993
### Abstract:
This article presents an algebraic approach to formulating and solving large models for sequential decisions under uncertainty. With this approach, decision analysis optimization methods can be applied to complex decision problems which are generally analyzed in management science practice using heuristics. Using the approach, a decision problem is formulated in terms of decision variables, random variables, and functions relating these variables. This leads to a compact representation, and a simple algorithm can be used to quickly solve algebraic models that would have decision trees with several hundred thousand endpoints. An application to research and development planning illustrates the usefulness of such large sequential decision models.
### Link:
- https://doi.org/10.1287/mnsc.39.7.900

