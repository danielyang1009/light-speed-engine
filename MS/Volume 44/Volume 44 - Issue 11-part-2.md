# Volume 44, Issue 11-part-2
- November 1998
- Pages S1-S144
- David Simchi-Levi

## 1. The Effects of R&D Team Co-location on Communication Patterns among R&D, Marketing, and Manufacturing
### Author(s):
- Christophe Van den Bulte
- Rudy K. Moenaert
### Published:
- 1 Nov 1998
### Abstract:
Reducing the physical distance among R&D engineers and between R&D and marketing is widely believed to result in more frequent communication, and hence higher product development performance. However, the empirical evidence for the effect of co-location on communication frequency is problematic for two reasons: (1) the evidence often features either little contextual realism or doubtful internal validity, and (2) the analysis does not deal with the statistical problems typical of network data. Our study avoids the first problem by using sequential network data collected from a quasi-experiment at an industrial company that regrouped its R&D teams into a new facility. We avoid the second problem by using Wasserman and Iacobucci's (1988) method for the statistical analysis of sequential network data. Our results show that communication among R&D teams was enhanced after co-locating these teams. Surprisingly, communication frequency between R&D and marketing was not affected by the increased physical distance. This may suggest that business procedures accompanying the relocation prevented a widening gap between R&D and marketing. Alternatively, it may indicate that the effect of co-location depends on the content and medium of the communication flows.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S1

## 2. Leasing and Selling: Optimal Marketing Strategies for a Durable Goods Firm
### Author(s):
- Preyas Desai
- Devavrat Purohit
### Published:
- 1 Nov 1998
### Abstract:
This paper analyzes the problems associated with marketing a durable through leases and sales. Academic research in this area has argued that in a monopolistic environment, leasing dominates selling. Hence, leasing and selling should not co-exist and the firm should concentrate its efforts solely on leasing. We show that the relative profitability of leasing and selling hinges on the rates at which leased and sold units depreciate. In particular, we find that leasing does not dominate selling in all cases; if sold units depreciate at a significantly higher rate than leased units, a monopolistic firm is better off by only selling its product. In addition, we find that if leaded and sold products depreciate at different rates, then the optimal strategy for the firm involves a combination of both leasing and selling. We conclude the paper with an empirical analysis of the depreciation rates of leased and sold units of a popular car model. We find that the depreciation rate of leased cars has been significantly lower than the depreciation rate of sold cars.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S19

## 3. Knowledge Driven Quality Improvement
### Author(s):
- Amit Shankar Mukherjee
- Michael A. Lapr
- Luk N. Van Wassenhove
### Published:
- 1 Nov 1998
### Abstract:
Little is known about the processes that make TQM effective. Why are some quality improvement projects more effective than others? We argue that TQM processes affect the way people create new knowledge, which in turn determines organizational effectiveness. We explore this by studying 62 quality improvement projects undertaken in one factory over a decade. Using a factor analysis we identify three learning constructs that characterize the learning process: scope, conceptual learning, and operational learning. We use OLS regressions to study the impact of these learning constructs on project performance. Conceptual and operational learning are found to play a crucial role in achieving goals, creating new technological knowledge, and changing factory personnel's attention. Contrary to the common practice of relying on operational learning, we suggest the application of conceptual learning as well, particularly if the technology is poorly understood. It facilitates the codification of knowledge, which enhances its dissemination for both present and future use.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S35

## 4. Managing New Product Definition in Highly Dynamic Environments
### Author(s):
- Shantanu Bhattacharya
- V. Krishnan
- Vijay Mahajan
### Published:
- 1 Nov 1998
### Abstract:
In highly dynamic environments, characterized by changing customer preferences and uncertainty about competitive products, managing the development of a new product is a complex managerial task. The traditional practice, recommended in the literature, of reaching a sharp definition early in the new product development (NPD) process may not be optimal, desirable or even feasible in such dynamic situations. Under high uncertainty, forcing early finalization of specifications may result in a firm getting locked into an incorrect definition. Based on our study of NPD in the high technology industry, we present a model of an approach called real-time definition, in which a firm adapts its product definition process to the market and competitive environment. Uncertainty in the product definition is resolved through frequent, repeated interactions with customers and using a flexible development process. We find that early definition is optimal only in a limited set of situations. To maximize its anticipated profits, a firm should tune its definition process to the prevailing level of market uncertainty, the marginal value of information obtained from the customer during the NPD process, and its own risk-profile and internal development capabilities. Effects of competition on a firm's definition approach are also examined, and implications for managers of a NPD process are presented using a conceptual framework.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S50

## 5. A Multi-Agent Framework for the Coordination and Integration of Information Systems
### Author(s):
- Riyaz Sikora
- Michael J. Shaw
### Published:
- 1 Nov 1998
### Abstract:
This paper describes a framework for the coordination and integration of information systems. By modeling typical enterprise information systems as consisting of multiple agents with different functionalities, the methodology provides the representational formalism, coordination mechanisms, and control schemes necessary for integrating heterogeneous units of an information system while meeting such performance criteria as overall effectiveness, efficiency, responsiveness, and robustness.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S65

## 6. Dynamic Asset Allocation in a Mean-Variance Framework
### Author(s):
- Isabelle Bajeux-Besnainou
- Roland Portait
### Published:
- 1 Nov 1998
### Abstract:
The aim of this article is to analyze the portfolio strategies that are mean-variance efficient when continuous rebalancing is allowed between the current date (0) and the horizon (T). Under very general assumptions, when a zero-coupon bond of maturity T exists, the dynamic efficient frontier is a straight line, the slope of which is explicitly characterized. Every dynamic mean-variance efficient strategy can be viewed as buy and hold combinations of two funds: the zero-coupon bond of maturity T and a continuously rebalanced portfolio. An appropriate dynamic strategy defining the latter is explicitly derived for two particular price processes and comparisons of the Efficient Frontiers (Static versus Dynamic) are provided in these cases.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S79

## 7. Note. An Acquisition Policy for a Single Item Multi-Supplier System
### Author(s):
- Meir J. Rosenblatt
- Yale T. Herer
- Ilan Hefter
### Published:
- 1 Nov 1998
### Abstract:
In this paper we consider the problem of developing an acquisition policy. Specifically, given a set of potential (qualified) suppliers, from whom should the firm buy the product, in what quantities, and how often? We provide properties of the optimal solution and relate them to the approach of using a single source as advocated by JIT. The solution procedure provides the periodic order quantity from each supplier; the order size; and the firm cycle time as well as how many times per cycle we should order from each supplier. We show that the maximum error of our solution can be made as small as desired.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S96

## 8. Applying Robust Optimization to Capacity Expansion of One Location in Telecommunications with Demand Uncertainty
### Author(s):
- Manuel Laguna
### Published:
- 1 Nov 1998
### Abstract:
The problem of expanding the capacity of a single facility in telecommunications network planning is addressed. This problem can be formulated as a time-dependent knapsack, when relevant information is assumed to be known. We introduce the use of scenarios to model uncertainty in key data. The problem is formulated within the robust optimization framework and solved exactly in two phases. The first phase consists of a dynamic programming recursion and the second one of a shortest path procedure. Experiments show that a large number of scenarios can be handled with this technique, because computational times are more sensitive to the maximum demand across all scenarios than to the number of scenarios considered. A user-interface based on Microsoft Excel is developed as a decision support system for network planners.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S101

## 9. Hierarchical Bayes Methods for Multifactor Model Estimation and Portfolio Selection
### Author(s):
- Martin R. Young
- Peter J. Lenk
### Published:
- 1 Nov 1998
### Abstract:
The factor model is an important construct for both portfolio managers and researchers in modern finance. For practitioners, factor model coefficients are used to guide the construction of optimal portfolios. For academicians, factor model parameters play a fundamental role in explaining equilibrium asset prices and other market phenomena. This paper presents a hierarchical modeling procedure that can substantially improve the accuracy of factor model parameter estimates through incorporation of cross-sectional information. It is shown that this improvement in parameter estimation accuracy translates into substantial improvement in portfolio performance. Expressions are derived that characterize the sensitivity of portfolio performance to parameter estimation error. Evidence with NYSE data suggests that the hierarchical estimation technique leads to superior out-of-sample portfolio performance when compared to alternative estimation approaches.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S111

## 10. Stochastic Shortest Path Problems with Piecewise-Linear Concave Utility Functions
### Author(s):
- Ishwar Murthy
- Sumit Sarkar
### Published:
- 1 Nov 1998
### Abstract:
This paper considers a stochastic shortest path problem where the arc lengths are independent random variables following a normal distribution. In this problem, the optimal path is one that maximizes the expected utility, with the utility function being piecewise-linear and concave. Such a utility function can be used to approximate nonlinear utility functions that capture risk averse behaviour for a wide class of problems. The principal contribution of this paper is the development of exact algorithms to solve large problem instances. Two algorithms are developed and incorporated in labelling procedures. Computational testing is done to evaluate the performance of the algorithms. Overall, both algorithms are very effective in solving large problems quickly. The relative performance of the two algorithms is found to depend on the curvature of the piecewise linear utility function.
### Link:
- https://doi.org/10.1287/mnsc.44.11.S125

## 11. A Note on Approximating Peak Congestion in Mt/G/ Queues with Sinusoidal Arrivals
### Author(s):
- Linda V. Green
- Peter J. Kolesar
### Published:
- 1 Nov 1998
### Abstract:
We study the Mt/G/ queue where customers arrive according to a sinusoidal function t =  + A sin(2t/T) and the service rate is . We show that the expected number of customers in the system during peak congestion can be closely approximated by ( + A)/ for service distributions with coefficient of variation between 0 and 1. Motivated by a result derived by Eick, Massey, and Whitt that the time lag of the peak congestion from the peak of the customer arrivals is 1/2 for models with deterministic service times, we show that the time lag for exponential service times is closely approximated by 1/. Based on a cycle length of 24 hours and regardless of the values of other system parameters, these approximations are of the order of 1% accuracy for  = 1, and the accuracy increases rapidly with increasing .
### Link:
- https://doi.org/10.1287/mnsc.44.11.S137

