# Volume 54, Issue 1
- January 2008
- Pages iv-235
- David Simchi-Levi

## 1. Management Insights
### Author(s):
### Published:
- 1 Jan 2008
### Abstract:
None
### Link:
- https://doi.org/10.1287/mnsc.1070.0854

## 2. A Queueing Analysis to Determine How Many Additional Beds Are Needed for the Detention and Removal of Illegal Aliens
### Author(s):
- Yifan Liu
- Lawrence M. Wein
### Published:
- 1 Jan 2008
### Abstract:
Due to lack of detention capacity (the U.S. government measures capacity by the number of detention beds), tens of thousands of apprehended illegal aliens are released into the U.S. interior each year, instead of being removed from the country. This vulnerability can be exploited by terrorist groups wanting to enter the United States. We construct a queueing model of the U.S. detention and removal operations, and derive approximate analytical expressions for key performance measures, including a simple normal approximation for the required number of beds. Due to shortcomings in the U.S. government's data collection procedures, we cannot directly estimate all of the model's parameter values. Consequently, we use the approximate analytical expressions and the 2003 U.S. government data quantifying these key performance measures to estimate several unknown parameter values. Although current funding is for approximately 21,000 detention beds, we estimate that approximately 34,500 beds are needed to remove all potential detainees (this does not include nonviolent, noncriminal Mexicans, who are returned to Mexico within several hours) based on 2003 data. The dramatic increase in the arrivals of potential detainees since 2003 suggests that approximately 50,000 beds are currently required, although the estimation of future arrival rates is very difficult due to uncertainties about the future direction of U.S. immigration policy. Our estimated bed requirements are approximately 25% higher than naive estimates that fail to account for right censoring of residence times due to some detainees being released from detention before removal to make way for higher-priority detainees.
### Link:
- https://doi.org/10.1287/mnsc.1070.0770

## 3. Public Evacuation Decisions and Hurricane Track Uncertainty
### Author(s):
- Eva Regnier
### Published:
- 1 Jan 2008
### Abstract:
Public officials with the authority to order hurricane evacuations face a difficult trade-off between risks to life and costly false alarms. Evacuation decisions must be made on the basis of imperfect information, in the form of forecasts. The quality of these decisions can be improved if they are also informed by measures of uncertainty about the forecast, including estimates of the value of waiting for updated, more accurate, forecasts. Using a stochastic model of storm motion derived from historic tracks, this paper explores the relationship between lead time and track uncertainty for Atlantic hurricanes and the implications of this relationship for evacuation decisions. Typical evacuation clearance times and track uncertainty imply that public officials who require no more than a 10% probability of failing to evacuate before a striking hurricane (a false negative) must accept that at least 76%and for some locations over 90%of evacuations will be false alarms. Reducing decision lead times from 72 to 48 hours for major population centers could save an average of hundreds of millions of dollars in evacuation costs annually, with substantial geographic variation in savings.
### Link:
- https://doi.org/10.1287/mnsc.1070.0764

## 4. A Path-Based Approach for Hazmat Transport Network Design
### Author(s):
- Vedat Verter
- Bahar Y. Kara
### Published:
- 1 Jan 2008
### Abstract:
The people living and working around the roads used for hazardous material (hazmat) shipments face the risk of suffering undesirable consequences of an accident. The main responsibility to mitigate the hazmat transport risk at a population zone belongs to the government agency with jurisdiction over that region. One of the common policy tools is to close certain road links to vehicles carrying hazmats. In effect, the road network available to dangerous goods carriers can be determined by the regulator. The transport risk in the region, however, is determined by the carriers' routing decisions over the available road network. Thus, the regulator needs to make the road closure decisions so that the total risk resulting from the carriers' route choices is minimized. We provide a path-based formulation for this network design problem. Alternative solutions can be generated by varying the routing options included in the model for each shipment. Each solution corresponds to a certain compromise between the two parties in terms of transport risk and economic viability. The proposed framework can be used for identifying mutually agreeable hazmat transport policies. We present two applications of the methodology to illustrate the insights that can be gained through its use: The first application focuses on hazmat shipments through the highway network of Western Ontario, Canada, whereas the second application studies the problem in a much larger geographical region that covers the provinces of Ontario and Quebec.
### Link:
- https://doi.org/10.1287/mnsc.1070.0763

## 5. Structural Estimation of the Newsvendor Model: An Application to Reserving Operating Room Time
### Author(s):
- Marcelo Olivares
- Christian Terwiesch
- Lydia Cassorla
### Published:
- 1 Jan 2008
### Abstract:
The newsvendor model captures the trade-off faced by a decision maker that needs to place a firm bet prior to the occurrence of a random event. Previous research in operations management has mostly focused on deriving the decision that minimizes the expected mismatch costs. In contrast, we present two methods that estimate the unobservable cost parameters characterizing the mismatch cost function. We present a structural estimation framework that accounts for heterogeneity in the uncertainty faced by the newsvendor as well as in the cost parameters. We develop statistical methods that give consistent estimates of the model primitives, and derive their asymptotic distribution, which is useful to do hypothesis testing. We apply our econometric model to a hospital that balances the costs of reserving too much versus too little operating room capacity to cardiac surgery cases. Our results reveal that the hospital places more emphasis on the tangible costs of having idle capacity than on the costs of schedule overrun and long working hours for the staff. We also extend our structural models to incorporate external information on forecasting biases and mismatch costs reported by the medical literature. Our analysis suggests that overconfidence and incentive conflicts are important drivers of the frequency of schedule overruns observed in our sample.
### Link:
- https://doi.org/10.1287/mnsc.1070.0756

## 6. Generating Objectives: Can Decision Makers Articulate What They Want?
### Author(s):
- Samuel D. Bond
- Kurt A. Carlson
- Ralph L. Keeney
### Published:
- 1 Jan 2008
### Abstract:
Objectives have long been considered a basis for sound decision making. This research examines the ability of decision makers to generate self-relevant objectives for consequential decisions. In three empirical studies, participants consistently omitted nearly half of the objectives that they later identified as personally relevant. More surprisingly, omitted objectives were perceived to be almost as important as those generated by participants on their own. These empirical results were replicated in a real-world case study of strategic decision making at a high-tech firm. Overall, our research suggests that decision makers are considerably deficient in utilizing personal knowledge and values to form objectives for the decisions they face.
### Link:
- https://doi.org/10.1287/mnsc.1070.0754

## 7. Predicting Product Purchase from Inferred Customer Similarity: An Autologistic Model Approach
### Author(s):
- Sangkil Moon
- Gary J. Russell
### Published:
- 1 Jan 2008
### Abstract:
Product recommendation models are key tools in customer relationship management (CRM). This study develops a product recommendation model based on the principle that customer preference similarity stemming from prior purchase behavior is a key element in predicting current product purchase. The proposed recommendation model is dependent on two complementary methodologies: joint space mapping (placing customers and products on the same psychological map) and spatial choice modeling (allowing observed choices to be correlated across customers). Using a joint space map based on past purchase behavior, a predictive model is calibrated in which the probability of product purchase depends on the customer's relative distance to other customers on the map. An empirical study demonstrates that the proposed approach provides excellent forecasts relative to benchmark models for a customer database provided by an insurance firm.
### Link:
- https://doi.org/10.1287/mnsc.1070.0760

## 8. On the Recoverability of Choice Behaviors with Random Coefficients Choice Models in the Context of Limited Data and Unobserved Effects
### Author(s):
- Rick L. Andrews
- Andrew Ainslie
- Imran S. Currim
### Published:
- 30 Nov 2007
### Abstract:
Random coefficients choice models are seeing widespread adoption in marketing research, partly because of their ability to generate household-level parameter estimates with limited data. However, the power of such models may tempt researchers to trust that they continue to produce reasonable estimates, when in fact either model misspecification or insufficient data limits the models' ability to recover household-level parameters successfully. If household-level choice behaviors are not recovered successfully, managerial decisions such as marketing-mix planning and targeting, direct marketing, segmentation, and forecasting may not produce the desired results. This study addresses the following questions. First, can random coefficients choice models correctly identify markets characterized by preference and response heterogeneity, state dependence, the use of alternative decision heuristics that result in reduced choice sets, and combinations of these effects? If so, how much data is required, and is this realistic given the size of data sets typically used in marketing analyses? Which model selection criteria should be used to identify these markets? When there is spurious market identification, which parameters contribute to the spurious result? An extensive simulation experiment is conducted wherein random coefficients logit models with varying specifications of parameter heterogeneity, state dependence effects, and choice set heterogeneity are applied to 128 experimental conditions. The results show which types of markets can be identified reliably and which cannot. Based on the results of the simulation, the authors develop a model selection heuristic that identifies the correct market in 81% of the experimental conditions. In contrast, strict application of the best model selection criterion alone results in correct market identification in at most 34% of experimental conditions. Interestingly, we find that the amount of data (number of households or number of purchases per household) does not affect our ability to identify the correct market type with this heuristic, so there is a good chance of identifying the correct market type even when little data is available.
### Link:
- https://doi.org/10.1287/mnsc.1070.0749

## 9. Customer Lifetime Value Measurement
### Author(s):
- Sharad Borle
- Siddharth S. Singh
- Dipak C. Jain
### Published:
- 11 Dec 2007
### Abstract:
The measurement of customer lifetime value is important because it is used as a metric in evaluating decisions in the context of customer relationship management. For a firm, it is important to form some expectations as to the lifetime value of each customer at the time a customer starts doing business with the firm, and at each purchase by the customer. In this paper, we use a hierarchical Bayes approach to estimate the lifetime value of each customer at each purchase occasion by jointly modeling the purchase timing, purchase amount, and risk of defection from the firm for each customer. The data come from a membership-based direct marketing company where the times of each customer joining the membership and terminating it are known once these events happen. In addition, there is an uncertain relationship between customer lifetime and purchase behavior. Therefore, longer customer lifetime does not necessarily imply higher customer lifetime value.
### Link:
- https://doi.org/10.1287/mnsc.1070.0746

## 10. Cultivating Trust and Harvesting Value in Virtual Communities
### Author(s):
- Constance Elise Porter
- Naveen Donthu
### Published:
- 1 Jan 2008
### Abstract:
Although previous scholars have examined the value of virtual communities to customers, in this study we investigate the role of a firm's efforts in cultivating trust and harvesting value for themselves via the virtual communities that they sponsor. We hypothesize that the perceptions of a firm's efforts to provide quality content, to foster member embeddedness, and to encourage interaction foster favorable customer beliefs about and trust in a virtual community sponsor. Further, we hypothesize that trust motivates customers to behave relationally toward the sponsoring firm by sharing information with, coproducing new products with, and granting loyalty to, the sponsoring firm. Data from 663 customers are analyzed using structural equation modeling techniques. We find that efforts to provide quality content and foster member embeddedness have positive effects on customer beliefs about the sponsor. In fact, fostering member embeddedness has a stronger explanatory effect on customer beliefs than does providing quality content. However, despite the fact that previous studies show that customers value interaction in virtual communities, our findings suggest that firms must do more than encourage interaction among their community members if they hope to create value from their virtual communities.
### Link:
- https://doi.org/10.1287/mnsc.1070.0765

## 11. Building Brand Awareness in Dynamic Oligopoly Markets
### Author(s):
- Prasad A. Naik
- Ashutosh Prasad
- Suresh P. Sethi
### Published:
- 1 Jan 2008
### Abstract:
Companies spend hundreds of millions of dollars annually on advertising to build and maintain awareness for their brands in competitive markets. However, awareness formation models in the marketing literature ignore the role of competition. Consequently, we lack both the empirical knowledge and normative understanding of building brand awareness in dynamic oligopoly markets. To address this gap, we propose an N-brand awareness formation model, design an extended Kalman filter to estimate the proposed model using market data for five car brands over time, and derive the optimal closed-loop Nash equilibrium strategies for every brand. The empirical results furnish strong support for the proposed model in terms of both goodness-of-fit in the estimation sample and cross-validation in the out-of-sample data. In addition, the estimation method offers managers a systematic way to estimate ad effectiveness and forecast awareness levels for their particular brands as well as competitors' brands. Finally, the normative analysis reveals an inverse allocation principle that suggestscontrary to the proportional-to-sales or competitive parity heuristicsthat large (small) brands should invest in advertising proportionally less (more) than small (large) brands.
### Link:
- https://doi.org/10.1287/mnsc.1070.0755

## 12. Inventory Management with Auctions and Other Sales Channels: Optimality of (s, S) Policies
### Author(s):
- Woonghee Tim Huh
- Ganesh Janakiraman
### Published:
- 1 Jan 2008
### Abstract:
We study periodic-review inventory replenishment problems with fixed ordering costs, and show the optimality of (s, S) inventory replenishment policies. Inventory replenishment is instantaneous, i.e., the lead time is zero. We consider several sales mechanisms, e.g., auction mechanisms, name-your-own-price mechanisms, and multiple heterogeneous sales channels. We prove this result by showing that these models satisfy a recently-established sufficient condition for the optimality of (s, S) policies. Thus, this paper shows that the optimality of (s, S) policies extends well beyond the traditional sales environments studied so far in the inventory literature.
### Link:
- https://doi.org/10.1287/mnsc.1070.0767

## 13. Financing the Entrepreneurial Venture
### Author(s):
- Jean-Etienne de Bettignies
### Published:
- 1 Jan 2008
### Abstract:
We model financial contracting in entrepreneurial ventures. In our incomplete contracts framework, the entrepreneur can design contracts contingent on three possible control right allocations: entrepreneur control, investor control, and joint control, with each allocation inducing different effort levels by both the entrepreneur and the investor. We find that a variety of contracts resembling financial instruments commonly used in practice, such as common stock, straight and convertible preferred equity, and secured and unsecured debt, can emerge as optimal, depending on two key factors: entrepreneur/investor effort complementarity and investors' opportunity cost of capital. The results of our model are consistent with, and yield new explanations for, empirical regularities such as (a) the prevalence of equity-type contracts in high-growth ventures and of debt-type contracts in lifestyle ventures; (b) geographical and temporal differences in equity-type instruments used in high-growth ventures; and (c) the impact of firm and loan characteristics on the choice between secured and unsecured debt.
### Link:
- https://doi.org/10.1287/mnsc.1070.0759

## 14. Is the Tendency to Engage in Entrepreneurship Genetic?
### Author(s):
- Nicos Nicolaou
- Scott Shane
- Lynn Cherkas
- Janice Hunkin
- Tim D. Spector
### Published:
- 1 Jan 2008
### Abstract:
We used quantitative genetics techniques to compare the entrepreneurial activity of 870 pairs of monozygotic (MZ) and 857 pairs of same-sex dizygotic (DZ) twins from the United Kingdom. We ran model-fitting analyses to estimate the genetic, shared environmental and nonshared environmental effects on the propensity of people to become entrepreneurs. We found relatively high heritabilities for entrepreneurship across different operationalizations of the phenomenon, with little effect of family environment and upbringing. Our findings suggest the importance of considering genetic factors in explanations for why people engage in entrepreneurial activity.
### Link:
- https://doi.org/10.1287/mnsc.1070.0761

## 15. Code Reuse in Open Source Software
### Author(s):
- Stefan Haefliger
- Georg von Krogh
- Sebastian Spaeth
### Published:
- 9 Nov 2007
### Abstract:
Code reuse is a form of knowledge reuse in software development that is fundamental to innovation in many fields. However, to date there has been no systematic investigation of code reuse in open source software projects. This study uses quantitative and qualitative data gathered from a sample of six open source software projects to explore two sets of research questions derived from the literature on software reuse in firms and open source software development. We find that code reuse is extensive across the sample and that open source software developers, much like developers in firms, apply tools that lower their search costs for knowledge and code, assess the quality of software components, and have incentives to reuse code. Open source software developers reuse code because they want to integrate functionality quickly, because they want to write preferred code, because they operate under limited resources in terms of time and skills, and because they can mitigate development costs through code reuse.
### Link:
- https://doi.org/10.1287/mnsc.1070.0748

## 16. Maximum Commonality Problems: Applications and Analysis
### Author(s):
- Milind Dawande
- Subodha Kumar
- Vijay Mookerjee
- Chelliah Sriskandarajah
### Published:
- 1 Jan 2008
### Abstract:
Recently, an agile software development technique called extreme programming has caught the attention of practitioners and researchers in the software industry. A core practice of extreme programming is pair programming, where two developers work on the same piece of code. We introduce the problem of assigning pairs of developers to modules so as to maximize the commonalitya measure of the extent to which common developers work on related modulessubject to a load-balancing constraint that is motivated by the need to control the completion time of the project. We consider two variants of this problem. In MCAPn, a developer is teamed up with exactly one other developer to form a pair that works together for the entire duration of the project. In MCAPs, we allow a developer to pair with more than one other developer during the project. This pair-splitting version of the problem facilitates knowledge dissemination among developers, but can increase the effort needed for a developer to adjust to the work habits of several partners.
### Link:
- https://doi.org/10.1287/mnsc.1070.0766

## 17. Risk Aversion in Cumulative Prospect Theory
### Author(s):
- Ulrich Schmidt
- Horst Zank
### Published:
- 1 Jan 2008
### Abstract:
This paper characterizes the conditions for strong risk aversion and second-order stochastic dominance for cumulative prospect theory. Strong risk aversion implies a convex weighting function for gains and a concave one for losses. It does not necessarily imply a concave utility function. The latter does follow if the weighting functions are continuous. By investigating the exact relationship between loss aversion and strong risk aversion, a natural index for the degree of loss aversion is derived.
### Link:
- https://doi.org/10.1287/mnsc.1070.0762

## 18. Research NoteShould Consumers Use the Halo to Form Product Evaluations?
### Author(s):
- Peter Boatwright
- Ajay Kalra
- Wei Zhang
### Published:
- 1 Jan 2008
### Abstract:
In purchase situations where attribute information is either missing or difficult to judge, a well-known heuristic that consumers use to form evaluations is the halo effect. The psychology literature has widely considered the halo a reflection of consumers' inability to discriminate between different attributes and have therefore labeled it the halo error or the logical error. The objective of this paper is to offer a rationale for the halo effect. We use a decision-theory framework to show that the halo is consistent with the goal of minimizing estimation risk. Contrary to conventional wisdom, we demonstrate that a decision using the halo has lower estimation risk compared to not using the halo heuristic. Therefore, using the halo results in utility maximization and is indicative of rational behavior.
### Link:
- https://doi.org/10.1287/mnsc.1070.0742

## 19. Research NoteThe Impact of Information Technology Investments and Diversification Strategies on Firm Performance
### Author(s):
- Murali D. R. Chari
- Sarv Devaraj
- Parthiban David
### Published:
- 26 Nov 2007
### Abstract:
As companies continue to make large investments in information technology (IT), questions about how and in what contexts such investments pay off have gained importance. We develop a theoretical framework to explain how IT investments could pay off in the economically significant context of corporate diversification, and empirically find that the performance pay off to IT investments is greater for firms with greater levels of diversification. We also find that the performance payoff to IT investments is greater in related diversification than in unrelated diversification.
### Link:
- https://doi.org/10.1287/mnsc.1070.0743

## 20. ErratumThe Debate on Influencing Doctors' Decisions: Are Drug Characteristics the Missing Link?
### Author(s):
- Sriram Venkataraman
- Stefan Stremersch
### Published:
- 1 Jan 2008
### Abstract:
The affiliation of Stefan Stremersch was incorrectly set in Management Science, Vol. 53, No. 11, November 2007, pp. 16881701. The correct affiliation appears above and in the online version.
### Link:
- https://doi.org/10.1287/mnsc.1070.0853

