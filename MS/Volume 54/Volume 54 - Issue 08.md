# Volume 54, Issue 8
- August 2008
- Pages iv-1527
- David Simchi-Levi

## 1. Management Insights
### Author(s):
### Published:
- 1 Aug 2008
### Abstract:
None
### Link:
- https://doi.org/10.1287/mnsc.1080.0926

## 2. Modeling a Presidential Prediction Market
### Author(s):
- M. Keith Chen
- Jonathan E. Ingersoll, Jr.
- Edward H. Kaplan
### Published:
- 10 Jun 2008
### Abstract:
Prediction markets now cover many important political events. The 2004 presidential election featured an active online prediction market at Intrade.com, where securities addressing many different election-related outcomes were traded. Using the 2004 data from this market, we examined three alternative models for these security prices, with special focus on the electoral college rules that govern U.S. presidential elections to see which models are more (or less) consistent with the data. The data reveal dependencies in the evolution of the security prices across states over time. We show that a simple diffusion model provides a good description of the overall probability distribution of electoral college votes, and an even simpler ranking model provides excellent predictions of the probability of winning the presidency. Ignoring dependencies in the evolution of security prices across states leads to considerable underestimation of the variance of the number of electoral college votes received by a candidate, which in turn leads to overconfidence in predicting whether that candidate will win the election. Overall, the security prices in the Intrade presidential election prediction market appear jointly consistent with probability models that satisfy the rules of the electoral college.
### Link:
- https://doi.org/10.1287/mnsc.1080.0872

## 3. An Integrated Decision-Making Approach for Improving European Air Traffic Management
### Author(s):
- Yael Grushka-Cockayne
- Bert De Reyck
- Zeger Degraeve
### Published:
- 1 Aug 2008
### Abstract:
We develop a multistakeholder, multicriteria decision-making framework for Eurocontrol, the European air traffic management organization, for evaluating and selecting operational improvements to the air traffic management system. The selected set of improvements will form the master plan of the Single European Sky initiative for harmonizing air traffic, in an effort to cope with the forecasted increase in air traffic, while maintaining safety, protecting the environment, and improving predictability and efficiency. The challenge is to select the set of enhancements such that the required performance targets are met and all key stakeholders are committed to the decisions. In this paper, we develop and implement a model to identify a preferred set of improvements to the arrival and departure procedures to and from airports. We provide an integrated approach for valuing a large number of alternatives, while considering interactions among them. The model combines quantitative and qualitative expert assessments of the possible enhancements and identifies commonalities and differences in the stakeholders' perspectives, ultimately recommending a preferred course of action. The model is currently being adopted by Eurocontrol as the formal trade-off analysis methodology supporting all enhancements' decision-making discussions throughout the construction of the master plan.
### Link:
- https://doi.org/10.1287/mnsc.1080.0878

## 4. Dynamic Allocation of Airline Check-In Counters: A Queueing Optimization Approach
### Author(s):
- Mahmut Parlar
- Moosa Sharafali
### Published:
- 14 May 2008
### Abstract:
This paper was motivated by an observation in an international airport with regard to allocation of resources for check-in counters. In an exclusive check-in counter system, each flight has a dedicated number of counters that will be open until at least a half-hour before the scheduled departure of that flight. Currently, in many of the airports around the world, the decision to open or close check-in counters is done on an ad hoc basis by human schedulers. In doing so, the schedulers are almost always forced to perform a balancing act in meeting the quality of service stipulated by the airport authority vis--vis the optimal allocation of the resources to the counters. There appear to be very few academic and application papers in counter management, and most of those that have looked into this problem have resorted to simulation to study the queue characteristics. Ours is the first paper to show that for a specific flight, this complicated problem is amenable to analytical treatment. We first propose a multicounter queueing model with a special type of arrival process reflecting reality from the population of passengers booked for the flight. Most importantly, we derive the time-dependent operating characteristics to the queueing process under a specified time-window constraint. Then a stochastic dynamic programming model is formulated to determine the optimal numbers of counters to open over the time window specified. A numerical example is provided to illustrate the model solution and gain managerial insights.
### Link:
- https://doi.org/10.1287/mnsc.1070.0842

## 5. How Near-Misses Influence Decision Making Under Risk: A Missed Opportunity for Learning
### Author(s):
- Robin L. Dillon
- Catherine H. Tinsley
### Published:
- 10 Jun 2008
### Abstract:
Although organizations appear to learn from obvious failures, we argue that it is harder for them to learn from near-missesevents in which chance played a role in averting failure. In this paper, we formalize the concept of near-misses and hypothesize that organizations and managers fail to learn from near-misses because they evaluate such events as successes and thus feel safer about the situation. We distinguish perceived (felt) risk from calculated statistical risk and propose that lower levels of perceived risk encourage people with near-miss information to make riskier subsequent decisions compared to people without near-miss information. In our first study, we confirm the tendency to evaluate near-misses as successes by having participants rate a project manager whose decisions result in either (a) mission success, (b) near-miss, or (c) failure. Participants (both students and NASA employees and contractors) give similar ratings to managers whose decisions produced near-misses and to managers whose decisions resulted in successes, and both ratings are significantly different from ratings of managers who experienced failures. We suggest that the failure to hold managers accountable for near-misses is a foregone learning opportunity for both the manager and the organization. In our second set of studies, we confirm that near-miss information leads people to choose a riskier alternative because of a lower perceived risk following near-miss events. We explore several alternative explanations for these findings, including the role of Bayesian updating in processing near-miss data. Ultimately, the analysis suggests that managers and organizations are reducing their perception of the risk, although not necessarily updating (lowering) the statistical probability of the failure event. We speculate that this divergence arises because perceived risk is the product of associative processing, whereas statistical risk arises from rule-based processing.
### Link:
- https://doi.org/10.1287/mnsc.1080.0869

## 6. Managing the Inventory of an Item with a Replacement Warranty
### Author(s):
- Wei Huang
- Vidyadhar Kulkarni
- Jayashankar M. Swaminathan
### Published:
- 1 Aug 2008
### Abstract:
In this paper, we study a firm that faces demand from two sources: demand for new items and demand to replace failed items under warranty. We model this setting as a multiperiod single-product inventory problem where the demands for new items in different periods are independent and the demands for replacing failed items depend on the number and ages of the items under warranty. We consider backlogging and emergency supply cases, and study both discounted cost and average cost criteria. We prove the optimality of the w-dependent base-stock ordering policy where the base-stock level is a function of w, the vector representing the number of items at different ages currently under warranty. For the special case where the demand for new products is identically distributed, we prove the optimality of a stationary w-dependent base stock policy for the finite-horizon discounted and the infinite-horizon discounted and average cost cases. In our computational study, we find that an optimal w-dependent policy can lead to 69% average improvement in expected costs when compared to a policy that neglects demands from items under warranty.
### Link:
- https://doi.org/10.1287/mnsc.1080.0863

## 7. Inventory Models for Substitutable Products: Optimal Policies and Heuristics
### Author(s):
- Mahesh Nagarajan
- S. Rajagopalan
### Published:
- 1 Jul 2008
### Abstract:
In this paper, we examine the nature of optimal inventory policies in a system where a retailer manages substitutable products. We first consider a system with two products 1 and 2 whose total demand is D and individual demands are negatively correlated. A fixed proportion of the unsatisfied customers for an item will purchase the other item if it is available in inventory. For the single-period case, we show that the optimal inventory levels of the two items can be computed easily and follow what we refer to as partially decoupled policies, i.e., base stock policies that are not state dependent, in certain critical regions of interest both when D is known and random. Furthermore, we show that such a partially decoupled base-stock policy is optimal even in a multiperiod version of the problem for known D for a wide range of parameter values and in an N-product single-period model under some restrictive conditions. Using a numerical study, we show that heuristics based on the decoupled inventory policy perform well in conditions more general than the ones assumed to obtain the analytical results. The analytical and numerical results suggest that the approach presented here is most valuable in retail settings for product categories where the level of substitution between items in a category is not high, demand variation at the aggregate level is not high, and service levels or newsvendor ratios are high.
### Link:
- https://doi.org/10.1287/mnsc.1080.0871

## 8. Confidentiality and Information Sharing in Supply Chain Coordination
### Author(s):
- Lode Li
- Hongtao Zhang
### Published:
- 1 Aug 2008
### Abstract:
We consider information sharing in a decentralized supply chain where one manufacturer supplies to multiple retailers competing in price. Each retailer has some private information about the uncertain demand function which he may choose to disclose to the manufacturer. The manufacturer then sets a wholesale price based on the information received. The information exchange is said to be confidential if the manufacturer keeps the received information to herself, or nonconfidential if she discloses the information to some or all other retailers. Without confidentiality, information sharing is not possible because it benefits the manufacturer but hurts the retailers. With confidentiality, all parties have incentive to engage in information sharing if retail competition is intense. Under confidentiality, the retailers infer the shared information from the wholesale price and this gives rise to a signaling effect that makes the manufacturer's demand more price elastic, resulting in a lower equilibrium wholesale price and a higher supply chain profit. When all retailers share their information confidentially, they will truthfully report the information and the supply chain profit will achieve its maximum in equilibrium.
### Link:
- https://doi.org/10.1287/mnsc.1070.0851

## 9. A Bargaining Framework in Supply Chains: The Assembly Problem
### Author(s):
- Mahesh Nagarajan
- Yehuda Bassok
### Published:
- 1 Aug 2008
### Abstract:
We examine a decentralized supply chain in which a single assembler buys complementary components from n suppliers and assembles the final product in anticipation of demand. Players take actions in the following sequence. First (stage 1), the suppliers form coalitions among themselves. Second (stage 2), the coalitions compete for a position in the negotiation sequence. Finally (stage 3), the coalitions negotiate with the assembler on allocations of the supply chain's profit. We model the multilateral negotiations between the suppliers and the assembler sequentially, i.e., the assembler negotiates with one coalition at a time. Each of these negotiations is modeled using the Nash bargaining concept. Further, in forming coalitions we assume that players are farsighted. We then predict at equilibrium the structure of the supply chain as a function of the players' relative negotiation powers. In particular, we show that the assembler always prefers the outcome where suppliers do not form coalitions. However, when the assembler is weak (low negotiation power) the suppliers join forces as a grand coalition, but when the assembler is powerful the suppliers stay independent, which is the preferred outcome to the assembler.
### Link:
- https://doi.org/10.1287/mnsc.1080.0880

## 10. Queuing for Expert Services
### Author(s):
- Laurens G. Debo
- L. Beril Toktay
- Luk N. Van Wassenhove
### Published:
- 1 Aug 2008
### Abstract:
We consider a monopolist expert offering a service with a credence characteristic. A credence service is one in which the customer cannot verify, even after a purchase, whether or not the amount of prescribed service was appropriate; examples include legal, medical, or consultancy services, and car repair. This creates an incentive for the expert to induce service, that is, to provide unnecessary services that add no value to the customer, but that allow the expert to increase his revenues. We focus on the impact of an operations phenomenon on service inducementworkload dynamics due to the stochasticity of interarrival and service times. To this end, we model the expert's service operation as a single-server queue. The expert determines the service price within a fixed and variable fee structure and determines the service inducement strategy. We characterize the expert's combined optimal price structure and service inducement strategy as a function of service capacity, market potential, inducement opportunity, value of service and waiting cost. We find that service inducement is a means to dynamically skim customer surplus with state-independent prices and provision of slower service to customers that arrive when the expert is idle. We conclude with design implications of our results in limiting service inducement.
### Link:
- https://doi.org/10.1287/mnsc.1080.0867

## 11. Fluid Models for Overloaded Multiclass Many-Server Queueing Systems with First-Come, First-Served Routing
### Author(s):
- Rishi Talreja
- Ward Whitt
### Published:
- 20 Jun 2008
### Abstract:
Motivated by models of tenant assignment in public housing, we study approximating deterministic fluid models for overloaded queueing systems having multiple customer classes (classes of tenants) and multiple service pools (housing authorities), each with many servers (housing units). Customer abandonment acts to keep the system stable, yielding a proper steady-state description. Motivated by fairness considerations, we assume that customers are selected for service by newly available servers on a first-come, first-served (FCFS) basis from all classes the corresponding service pools are allowed to serve. In this context, it is challenging to determine stationary routing flow rates between customer classes and service pools. Given those routing flow rates, each single fluid queue can be analyzed separately using previously established methods. Our ability to determine the routing flow rates depends on the structure of the network routing graph. We obtain the desired routing flow rates in three cases: when the routing graph is (i) a tree (sparsely connected), (ii) complete bipartite (fully connected), and (iii) an appropriate combination of the previous two cases. Other cases remain unsolved. In the last two solved cases, the routing flow rates are actually not uniquely determined by the fluid model, but become so once we make stochastic assumptions about the queueing models that the fluid model approximates.
### Link:
- https://doi.org/10.1287/mnsc.1080.0868

