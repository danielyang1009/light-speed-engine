# Volume 46, Issue 02
- February 2000
- Pages 169-332
- David Simchi-Levi

## 1. How the Incumbent Can Win: Managing Technological Transitions in the Semiconductor Industry
### Author(s):
- Marco Iansiti
### Published:
- 1 Feb 2000
### Abstract:
The paper reports on an empirical study of the management of technological transitions. It focuses on project-level mechanisms for the generation of knowledge through experimentation and for its accumulation through individual experience. It proposes a model that links these mechanisms to effectiveness in the management of revolutionary and evolutionary development approaches. This argument is tested with data describing projects conducted by all major competitors in the semiconductor industry. Each project was aimed at a technological transition, defined as the introduction of a major new generation of process technology. The analysis shows substantial differences among competitors in the approach taken (i.e., evolutionary vs. revolutionary) and results achieved. Additionally, it shows that individual organizations can migrate, over time, from evolution to revolution and vice versa. The analysis further indicates that accumulating experience and generating knowledge through experimentation are significantly associated with project performance. While product performance improvement through revolution is associated with research experience and with parallel experimentation capacity, improvement through evolution is associated with project experience and minimum experimental iteration time.
### Link:
- https://doi.org/10.1287/mnsc.46.2.169.11922

## 2. A Theoretical Extension of the Technology Acceptance Model: Four Longitudinal Field Studies
### Author(s):
- Viswanath Venkatesh
- Fred D. Davis
### Published:
- 1 Feb 2000
### Abstract:
The present research develops and tests a theoretical extension of the Technology Acceptance Model (TAM) that explains perceived usefulness and usage intentions in terms of social influence and cognitive instrumental processes. The extended model, referred to as TAM2, was tested using longitudinal data collected regarding four different systems at four organizations (N = 156), two involving voluntary usage and two involving mandatory usage. Model constructs were measured at three points in time at each organization: preimplementation, one month postimplementation, and three months postimplementation. The extended model was strongly supported for all four organizations at all three points of measurement, accounting for 40%60% of the variance in usefulness perceptions and 34%52% of the variance in usage intentions. Both social influence processes (subjective norm, voluntariness, and image) and cognitive instrumental processes (job relevance, output quality, result demonstrability, and perceived ease of use) significantly influenced user acceptance. These findings advance theory and contribute to the foundation for future research aimed at improving our understanding of user adoption behavior.
### Link:
- https://doi.org/10.1287/mnsc.46.2.186.11926

## 3. Capital Budgeting, the Hold-up Problem, and Information System Design
### Author(s):
- Anil Arya
- John Fellingham
- Jonathan Glover
- K. Sivaramakrishnan
### Published:
- 1 Feb 2000
### Abstract:
In this article, we explore the connection between information system design and incentives for project search. The choice of an information system affects the level of managerial slack that is generated during project implementation. Whether slack is beneficial or costly to an organization has been the subject of debate. In our model of the hold-up problem in capital budgeting, there are both costs and benefits to having managerial slack. The cost of slack is the consumption of perquisites by the manager. The benefit of slack is that it can serve as a motivational tool. The possibility of increasing his slack may encourage a self-interested manager to conduct a more diligent search for a profitable project. To trade off the costs and benefits of slack in our model, an optimal information system sometimes incorporates coarse information, late information, and a mix of monitored and self-reported information. These features are familiar to accountants. Accounting incorporates both verified (monitored) and unverified (self-reported) information and provides information that is aggregated (coarse) and historical (late).
### Link:
- https://doi.org/10.1287/mnsc.46.2.205.11927

## 4. Stock Replenishment and Shipment Scheduling for Vendor-Managed Inventory Systems
### Author(s):
- Sila etinkaya
- Chung-Yee Lee
### Published:
- 1 Feb 2000
### Abstract:
Vendor-managed inventory (VMI) is a supply-chain initiative where the supplier is authorized to manage inventories of agreed-upon stock-keeping units at retail locations. The benefits of VMI are well recognized by successful retail businesses such as Wal-Mart. In VMI, distortion of demand information (known as bullwhip effect) transferred from the downstream supply-chain member (e.g., retailer) to the upstream member (e.g., supplier) is minimized, stockout situations are less frequent, and inventory-carrying costs are reduced. Furthermore, a VMI supplier has the liberty of controlling the downstream resupply decisions rather than filling orders as they are placed. Thus, the approach offers a framework for synchronizing inventory and transportation decisions.
### Link:
- https://doi.org/10.1287/mnsc.46.2.217.11923

## 5. On the Determination of Subjective Probability by Choices
### Author(s):
- Edi Karni
- Philippe Mongin
### Published:
- 1 Feb 2000
### Abstract:
The paper explores the uniqueness properties of the subjective probabilities in two axiomatizations of state-dependent preferences. Karni, Schmeidler, and Vind's (KSV 1983) system depends on selecting an arbitrary auxiliary probability, and as such, does not guarantee the uniqueness of the derived subjective probability. However, an axiom system initially designed by Karni and Schmeidler (KS 1981) and further elaborated upon here does guarantee the desired uniqueness as well as a useful property of stability of the derived solution. When the preference relation displays state-independence, even the KS probabilities may not agree with those derived from the classic Anscombe-Aumann (AA 1963) theorem. However, we claim that, in this case, the KS rather than the AA probabilities are the appropriate representation of the agent's beliefs.
### Link:
- https://doi.org/10.1287/mnsc.46.2.233.11929

## 6. Turning Datamining into a Management Science Tool: New Algorithms and Empirical Results
### Author(s):
- Lee G. Cooper
- Giovanni Giuffrida
### Published:
- 1 Feb 2000
### Abstract:
This article develops and illustrates a new knowledge discovery algorithm tailored to the action requirements of management science applications. The challenge is to develop tactical planning forecasts at the SKU level. We use a traditional market-response model to extract information from continuous variables and use datamining techniques on the residuals to extract information from the many-valued nominal variables, such as the manufacturer or merchandise category. This combination means that a more complete array of information can be used to develop tactical planning forecasts. The method is illustrated using records of the aggregate sales during promotion events conducted by a 95-store retail chain in a single trading area. In a longitudinal cross validation, the statistical forecast (PromoCast) predicted the exact number of cases of merchandise needed in 49% of the promotion events and was within  one case in 82% of the events. The dataminer developed rules from an independent sample of 1.6 million observations and applied these rules to almost 460,000 promotion events in the validation process. The dataminer had sufficient confidence to make recommendations on 46% of these forecasts. In 66% of those recommendations, the dataminer indicated that the forecast should not be changed. In 96% of those promotion events where no change was recommended, this was the correct action to take. Even including these no change recommendations, the dataminer decreased the case error by 9% across all promotion events in which rules applied.
### Link:
- https://doi.org/10.1287/mnsc.46.2.249.11932

## 7. Improving Manufacturing Performance Through Process Change and Knowledge Creation
### Author(s):
- Janice E. Carrillo
- Cheryl Gaimon
### Published:
- 1 Feb 2000
### Abstract:
A model is introduced to guide a profit maximizing firm in its quest to enhance performance through process change. The key benefit sought from process change is a long term increase in effective capacity. However, realizing success from process change is not trivial. First, while process change may increase effective capacity in the long run, the disruptions during implementation typically reduce short term capacity. Second, competitive forces such as decreasing revenue streams and shrinking product life cycles complicate the implementation of process change. Third, while knowledge may enhance the ultimate benefits derived from process change, the correct timing and means of knowledge creation are difficult to discern. Lastly, a variety of trade-offs must be evaluated when selecting the particular process change to pursue. For example, choices range from hardware and software replacements to modification of manufacturing procedures.
### Link:
- https://doi.org/10.1287/mnsc.46.2.265.11925

## 8. Third Degree Stochastic Dominance and Mean-Risk Analysis
### Author(s):
- Jun-ya Gotoh
- Hiroshi Konno
### Published:
- 1 Feb 2000
### Abstract:
In their recent article, Ogryczak and Ruszczyski (1999) proved that those portfolios associated with the efficient frontiers generated by mean-lower semi-standard deviation model and mean- (lower semi-)absolute deviation model are efficient in the sense of second degree stochastic dominance. This rather surprising result reveals the importance of lower partial risk models in portfolio analysis.
### Link:
- https://doi.org/10.1287/mnsc.46.2.289.11928

## 9. The Effects of Coefficient Correlation Structure in Two-Dimensional Knapsack Problems on Solution Procedure Performance
### Author(s):
- Raymond R. Hill
- Charles H. Reilly
### Published:
- 1 Feb 2000
### Abstract:
This paper presents the results of an empirical study of the effects of coefficient correlation structure and constraint slackness settings on the performance of solution procedures on synthetic two-dimensional knapsack problems (2KP). The population correlation structure among 2KP coefficients, the level of constraint slackness, and the type of correlation (product moment or rank) are varied in this study. Representative branch-and-bound and heuristic solution procedures are used to investigate the influence of these problem parameters on solution procedure performance. Population correlation structure, and in particular the interconstraint component of the correlation structure, is found to be a significant factor influencing the performance of both the algorithm and the heuristic. In addition, the interaction between constraint slackness and population correlation structure is found to influence solution procedure performance.
### Link:
- https://doi.org/10.1287/mnsc.46.2.302.11930

## 10. Improved Rolling Schedules for the Dynamic Single-Level Lot-Sizing Problem
### Author(s):
- Hartmut Stadtler
### Published:
- 1 Feb 2000
### Abstract:
A major argument for favoring simple lot-sizing heuristicslike the Silver/Meal or Groff's heuristicto solve instances of the dynamic single-level uncapacitated lot-sizing problem (SLLSP) instead of exact algorithmslike those of Wagner/Whitin or Federgruen/Tzuris that exact algorithms applied in a rolling horizon environment are heuristics too and may be outperformed by simple heuristics.
### Link:
- https://doi.org/10.1287/mnsc.46.2.318.11924

## 11. Technical Note: Mathematical Properties of the Optimal Product Line Selection Problem Using Choice-Based Conjoint Analysis
### Author(s):
- Kyle D. Chen
- Warren H. Hausman
### Published:
- 1 Feb 2000
### Abstract:
Selecting and pricing product lines is an essential activity in many businesses. In recent years, quantitative approaches for such tasks have been gaining in popularity. One often-employed method is to use data from traditional rankings/ratings-based conjoint analysis and attack the product line selection problem with enumeration or heuristics. In this note, we employ a relatively new methodology known as choice-based conjoint analysis (to model customer preferences) and investigate its mathematical properties when used to model the product line selection problem. Despite some inherent limitations resulting from its aggregated formulation, we show that this more parsimonious conjoint approach has some special mathematical properties that lead to an efficient optimal algorithm to tackle the product line/price selection problem. As a result, problems of realistic size can be solved efficiently using standard, commercially available mathematical programming codes.
### Link:
- https://doi.org/10.1287/mnsc.46.2.327.11931

