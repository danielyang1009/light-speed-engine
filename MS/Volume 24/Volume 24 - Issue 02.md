# Volume 24, Issue 02
- October 1977
- Pages 121-240
- David Simchi-Levi

## 1. A Composite Heterogeneous Model of Brand Choice and Purchase Timing Behavior
### Author(s):
- Fred S. Zufryden
### Published:
- 1 Oct 1977
### Abstract:
A stochastic model of purchase behavior is developed to aid marketing managers analyze and predict consumer purchase behavior. The model is based upon a composite structure, that is, it integrates several submodel components (e.g., brand choice and purchase incidence behavior) within its structure. Although the overall model is founded upon individual consumer behavior assumptions, it provides measures of market behavior by aggregating individual behavior parameters over a heterogeneous population of consumers. Thus, the model is developed from assumptions of relevant probability laws that relate to individual consumer's probability of brand choice and the time between product class purchases; as well as the distributions of brand choice probability and the average product class purchase rate of individuals over the population of consumers. The model provides aggregate market behavior measures including brand market share, expected brand sales and the distribution of brand purchase probability over the consumer population through time. Other measures of market behavior of potential use to marketing managers, such as the cumulative penetration, trial and repeat purchase ratio for a given brand, are also derived from the brand's aggregate theoretical purchase distribution.
### Link:
- https://doi.org/10.1287/mnsc.24.2.121

## 2. Managerial Differences in Assessing Probabilities of Technical Success for R&D Projects
### Author(s):
- Albert H. Rubenstein
- Hans-Horst Schrder
### Published:
- 1 Oct 1977
### Abstract:
Based on the notion that the process of assessing probabilities of technical success for R&D projects is composed of four phasesthe perception phase, the evaluation phase, the transformation phase, and the review phasethree types of variables are identified as accounting for individual differences in probability assessments: personal, organizational, and situational variables. The empirical findings about the impact of some selected variables on subjective probabilities are described and discussed for their relevance to the problem at hand. It is found that both an assessor's specific relations towards the project to be evaluated and his organizational rank may be of use in explaining individual differences in R&D probability assessments.
### Link:
- https://doi.org/10.1287/mnsc.24.2.137

## 3. Cost-Volume-Profit Analysis Adjusted for Learning
### Author(s):
- E. V. McIntyre
### Published:
- 1 Oct 1977
### Abstract:
A model is developed for cost-volume-profit analysis which incorporates a nonlinear cost function to express the effects of employee learning. Sensitivity analysis is applied to the model to assess the impact of estimation errors in the learning rate and steady-state production time on estimated profit and break-even quantities. The paper also examines the effects on the model of (1) alternative accounting treatments of production-related costs, and (2) continuous learning due to employee turnover.
### Link:
- https://doi.org/10.1287/mnsc.24.2.149

## 4. Workforce Scheduling with Cyclic Demands and Day-Off Constraints
### Author(s):
- Kenneth R. Baker
- Michael J. Magazine
### Published:
- 1 Oct 1977
### Abstract:
We examine the problem of scheduling days off in continuous (seven-day-a-week) operations under a variety of day-off policies, when demand for manpower is N on weekdays and n on weekend days. We consider a number of policies governing employee work assignments and in each case we give a formula for the minimum workforce size and a schedule construction algorithm.
### Link:
- https://doi.org/10.1287/mnsc.24.2.161

## 5. Queues with Instantaneous Feedback
### Author(s):
- Gilles R. D'Avignon
- Ralph L. Disney
### Published:
- 1 Oct 1977
### Abstract:
Queueing problems in which a customer having received a unit of service, returns to the waiting line, under some decision rule, to receive another unit of service occur often in applications. Inspection procedures provide such a framework for units that must be reworked. A large class of such problems appears in computer modelling under the name of round-robin models and foreground-background models. In the present paper, such a system is referred to as a queue with instantaneous feedback.
### Link:
- https://doi.org/10.1287/mnsc.24.2.168

## 6. Analysis of Simulation-Generated Responses using Autoregressive Models
### Author(s):
- D. A. Hsu
- J. S. Hunter
### Published:
- 1 Oct 1977
### Abstract:
Insights concerning a system are often provided by comparisons of historical versus simulated data. Such insights offer valuable assistance in the evolution of the simulation modeling process. In this article, a testing procedure is suggested for comparing historical time series records against responses generated by a simulation model. Time series models are identified and their parameters estimated for both the historical and simulated data using the techniques outlined by Box and Jenkins. The models are then tested for differences in their means, autoregressive parameters, and residual variances employing Bayesian arguments. The procedure suggested is emphasized as a diagnostic instrument useful for validation, and for suggesting iterative modifications of a simulation model. Applications of the procedure are illustrated by an example involving air traffic control communications.
### Link:
- https://doi.org/10.1287/mnsc.24.2.181

## 7. Successful Information System Development Projects
### Author(s):
- Bert Debrabander
- Anders Edstrm
### Published:
- 1 Oct 1977
### Abstract:
It is generally agreed between researchers and practitioners that user involvement is a key to the success of computer based information systems. This paper treats user involvement within the framework of a dyadic (two party) communication relationship between user and specialist. We add to previous work in three respects. First, the theoretical framework is enriched by specifying what we consider to be important contingency factors for the interaction between user and specialist. Second, a formal theory for predicting the success of information system development projects is developed. Third, one important managerial tool to establish effective user-specialist communication is suggested.
### Link:
- https://doi.org/10.1287/mnsc.24.2.191

## 8. Dynamic Programming Models of the Nonserial Critical Path-Cost Problem
### Author(s):
- Augustine O. Esogbue
- Barry R. Marks
### Published:
- 1 Oct 1977
### Abstract:
One of the major contributions to the planning and management of Research and Development organizations is the evolution of methods for dealing with PERT-Cost or CPM-Cost problems. Classically however, variations of the critical path-cost (CPM-Cost) problem, arising when different cost duration relationships are assumed, have been mostly studied via techniques other than dynamic programming. If the precedence relations possess a serial structure, one can develop two essentially equivalent dynamic programming formulations, of the resource allocation variety, by minimizing either the project cost or the completion time. When nonserial precedence relationships are involved, this problem cannot be solved by routine invocation of conventional dynamic programming formulations or algorithms. The intent of this paper is to show that efficient nonserial dynamic programming formulations can be developed for several complex nonserial CPM-Cost problem situations. In particular, the project time minimization procedure results in less complex dynamic programming models and is thus employed in this paper. Three recent computational reduction techniques based primarily on the introduction of the artifice of pseudo-tasks and pseudo-stages are invoked to treat different variations of this essentially nonserial critical path-cost problem. Considerable savings in computational requirements are achieved by consolidating all phases preceding a junction node prior to the invocation of the dynamic programming procedure. The advantages of these approaches over existing mathematical programming methods include their ability to handle nonlinear cost functions and constraints, as well as their highly efficient parametrization capabilities. Further, the complexity of the dynamic programming formulation does not, unlike other methods, increase with the number of phases (tasks) but only with the degree in which the additional tasks change the structure of the precedence relations.
### Link:
- https://doi.org/10.1287/mnsc.24.2.200

## 9. Means and Variances of Stochastic Vector Products with Applications to Random Linear Models
### Author(s):
- Gerald G. Brown
- Herbert C. Rutemiller
### Published:
- 1 Oct 1977
### Abstract:
Applications in operations research often employ models which contain linear functions. These linear functions may have some components (coefficients and variables) which are random. (For instance, linear functions in mathematical programming often represent models of processes which exhibit randomness in resource availability, consumption rates, and activity levels.) Even when the linearity assumptions of these models is unquestioned, the effects of the randomness in the functions is of concern. Methods to accomodate, or at least estimate for a linear function the implications of randomness in its components typically make several simplifying assumptions. Unfortunately, when components are known to be random in a general, multivariate dependent fashion, concise specification of the randomness exhibited by the linear function is, at best, extremely complicated, usually requiring severe, unrealistic restrictions on the density functions of the random components. Frequent stipulations include assertion of normality of independence-yet, observed data, accepted collateral theory and common sense may dictate that a symmetric distribution with infinite domain limits is inappropriate, or that a dependent structure is definitely present. (For example, random resource levels may be highly correlated due to economic conditions, and non-negative for physical reasons.) Often, an investigation is performed by discretizing the random components at point quantile levels, or by replacing the random components by their means-methods which give a deterministic equivalent model with constant terms, but possibly very misleading results. Outright simulation can be used, but requires considerable time investment for setup and debugging (especially for generation of dependent sequences of pseudorandom variates) and gives results with high parametric specificity and computation cost. This paper shows how to use elementary methods to estimate the mean and variance of a linear function with arbitrary multivanate randomness in its components. Expressions are given for the mean and variance and are used to make Tchebycheff-type probability statements which can accomodate and exploit stochastic dependence. Simple estimation examples are given which lead to illustrative applications with (dependent-) stochastic programming models.
### Link:
- https://doi.org/10.1287/mnsc.24.2.210

## 10. Maximum Throughput in Finite-Capacity Open Queueing Networks with Product-Form Solutions
### Author(s):
- Paul J. Schweitzer
### Published:
- 1 Oct 1977
### Abstract:
A finite-capacity open queueing network with independent balance is considered. These are systems with customers undergoing stages of service, where the rate of flow into a state due to a customer entering a stage of service is equal to the flow out of that state due to a customer leaving that stage of service. Such systems have the convenient property that the steady-state probability of a given configuration of customers factors into a product of terms, each term involving the configuration at one service center. If service rates are constant for each customer class, and excess arrivals are discarded, then the following two results hold: (1) The maximum possible output rate for the finite-capacity case equals the value of the customer arrival rate which just saturates the slowest server in the infinite-capacity case. (2) An infinite-capacity network can have a strictly greater output rate than the corresponding finite-capacity network, no matter how large the capacity.
### Link:
- https://doi.org/10.1287/mnsc.24.2.217

## 11. Probabilistic Weights in the One-Dimensional Facility Location Problem
### Author(s):
- George O. Wesolowsky
### Published:
- 1 Oct 1977
### Abstract:
This note deals with the one-dimensional facility location model in which the weights, which can represent either demand volumes or demands and costs combined, are known only probabilistically. The demand points themselves, or at least the feeder routes to the demand points, for the facility are located on a straight line which represents a road or some other transportation route. It is assumed that the weights of the demand points have a multivariate normal distribution. The probability of the facility being optimally located at any point on the route is derived; it is shown that only the demand points have non-zero probabilities. In addition, the expected value of perfect information (EVPI) is found. In this problem, the EVPI is the expected difference in costs between the actual best location and the optimum location obtained by using expected weights. The EVPI, therefore, is the maximum amount the decision maker should pay for information about weights if expected values are acceptable as a decision criterion.
### Link:
- https://doi.org/10.1287/mnsc.24.2.224

## 12. Minimising the Maximum Penalty in the Two-Machine Flow Shop
### Author(s):
- W. Townsend
### Published:
- 1 Oct 1977
### Abstract:
It is shown how Lawler's procedure for the one-machine case can be combined with Johnson's rule to produce a branch-and-bound algorithm for the two-machine version.
### Link:
- https://doi.org/10.1287/mnsc.24.2.230

## 13. NoteA Note on Comparison of Computer Algorithms and Visual Based Methods for Plant Layout by M. Scriabin and R. C. Vergin
### Author(s):
- T. E. Block
### Published:
- 1 Oct 1977
### Abstract:
This note recommends the use of flow dominance as a measure to determine the choice between computer algorithms and visual based methods for plant layout. It is suggested that plant layout problems with flow dominance close to or greater than 200% should be solved by visual based methods rather than computer algorithms. For the plant layout problems used by Scriabin and Vergin with a flow dominance greater than 200% visual based methods are superior to computer algorithms. It is shown by an experiment that for plant layout problems with a flow dominance less than 200% computer algorithms are superior to visual based methods.
### Link:
- https://doi.org/10.1287/mnsc.24.2.235

## 14. Linear Multiparametric Programming by Multicriteria Simplex Method: Errata
### Author(s):
- P. L. Yu
- Milan Zeleny
### Published:
- 1 Oct 1977
### Abstract:
Corrections to the authors' paper Linear Multiparametric Programming by Multicriteria Simplex Method, Management Science, Vol. 23, No. 2, October 1976, pp. 159170.
### Link:
- https://doi.org/10.1287/mnsc.24.2.238

## 15. Notes About Authors
### Author(s):
### Published:
- 1 Oct 1977
### Abstract:
None
### Link:
- https://doi.org/10.1287/mnsc.24.2.239

