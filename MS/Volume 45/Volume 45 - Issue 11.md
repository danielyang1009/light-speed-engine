# Volume 45, Issue 11
- November 1999
- Pages 1463-1611
- David Simchi-Levi

## 1. The Internalization of Exports: Firm- and Location-Specific Factors in a Middle-Income Country
### Author(s):
- Jos Campa
- Mauro F. Guilln
### Published:
- 1 Nov 1999
### Abstract:
Firms make strategic choices about foreign market access on the basis of location factors in the home and export countries, as well as on their ownership advantages. The empirical analysis is based on a sample of 837 manufacturing companies in a typical middle-income country (Spain), in which firms are starting to internationalize through investments or alliances in distribution. Following theoretical expectations, the greater the level of such ownership factors as intangible technological assets, product variability, and resource availability, the higher the likelihood of internalization, and in particular internalization by proprietary distribution instead of by commercial alliance. But most importantly, location factors in the home country and in the export market have an independent effect on the likelihood and mode of internalization. Proprietary distribution channels are preferred when the firm's competitors are based in richer countries than the home country, and when the export market is well known to the firm.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1463

## 2. Simulating Project Work Processes and Organizations: Toward a Micro-Contingency Theory of Organizational Design
### Author(s):
- Raymond E. Levitt
- Jan Thomsen
- Tore R. Christiansen
- John C. Kunz
- Yan Jin
- Clifford Nass
### Published:
- 1 Nov 1999
### Abstract:
The Virtual Design Team (VDT) extends and operationalizes Galbraith's (1973) information-processing view of organizations. VDT simulates the micro-level information processing, communication, and coordination behavior of participants in a project organization and predicts several measures of participant and project-level performance. VDT-1 (Cohen 1991) and VDT-2 (Christiansen 1993) modeled project organizations containing actors with perfectly congruent goals engaged in complex but routine engineering design work within static organization structures. VDT-3 extends the VDT-2 work process representation to include measures of activity flexibility, complexity, uncertainty, and interdependence strength. It explicitly models the effects of goal incongruency between agents on their information processing and communication behavior while executing more flexible tasks. These extensions allow VDT to model more flexible organizations executing less routine work processes. VDT thus bridges rigorously between cognitive and social psychological micro-organization theory and sociological and economic macro-organization theory for project teams. VDT-3 has been used to model and simulate the design of two major subsystems of a complex satellite launch vehicle. This case study provides initial evidence that the micro-contingency theory embodied in VDT-3 can be used to predict organizational breakdowns, and to evaluate alternative organizational changes to mitigate identified risks. VDT thus supports true organizational engineering for project teams.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1479

## 3. On the Relationship Between Inventory Costs and Variety Benefits in Retail Assortments
### Author(s):
- Garrett van Ryzin
- Siddharth Mahajan
### Published:
- 1 Nov 1999
### Abstract:
Consider a category of product variants distinguished by some attribute such as color or flavor. A retailer must construct an assortment for the category, i.e., select a subset variants to stock and determine purchase quantities for each offered variant. We analyze this problem using a multinomial logit model to describe the consumer choice process and a newsboy model to represent the retailer's inventory cost. We show that the optimal assortment has a simple structure and provide insights on how various factors affect the optimal level of assortment variety. We also develop a formal definition of the level of fashion in a category using the theory of majorization and examine its implications for category profits.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1496

## 4. A Periodic Review Inventory Model with Demand Influenced by Promotion Decisions
### Author(s):
- Feng Cheng
- Suresh P. Sethi
### Published:
- 1 Nov 1999
### Abstract:
In this paper, we use a Markov decision process (MDP) to model the joint inventory-promotion decision problem. The state variable of the MDP represents the demand state brought about by changing environmental factors as well as promotion decisions. The demand state in a period determines the distribution of the random demand in that period. Optimal inventory and promotion decision policies in the finite horizon problem are obtained via dynamic programming. Under certain conditions, we show that there is a threshold inventory level P for each demand state such that if the threshold is exceeded, then it is desirable to promote the product. For the proportional ordering cost case, the optimal inventory replenishment policy is a base-stock type policy with the optimal base-stock level dependent on the promotion decision.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1510

## 5. The Use of a Neural Factory to Investigate the Effect of Product Line Width on Manufacturing Performance
### Author(s):
- Paul M. Swamidass
- Satish S. Nair
- Sanjay I. Mistry
### Published:
- 1 Nov 1999
### Abstract:
The dual goals of this study are: (1) to develop an empirically valid neural model of U.S. factories in a range of industries producing discrete products, and (2) to use the model to test the effect of changes in product line width on plant performance variables. Accordingly, a neural factory was developed using 59 input and 5 output/performance variables, and was trained using field data collected from 385 U.S. manufacturing plants. The model was validated using a holdout sample before conducting sensitivity tests. The study demonstrates that, through the use of parametric sensitivity analysis, the neural factory could be used to investigate the relationship between inputs and performance of a factory.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1524

## 6. The Data-Correcting Algorithm for the Minimization of Supermodular Functions
### Author(s):
- Boris Goldengorin
- Gerard Sierksma
- Gert A. Tijssen
- Michael Tso
### Published:
- 1 Nov 1999
### Abstract:
The Data-Correcting (DC) Algorithm is a recursive branch-and-bound type algorithm, in which the data of a given problem instance are heuristically corrected at each branching in such a way that the new instance will be as close as possible to polynomially solvable and the result satisfies a prescribed accuracy (the difference between optimal and current solution). In this paper the DC algorithm is applied to determining exact or approximate global minima of supermodular functions. The working of the algorithm is illustrated by an instance of the Simple Plant Location (SPL) Problem. Computational results, obtained for the Quadratic Cost Partition Problem (QCP), show that the DC algorithm outperforms a branch-and-cut algorithm, not only for sparse graphs but also for nonsparse graphs (with density more than 40%), often with speeds 100 times faster.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1539

## 7. A Comparison of Graphical Techniques for Asymmetric Decision Problems
### Author(s):
- Concha Bielza
- Prakash P. Shenoy
### Published:
- 1 Nov 1999
### Abstract:
We compare four graphical techniques for representation and solution of asymmetric decision problemsdecision trees, influence diagrams, valuation networks, and sequential decision diagrams. We solve a modified version of Covaliu and Oliver's Reactor problem using each of the four techniques. For each technique, we highlight the strengths, weaknesses, and some open issues that perhaps can be resolved with further research.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1552

## 8. Simulation-Based Optimization with Stochastic Approximation Using Common Random Numbers
### Author(s):
- Nathan L. Kleinman
- James C. Spall
- Daniel Q. Naiman
### Published:
- 1 Nov 1999
### Abstract:
The method of Common Random Numbers is a technique used to reduce the variance of difference estimates in simulation optimization problems. These differences are commonly used to estimate gradients of objective functions as part of the process of determining optimal values for parameters of a simulated system. Asymptotic results exist which show that using the Common Random Numbers method in the iterative Finite Difference Stochastic Approximation optimization algorithm (FDSA) can increase the optimal rate of convergence of the algorithm from the typical rate of k1/3 to the faster k1/2, where k is the algorithm's iteration number. Simultaneous Perturbation Stochastic Approximation (SPSA) is a newer and often much more efficient optimization algorithm, and we will show that this algorithm, too, converges faster when the Common Random Numbers method is used. We will also provide multivariate asymptotic covariance matrices for both the SPSA and FDSA errors.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1570

## 9. Partitioning Customers into Service Groups
### Author(s):
- Ward Whitt
### Published:
- 1 Nov 1999
### Abstract:
We explore the issues of when and how to partition arriving customers into service groups that will be served separately, in a first-come first-served manner, by multiserver service systems having a provision for waiting, and how to assign an appropriate number of servers to each group. We assume that customers can be classified upon arrival, so that different service groups can have different service-time distributions. We provide methodology for quantifying the tradeoff between economies of scale associated with larger systems and the benefit of having customers with shorter service times separated from other customers with longer service times, as is done in service systems with express lines. To properly quantify this tradeoff, it is important to characterize service-time distributions beyond their means. In particular, it is important to also determine the variance of the service-time distribution of each service group. Assuming Poisson arrival processes, we then can model the congestion experienced by each server group as an M/G/squeue with unlimited waiting room. We use previously developed approximations for M/G/sperformance measures to quickly evaluate alternative partitions.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1579

## 10. DEA Duality on Returns to Scale (RTS) in Production and Cost Analyses: An Occurrence of Multiple Solutions and Differences Between Production-Based and Cost-Based RTS Estimates
### Author(s):
- Toshiyuki Sueyoshi
### Published:
- 1 Nov 1999
### Abstract:
This article discusses the concept of RTS (Returns To Scale) in the framework of DEA (Data Envelopment Analysis) production and cost analyses, focusing on an occurrence of multiple solutions and how to deal with such a difficulty. Dual relationships between production-based and cost-based RTS estimates are also theoretically discussed in this study.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1593

## 11. The Many-Player Advertising Game
### Author(s):
- Gila E. Fruchter
### Published:
- 1 Nov 1999
### Abstract:
This study extends the time-variant closed-loop strategy of Fruchter and Kalish (1997) to the n-player advertising game. We demonstrate that solving an n-player game using 2 players results in overadvertising.
### Link:
- https://doi.org/10.1287/mnsc.45.11.1609

