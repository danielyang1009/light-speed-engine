# Volume 45, Issue 12
- December 1999
- Pages 1613-1727
- David Simchi-Levi

## 1. Bundling Information Goods: Pricing, Profits, and Efficiency
### Author(s):
- Yannis Bakos
- Erik Brynjolfsson
### Published:
- 1 Dec 1999
### Abstract:
We study the strategy of bundling a large number of information goods, such as those increasingly available on the Internet, and selling them for a fixed price. We analyze the optimal bundling strategies for a multiproduct monopolist, and we find that bundling very large numbers of unrelated information goods can be surprisingly profitable. The reason is that the law of large numbers makes it much easier to predict consumers' valuations for a bundle of goods than their valuations for the individual goods when sold separately. As a result, this predictive value of bundling makes it possible to achieve greater sales, greater economic efficiency, and greater profits per good from a bundle of information goods than can be attained when the same goods are sold separately. Our main results do not extend to most physical goods, as the marginal costs of production for goods not used by the buyer typically negate any benefits from the predictive value of large-scale bundling.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1613

## 2. Price Versus Production Postponement: Capacity and Competition
### Author(s):
- Jan A. Van Mieghem
- Maqbool Dada
### Published:
- 1 Dec 1999
### Abstract:
This article presents a comparative analysis of possible postponement strategies in a two-stage decision model where firms make three decisions: capacity investment, production (inventory) quantity, and price. Typically, investments are made while the demand curve is uncertain. The strategies differ in the timing of the operational decisions relative to the realization of uncertainty.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1631

## 3. Optimal Pricing Strategy for New Products
### Author(s):
- Trichy V. Krishnan
- Frank M. Bass
- Dipak C. Jain
### Published:
- 1 Dec 1999
### Abstract:
Robinson and Lakhani (1975) initiated a long research stream in marketing when they used the Bass model (1969) to develop optimal pricing path for a new product. A careful analysis of the extant literature reveals that the research predominantly suggests that the optimal price path should be largely based on the sales growth pattern. However, in the real world we rarely find new products that have such pricing pattern. We observe either a monotonically declining pricing pattern or an increase-decrease pricing pattern that does not seem close to the sales path. In this paper, we use a variation of the generalized Bass model (called GBM) developed by Bass et al. (1994) that yields optimal pricing policies that are consistent with empirical data.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1650

## 4. The Effects of Low Inventory on the Development of Productivity Norms
### Author(s):
- Kenneth L. Schultz
- David C. Juran
- John W. Boudreau
### Published:
- 1 Dec 1999
### Abstract:
Low inventory, a crucial part of just-in-time (JIT) manufacturing systems, enjoys increasing application worldwide, yet the behavioral effects of such systems remain largely unexplored. Operations research (OR) models of low-inventory systems typically use a simplifying assumption that processing times of individual workers are independent random variables. This leads to predictions that low-inventory systems will exhibit production interruptions leading to lower productivity. Yet empirical results suggest that low-inventory systems do not exhibit the predicted productivity losses. This paper develops a model integrating feedback, goal setting, group cohesiveness, task norms, and peer pressure to predict how individual behavior may adjust to alleviate production interruptions in low-inventory systems. In doing so we integrate previous research on the development of task norms. Operations research models are used to show how norms can significantly improve throughput by decreasing variance and increasing the speed of the slowest workers, even if accompanied by decreases in speed of the fastest workers. Findings suggest that low-inventory systems induce individual and group responses that cause behavioral changes that mitigate production interruptions.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1664

## 5. 94%-Effective Policies for a Two-Stage Serial Inventory System with Stochastic Demand
### Author(s):
- Fangruo Chen
### Published:
- 1 Dec 1999
### Abstract:
A two-stage inventory system is considered where Poisson demand occurs at Stage 1, and Stage 1 replenishes its inventory from Stage 2, which in turn orders from an outside supplier with unlimited stock. Each shipment, either to Stage 2 or to Stage 1, incurs a fixed setup cost. Under the assumption that the supply leadtime at Stage 2 is zero, we characterize a simple heuristic policy whose long-run average cost is guaranteed to be within 6% of optimality, i.e., a 94%-effective policy. The paper also provides heuristic policies for more general inventory systems and reports computational results.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1679

## 6. Generating Pareto Solutions in a Two-Party Setting: Constraint Proposal Methods
### Author(s):
- Harri Ehtamo
- Raimo P. Hmlinen
- Pirja Heiskanen
- Jeffrey Teich
- Markku Verkama
- Stanley Zionts
### Published:
- 1 Dec 1999
### Abstract:
This paper presents a class of methods, called constraint proposal methods, for generating Pareto-optimal solutions in two-party negotiations. In these methods joint tangents of the decision makers' value functions are searched by adjusting an artificial plane constraint. The problem of generating Pareto-optimal solutions decomposes into ordinary multiple criteria decision-making problems for the individual decision makers and into a coordination problem for an assisting mediator. Depending on the numerical iteration scheme used to solve the coordination problem, different constraint proposal methods are obtained. We analyze and illustrate the behaviour of some iteration schemes by numerical examples using both precise and imprecise answers from decision makers. An example of a method belonging to the class under study is the RAMONA method, that has been previously described from a practical point of view. We present the underlying theory for it by describing it as a constraint proposal method, and include some applications.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1697

## 7. Disclosure Detection in Multivariate Categorical Databases: Auditing Confidentiality Protection Through Two New Matrix Operators
### Author(s):
- Sumit Dutta Chowdhury
- George T. Duncan
- Ramayya Krishnan
- Stephen F. Roehrig
- Sumitra Mukherjee
### Published:
- 1 Dec 1999
### Abstract:
As databases grow more prevalent and comprehensive, database administrators seek to limit disclosure of confidential information while still providing access to data. Practical databases accommodate users with heterogeneous needs for access. Each class of data user is accorded access to only certain views. Other views are considered confidential, and hence to be protected. Using illustrations from health care and education, this article addresses inferential disclosure of confidential views in multidimensional categorical databases. It demonstrates that any structural, so data-value-independent method for detecting disclosure can fail. Consistent with previous work for two-way tables, it presents a data-value-dependent method to obtain tight lower and upper bounds for confidential data values. For two-dimensional projections of categorical databases, it exploits the network structure of a linear programming (LP) formulation to develop two transportation flow algorithms that are both computationally efficient and insightful. These algorithms can be easily implemented through two new matrix operators, cell-maxima and cell-minima. Collectively, this method is called matrix comparative assignment (MCA). Finally, it extends both the LP and MCA approaches to inferential disclosure when accessible views have been masked.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1710

## 8. A Note on Asset Proportions, Stochastic Dominance, and the 50% Rule
### Author(s):
- Ephraim Clark
- Octave Jokung
### Published:
- 1 Dec 1999
### Abstract:
In this note we analyze the composition of an optimal portfolio by considering the cumulative conditional expected outcome of two dependent assets. We develop a conditional stochastic dominance relation and show that for any concave von Neumann-Morgenstern utility function, the proportion of wealth invested in the dominant asset will be greater than 50%.
### Link:
- https://doi.org/10.1287/mnsc.45.12.1724

