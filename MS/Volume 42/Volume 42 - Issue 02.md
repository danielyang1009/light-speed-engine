# Volume 42, Issue 02
- February 1996
- Pages 157-306
- David Simchi-Levi

## 1. Consumer Heterogeneity and Strategic Quality Decisions
### Author(s):
- Byong-Duk Rhee
### Published:
- 1 Feb 1996
### Abstract:
Though recent studies show that quality differentiation is an equilibrium outcome, products of similar qualities frequently are observed in the marketplace. This inconsistency may be explained by incorporating consumer heterogeneity along unobservable attributes into a model of competition. In this paper, consumers not only take into account the quality and price of a product but also their heterogeneous tastes along other attributes which are unobservable to firms. We investigate the effect of heterogeneity along the unobservable attributes on both quality and price equilibrium in a two-stage game framework. We show that when consumers are sufficiently heterogeneous along the unobservable attributes, the firms offer products of identical qualities in equilibrium. Under low levels of heterogeneity along the unobservable attributes, however, our results are consistent with past research which argues for quality differentiation.
### Link:
- https://doi.org/10.1287/mnsc.42.2.157

## 2. New Product Development: The Performance and Time-to-Market Tradeoff
### Author(s):
- Morris A. Cohen
- Jehoshua Eliasberg
- Teck-Hua Ho
### Published:
- 1 Feb 1996
### Abstract:
Reduction of new product development cycle time and improvements in product performance have become strategic objectives for many technology-driven firms. These goals may conflict, however, and firms must explicitly consider the tradeoff between them. In this paper we introduce a multistage model of new product development process which captures this tradeoff explicitly. We show that if product improvements are additive (over stages), it is optimal to allocate maximal time to the most productive development stage. We then indicate how optimal time-to-market and its implied product performance targets vary with exogenous factors such as the size of the potential market, the presence of existing and new products, profit margins, the length of the window of opportunity, the firm's speed of product improvement, and competitor product performance. We show that some new product development metrics employed in practice, such as minimizing break-even time, can be sub-optimal if firms are striving to maximize profits. We also determine the minimal speed of product improvement required for profitably undertaking new product development, and discuss the implications of product replacement which can occur whenever firms introduce successive generations of new products. Finally, we show that an improvement in the speed of product development does not necessarily lead to an earlier time-to-market, but always leads to enhanced products.
### Link:
- https://doi.org/10.1287/mnsc.42.2.173

## 3. Designs for Environmental Scanning Systems: Tests of a Contingency Theory
### Author(s):
- Masoud Yasai-Ardekani
- Paul C. Nystrom
### Published:
- 1 Feb 1996
### Abstract:
This study compared the relationships between organizational context and the designs of environmental scanning systems for organizational with effective and ineffective scanning systems. The study analyzed data from over 100 North American business organizations. Results indicate that organizations with effective scanning systems tend to align their scanning designs with the requirements of their context. On the other hand, the results show that organizations with ineffective scanning systems typically fail to exhibit the requisite level of alignment between contexts and scanning design.
### Link:
- https://doi.org/10.1287/mnsc.42.2.187

## 4. Indicators of Ill-Conditioned Data Sets and Model Misspecification in Data Envelopment Analysis: An Extended Facet Approach
### Author(s):
- O. B. Olesen
- N. C. Petersen
### Published:
- 1 Feb 1996
### Abstract:
Date Envelopment Analysis (DEA) employs mathematical programming to measure the relative efficiency of Decision Making Units (DMUs). This paper is concerned with development of indicators to determine whether or not the specification of the input and output space is supported by data in the sense that the variation in data is sufficient for estimation of a frontier of the same dimension as the input output space. Insufficient variation in data implies that some inputs/outputs can be substituted along the efficient frontier but only in fixed proportions. Data thus locally supports variation in a subspace of a lower dimension rather than in the input output space of full dimension. Each segment of the efficient frontier is in this sense subject to local collinearity. Insufficient variation in data provides a bound on admissible disaggregations in cases where substitution in fixed proportions is incompatible with a priori information concerning the production process. A data set incapable of estimating a frontier of full dimension will in this case be denoted ill-conditioned. It is shown that the existence of well-defined marginal rates of substitution along the estimated strongly efficient frontier segments requires the existence of Full Dimensional Efficient Facets (FDEFs). A test for the existence of FDEFs is developed, and an operational two-stage procedure for efficiency evaluation relative to an over-all non-fixed technology is developed; the two-stage procedure provides a lower and an upper bound on the efficiency index for each DMU.
### Link:
- https://doi.org/10.1287/mnsc.42.2.205

## 5. Selling Procedures with Private Information and Common Values
### Author(s):
- John H. Lindsey, II
- William Samuelson
- Richard Zeckhauser
### Published:
- 1 Feb 1996
### Abstract:
The seller posted-price procedure is probably the most common method for making transactions in modern economies. We analyze the performance of posted pricing for transactions having significant common-value elements. In a model of two-sided private information, we characterize the fully revealing, perfect equilibrium offer strategy of the seller. We also characterize equilibrium behavior under two other pricing proceduresa sealed-bid procedure and a direct revelation mechanism. Finally, we examine the efficiency of these procedures and show that as the degree of common values increases, fewer mutually beneficial agreements are attained.
### Link:
- https://doi.org/10.1287/mnsc.42.2.220

## 6. Resolving the Process vs. Product Innovation Dilemma: A Consumer Choice Theoretic Approach
### Author(s):
- Sriraman Bhoovaraghavan
- Ashok Vasudevan
- Rajan Chandran
### Published:
- 1 Feb 1996
### Abstract:
There has been considerable emphasis on the strategic importance of process and product innovation in the management literature. What actually constitutes process and product innovation, however, is a confused issue in the current literature. Are product and process innovations separate, or are they on a continuum? The importance of addressing this issue is that research over the past few decades has attributed Japan's increasing competitiveness to its propensity to process innovate. This paper uses a consumer-based approach to distinguish between process and product innovation using a model based on choice theory. An empirical illustration of the model is also presented. The model is then used to emphasize the need to pursue an integrated strategy of process and product innovation in response to consumer wants. The model also helps managers decide on the appropriate mix of process innovation relative to product innovation for R&D resource allocation purposes.
### Link:
- https://doi.org/10.1287/mnsc.42.2.232

## 7. Joint Cost Allocation for Multiple Lots
### Author(s):
- Bala V. Balachandran
- Ram T. S. Ramakrishnan
### Published:
- 1 Feb 1996
### Abstract:
We consider the joint cost allocation problem that arises when several lots or resources are available to serve different products or divisions. We provide a two-phase model, wherein the first phase the optimal set of lots to be acquired is chosen and given the optimal set, and the products using each acquired lot is also determined. In the second phase, a stable full cost allocation method is developed that will not induce the divisions to form coalitions to reduce the allocated joint costs. Utilizing the optimal dual solution of the lot selection phase, we provide a joint cost allocation mechanism based on the concept of propensity to contribute and show that this allocation is also stable. If in the first phase there is a dual gap, then we show that there is no cost allocation in the core. A numerical illustration is provided.
### Link:
- https://doi.org/10.1287/mnsc.42.2.247

## 8. Setting Base Stock Levels Using Product-Form Queueing Networks
### Author(s):
- Rodrigo Rubio
- Lawrence M. Wein
### Published:
- 1 Feb 1996
### Abstract:
A manufacturing facility produces multiple products in a make-to-stock manner, and unsatisfied demand is backordered. A simple production control policy is analyzed: When the amount of work-in-process inventory plus finished goods inventory for a particular product falls below a base stock level, then release another unit of that product onto the shop floor. Assuming that the work-in-process inventory has a steady state distribution and that there are different costs incurred for carrying in-process, completed and backordered units, we show that the cost minimizing base stock level for each product is a critical fractile of the steady state distribution of the product's total work-in-process inventory. By exploiting the relationship between the make-to-stock system and an open queueing network, we identify specific formulas for the base stock levels under standard product-form assumptions. For the lost sales case, a similar relation to a closed queueing network can be used to characterize the optimal control parameters.
### Link:
- https://doi.org/10.1287/mnsc.42.2.259

## 9. Estimating Security Price Derivatives Using Simulation
### Author(s):
- Mark Broadie
- Paul Glasserman
### Published:
- 1 Feb 1996
### Abstract:
Simulation has proved to be a valuable tool for estimating security prices for which simple closed form solutions do not exist. In this paper we present two direct methods, a pathwise method and a likelihood ratio method, for estimating derivatives of security prices using simulation. With the direct methods, the information from a single simulation can be used to estimate multiple derivatives along with a security's price. The main advantage of the direct methods over resimulation is increased computational speed. Another advantage is that the direct methods give unbiased estimates of derivatives, whereas the estimates obtained by resimulation are biased. Computational results are given for both direct methods, and comparisons are made to the standard method of resimulation to estimate derivatives. The methods are illustrated for a path independent model (European options), a path dependent model (Asian options), and a model with multiple state variables (options with stochastic volatility).
### Link:
- https://doi.org/10.1287/mnsc.42.2.269

## 10. Some Results in the CAPM with Nontraded Endowments
### Author(s):
- Gyutaeg Oh
### Published:
- 1 Feb 1996
### Abstract:
The paper establishes a positive security market line in the CAPM with nontraded endowments. The effects of a market structure change on the security market line are analyzed when the equilibrium allocation is affected by the change.
### Link:
- https://doi.org/10.1287/mnsc.42.2.286

## 11. A Game Theoretic Approach to Problems in Telecommunication
### Author(s):
- A. van den Nouweland
- P. Borm
- W. van Golstein Brouwers
- R. Groot Bruinderink
- S. Tijs
### Published:
- 1 Feb 1996
### Abstract:
This paper considers two specific problems in telecommunication, namely the Terrestrial Flight Telephone System and the rerouting of international telephone calls. Both situations are modelled as coalitional games, and game theoretic techniques are used to tackle the problems. It is shown that a special class of coalitional games emerges from the situations under consideration and that the structure of the situations has theoretical implications, including the coincidence of several game theoretic solution concepts. The implications of these theoretical results for the two practical problems are discussed.
### Link:
- https://doi.org/10.1287/mnsc.42.2.294

## 12. Note: Microcomputer Performance of OptPack on Hoffmann's Data Sets: Comparison with Eureka and FABLE
### Author(s):
- Francis J. Nourie
- Enrique R. Venta
### Published:
- 1 Feb 1996
### Abstract:
OptPack (Nourie and Venta [Nourie, Francis J., E. R. Venta. 1991. Finding optimal line balances with OptPack. Oper. Res. Letters10(April) 165171.]) was published between the publication times of FABLE and EUREKA. This communication reports microcomputer computational experience with OptPack on Hoffmann's data sets following the pattern of Johnson (Johnson, Roger V. 1993a. Microcomputer performance of FABLE on Hoffmann's data sets. Management Sci.39(10) 11901192.). Some insights about the computational effectiveness of the algorithms and some additional difficult problems are also presented.
### Link:
- https://doi.org/10.1287/mnsc.42.2.304

