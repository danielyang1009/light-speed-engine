# Volume 42, Issue 01
- January 1996
- Pages 1-156
- David Simchi-Levi

## 1. A Multiechelon Inventory Model with Fixed Replenishment Intervals
### Author(s):
- Stephen C. Graves
### Published:
- 1 Jan 1996
### Abstract:
This paper develops a new model for studying multiechelon inventory systems with stochastic demand. For the model we assume that each site in the system orders at preset times according to an order-up-to policy, that delivery times are deterministic, and that the demand processes are stochastic with independent increments. We introduce a new scheme for allocating stock in short supply, which we call virtual allocation and which permits significant tractability. We exercise the model on a set of test problems for two-echelon systems to get insight into the structure of good policies. The primary findings are that both the central warehouse (upper echelon) and the retail sites (lower echelon) should hold safety stock, but that most of the safety stock should be at the retail sites. Consequently, the central warehouse will stock out with high probability. Furthermore, we show that the virtual allocation rule is near optimal for the set of test problems.
### Link:
- https://doi.org/10.1287/mnsc.42.1.1

## 2. Lot Sizing in Serial Assembly Systems with Multiple Constrained Resources
### Author(s):
- Terry P. Harrison
- Holly S. Lewis
### Published:
- 1 Jan 1996
### Abstract:
We present a heuristic for lot sizing in serial assembly systems with multiple contrained resources. This procedure, the Coefficient Modification Heuristic (CMH), exploits a special problem structure by solving repetitively a small linear programming restriction of the original problem. The key idea is to modify the constraint coefficients of certain variables in the LP restriction to implicitly account for the capacity consumed in setups.
### Link:
- https://doi.org/10.1287/mnsc.42.1.19

## 3. Decision Roll and Horizon Roll Processes in Infinite Horizon Discounted Markov Decision Processes
### Author(s):
- D. J. White
### Published:
- 1 Jan 1996
### Abstract:
In this paper we look at some aspects of infinite horizon Markov decision processes in which information regarding parameter values is restricted to a finite time horizon, and in which decisions are based upon the finite horizon data but are recomputed as we move forward in time and gain knowledge of later parametric values. A general framework is given. Bounds on the loss of optimality arising from two planning horizon decision processes are given, and the choice of decision process and planning horizon is examined.
### Link:
- https://doi.org/10.1287/mnsc.42.1.37

## 4. A Psychological Approach to Decision Support Systems
### Author(s):
- Stephen J. Hoch
- David A. Schkade
### Published:
- 1 Jan 1996
### Abstract:
Rapid advances in information technology have brought decision makers the mixed blessing of an increasingly vast amount of easily available data. Designers of decision support systems (DSS) have focused on incorporating the latest technology with little attention to whether these new systems are compatible with the psychology of decision makers. Our premise is that DSS should be designed to take advantage of the distinctive competencies of decision makers while using technology to compensate for their inherent weaknesses. In this study we apply this approach to a forecasting task. We find that to arrive at a forecast decision makers often search their experience for a situation similar to the one at hand and then make small adjustments to this previous situation. Our theoretical model of the performance of this intuitively appealing strategy shows that it performs reasonably well in highly predictable environments, but performs quite poorly in less predictable environments. Results from an experiment confirm these predictions and show that providing decision makers with a simple linear model in combination with a computerized database of historical cases improves performance significantly. We conclude by discussing how these results can be used to help improve forecasting in applied contexts, such as promotion forecasting in the retail grocery industry.
### Link:
- https://doi.org/10.1287/mnsc.42.1.51

## 5. A Theory of Cutoff Formation Under Imperfect Information
### Author(s):
- Fred M. Feinberg
- Joel Huber
### Published:
- 1 Jan 1996
### Abstract:
Numerous models in the Management Science literature contain constructions that are a variant of the following: A decision-maker must choose from a set of alternatives based on imperfect information as to their relative quality, while further evaluation, through costly, provides more accurate information. We examine decision heuristics in which the optimal search policy entails a screening strategy limiting the number of alternatives in the subsequent, costly evaluation. There are two general methods for accomplishing this screening: Quota cutoffs operate by selecting the optimal number of alternatives to evaluate; Level cutoffs operate by specifying a minimally-acceptable level of the imperfect screening indicator. The present paper has three main objectives. First, to define the Level and Quota cutoff methods, broadly characterize optimal behavior for each and determine what aspects of the decision environment of order statistics as a methodology for exploring decision problems when information is imperfectly known; and third, to discuss the pivotal role of default, or fallback, options in a broad class of search problems.
### Link:
- https://doi.org/10.1287/mnsc.42.1.65

## 6. Empirical Evaluation of the Revised Technology Acceptance Model
### Author(s):
- Bernadette Szajna
### Published:
- 1 Jan 1996
### Abstract:
Davis et al. (Davis, F. D., R. P. Bagozzi, P. R. Warshaw. 1989. User acceptance of computer technology: A comparison of two theoretical models. Management Sci.35(8) 9821003.) proposed, tested, and revised the Technology Acceptance Model (TAM), which attempts to explain and predict why users sometimes accept and sometimes reject information systems (IS). The research reported here (1) provides a confirmatory, empirical test of the revised TAM and (2) introduces and objective measure of technology acceptance, actual usage rather than self-report usage. Subjects' beliefs about the usefulness and ease of use of an electronic mail system, their intentions to use the system, and their usage of it 15 weeks later were measured in a longitudinal study. The results confirmed that the TAM is a valuable tool for predicting intentions to use an IS. The findings here combined with results from other studies in this area suggest that the original TAM may be more appropriate than the two-version revised TAM. However, the addition of an experience component to the original TAM may be a significant enhancement. In addition, the results support that self-report usage may not be an appropriate surrogate measure for actual usage.
### Link:
- https://doi.org/10.1287/mnsc.42.1.85

## 7. Performance Verifiability and Output Sharing in Collaborative Ventures
### Author(s):
- Tailan Chi
### Published:
- 1 Jan 1996
### Abstract:
This paper studies the problem of contracting between two firms when they try to exploit their complementary resources in a collaborative venture (CV), but their performance in the CV cannot be precisely verified by the other party or by a third-party arbiter. Using a mathematical model that treats performance verifiability as a continuous variable, the paper first establishes that a party whose performance cannot be perfectly verified has an incentive to shirk if it is paid only a flat fee and that this shirking problem is more severe as its performance is less verifiable. Then, the paper shows in a general setting that a contract under which each party shares a fraction of the output is superior to a contract under which one of them is paid only a flat fee when performance verifiability is sufficiently low. In addition, with some specific assumptions about the forms of the revenue and cost functions, the paper also shows that a partys share of the ventures residual output in the equilibrium is an increasing function of its productivity and a decreasing function of its opportunity cost. Finally, the numerical examples constructed in the paper suggest that a contract which combines the self-enforcing mechanism of output sharing with the third-party enforcement mechanism of arbitration generally performs better than a contract that utilizes only one of these mechanisms.
### Link:
- https://doi.org/10.1287/mnsc.42.1.93

## 8. Hospital Ownership and Technical Inefficiency
### Author(s):
- James F. Burgess, Jr.
- Paul W. Wilson
### Published:
- 1 Jan 1996
### Abstract:
The theoretical industrial organization literature cites varying factors which might influence the degree of technical efficiency achieved under different ownership structures in the US hospital industry. Unfortunately, this literature offers no consensus regarding the net direction and magnitude of these various effects. This study analyzes the four types of ownership structure in the US hospital industryprivate nonprofit, private for-profit, federal, and state and local government. Distance functions are used to measure technical efficiency of hospitals producing multiple outputs relative to other hospitals in the sample, allowing comparisons among the different ownership types.
### Link:
- https://doi.org/10.1287/mnsc.42.1.110

## 9. The Nonstationary Stochastic Lead-Time Inventory Problem: Near-Myopic Bounds, Heuristics, and Testing
### Author(s):
- Ravi Anupindi
- Thomas E. Morton
- David Pentico
### Published:
- 1 Jan 1996
### Abstract:
The purpose of the current paper is to combine the classical results of Kaplan (Kaplan, R. 1970. Dynamic inventory model with stochastic lead times. Management Sci.16(2) 491507.) and Ehrhardt (Ehrhardt, R. 1984. (s, S) Policies for a dynamic inventory model with stochastic lead times. Oper. Res.32(1) 121132.) for stochastic leadtime problems with recent work of Morton and Pentico (Morton, T., D. Pentico. 1995. The finite horizon nonstationary stochastic inventory problem near-myopic bounds, heuristics, testing. Management Sci.41(2) 334343.), which assumed zero lag, to obtain near-myopic bounds and heuristics for the nonstationary stochastic leadtime problem with arbitrary sequences of demand distributions, and to obtain planning horizon results. Four heuristics have been tested on a number of different demand scenarios over a number of random trials for four different leadtime distributions. The myopic (simplest) heuristic performs well only for moderately varying problems without heavy end of season salvaging, giving errors for this type of problem that are less than 1.5%. However, the average error for the myopic heuristic over all scenarios tested is 20.0%. The most accurate heuristic is the near-myopic heuristic which averages 0.5% form optimal across all leadtime distributions with a maximum error of 4.7%. The average error with increases in variance of the leadtime distribution.
### Link:
- https://doi.org/10.1287/mnsc.42.1.124

## 10. Periodic Review Production Models with Variable Capacity, Random Yield, and Uncertain Demand
### Author(s):
- Yunzeng Wang
- Yigal Gerchak
### Published:
- 1 Jan 1996
### Abstract:
We investigate a production planning problem in a periodic review environment with variable production capacity, random yields, and uncertain demand. The implications of random yields and variable capacity for lot sizing previously have been explored separately, but not jointly. Many production environments are likely to be subject to both types of uncertainties. To minimize the total discounted expected costs (production, holding, and shortage costs), we formulate the problem as a stochastic dynamic program. For the finite-horizon problem, we prove that the objective function is quasi-convex and that the structure of the optimal policy is characterized by a single critical point for the initial stock level at each period. That is, if the initial stock is greater than this critical point, the optimal planned production is zero; otherwise, it is greater than zero. Expressions for solving the critical point and the optimal planned production are obtained. We further show that the solution for the finite-horizon problem converges to that of the infinite-horizon problem.
### Link:
- https://doi.org/10.1287/mnsc.42.1.130

## 11. A Note on Testing for Skewness Persistence
### Author(s):
- Ravinder Nath
### Published:
- 1 Jan 1996
### Abstract:
This paper shows that the tests of skewness persistence considered by Muralidhar (Muralidhar, K. 1993. The bootstrap approach for testing skewness persistence. Management Sci.39 487491.) far exceed the true Type I error. That is, the probabilities of detecting an increase (decrease) in skewness from one time period to another when in fact there is no change are inflated. Consequently, higher power achieved by these tests comes at the cost of a higher than specified level of Type I error. We propose a new test which maintains the specified Type I error levels. Additionally, the power of this test for lognormal distributions is reported.
### Link:
- https://doi.org/10.1287/mnsc.42.1.138

## 12. An O(T3) Algorithm for the Economic Lot-Sizing Problem with Constant Capacities
### Author(s):
- C. P. M. van Hoesel
- A. P. M. Wagelmans
### Published:
- 1 Jan 1996
### Abstract:
We develop an algorithm that solves the constant capacities economic lot-sizing problem with concave production costs and linear holding in O(T3) time. The algorithm is based on the standard dynamic programming approach which requires the computation of the minimal costs for all possible subplans of the production plan. Instead of computing these costs in a straightforward manner, we use structural properties of optimal subplans to arrive at a more efficient implementation. Our algorithm improves upon the O(T4) running time of an earlier algorithm.
### Link:
- https://doi.org/10.1287/mnsc.42.1.142

## 13. A Note on Strategic Sampling in Agencies
### Author(s):
- Robert Bushman
- Chandra Kanodia
### Published:
- 1 Jan 1996
### Abstract:
This paper studies sample design for process control in principal-agent settings where deterrence rather than ex post detection is the main issue. We show how the magnitude of gains from additional sampling can be calculated and traded off against sampling costs. It is shown that the optimal sample size shrinks as target rates are lowered.
### Link:
- https://doi.org/10.1287/mnsc.42.1.151

