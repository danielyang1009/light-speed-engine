# Volume 42, Issue 04
- April 1996
- Pages 475-627
- David Simchi-Levi

## 1. A Scaled Stochastic Approximation Algorithm
### Author(s):
- Sigrn Andradttir
### Published:
- 1 Apr 1996
### Abstract:
Consider a stochastic system of such complexity that its performance can only be evaluated by using simulation or direct experimentation. To optimize the expected performance of such systems as a function of several continuous input parameters (decision variables), we present a scaled stochastic approximation algorithm for finding the zero (root) of the gradient of the response function. In each iteration of the scaled algorithm, two independent gradient estimates are sampled at the current estimate of the optimal input-parameter vector to compute a scale-free estimate of the next search direction. We establish sufficient conditions to ensure strong consistency and asymptotic normality of the resulting estimator of the optimal input-parameter vector. Strong consistency is also established for a variant of the scaled algorithm with Kesten's acceleration. An experimental performance comparison of the scaled algorithm and the classical Robbins-Monro algorithm in two simple queueing systems reveals some of the practical advantages of the scaled algorithm.
### Link:
- https://doi.org/10.1287/mnsc.42.4.475

## 2. Procedural Justice and Managers' In-Role and Extra-Role Behavior: The Case of the Multinational
### Author(s):
- W. Chan Kim
- Rene A. Mauborgne
### Published:
- 1 Apr 1996
### Abstract:
Existing procedural justice studies to date offer only pieces of the picture on how procedural justice judgments affect behavior. Besides, these studies have been conducted primarily in the legal context. This paper develops a comprehensive picture of how procedural justice affects managers' in-role and extra-role behavior in the business context. It does so by examining the direct and indirect effects of procedural justice judgments on the in-role and extra-role behavior of multinationals' subsidiary top management in the context of the global resource allocation decision process. Especially, this paper advances and tests a theory which predicts that the attitude of commitment to support decisions provides a bridge between procedural justice and extra-role behavior. Based on an analysis of 119 subsidiary top managers, we offer evidence in support of this theory. Besides its contribution to the procedural justice literature, our study also sheds light on one of the most pressing issues outstanding in the field of international management: how multinationals can motivate subsidiary top managers to implement their global resource allocation decisions. The results suggest that the exercise of procedural justice inspires managers to go beyond the call of duty and engage in innovative actions, spontaneous cooperation, and creative behavior on behalf of the organization in their execution of decisions.
### Link:
- https://doi.org/10.1287/mnsc.42.4.499

## 3. Aggregation Error in Bayesian Analysis of Reliability Systems
### Author(s):
- M. Naceur Azaiez
- Vicki M. Bier
### Published:
- 1 Apr 1996
### Abstract:
Perfect aggregation in Bayesian system reliability analysis has been shown to be extremely unlikely. In other words, aggregation error is almost inevitable. Consequently, analysts have to deal with the following dilemma: on one hand, an aggregate analysis (i.e., an analysis at the system level), while relatively inexpensive, may be misleading. On the other hand, a disaggregate analysis (i.e., at the component level) provides more accurate results, but may be costly and impractical. Therefore, simple techniques to estimate the size of aggregation error are necessary to help analysts choose the most appropriate level of detail for an analysis. In this paper, reasonable bounds on the aggregation error are derived for a variety of reliability models. In particular, these bounds will never be more than twice the actual error. Tools to compute these bounds (and in some cases the actual error) are also provided.
### Link:
- https://doi.org/10.1287/mnsc.42.4.516

## 4. Combining Buy-In Penalties with Commissions at Auction Houses
### Author(s):
- Eric A. Greenleaf
- Atanu R. Sinha
### Published:
- 1 Apr 1996
### Abstract:
Most auction sellers consign property to auction houses rather than holding the auction themselves. In addition to charging sellers a commission on property that sells in the auction, many auction houses also specify buy-in penalties in auction contracts. This is an amount the seller must pay the auction house if the property fails to sell at auction. An important managerial question for auction houses is whether and when buy-in penalties can increase revenues of the auction house, seller, or both, and what combinations of commission and buy-in penalty to use. We show that auctions which combine buy-in penalties with lower commissions Pareto-dominate auctions that use only commissions. This strategy motivates the seller to set a lower reserve, which creates a surplus in auction revenues that can go to one or both parties. This strategy is Pareto-dominant even if the auction house and the seller are uncertain about the number of bidders at the auction, or the auction house is uncertain about the seller's own valuation for the property, at the time the buy-in penalty, commission, and reserve are contractually set. We also discuss the incentive issues raised by this strategy.
### Link:
- https://doi.org/10.1287/mnsc.42.4.529

## 5. Paradox Lost? Firm-Level Evidence on the Returns to Information Systems Spending
### Author(s):
- Erik Brynjolfsson
- Lorin Hitt
### Published:
- 1 Apr 1996
### Abstract:
The productivity paradox of information systems (IS) is that, despite enormous improvements in the underlying technology, the benefits of IS spending have not been found in aggregate output statistics. One explanation is that IS spending may lead to increases in product quality or variety which tend to be overlooked in the aggregate statistics, even if they increase output at the firm-level. Furthermore, the restructuring and cost-cutting that are often necessary to realize the potential benefits of IS have only recently been undertaken in many firms.
### Link:
- https://doi.org/10.1287/mnsc.42.4.541

## 6. Initial Data Truncation for Univariate Output of Discrete-Event Simulations Using the Kalman Filter
### Author(s):
- Mark A. Gallagher
- Kenneth W. Bauer, Jr.
- Peter S. Maybeck
### Published:
- 1 Apr 1996
### Abstract:
Data truncation is a commonly accepted method of dealing with initialization bias in discrete-event simulation. An algorithm for determining the appropriate initial-data truncation point for univariate output is proposed. The technique entails averaging across independent replications and estimating a steady-state output model in a state-space framework. A Bayesian technique called Multiple Model Adaptive Estimation (MMAE) is applied to compute a time varying estimate of the output's steady-state mean. This MMAE implementation features the use, in parallel, of a bank of three Kalman filters. Each filter is constructed under a different assumption about the output's steady-state mean. One of the filters assumes that the steady-state mean is accurately reflected by an estimate, called the assumed steady-state mean, taken from the last half of the simulation data. This filter is called the reference filter. The remaining filters are calibrated with steady-state means corresponding to simple functions of the minimum and maximum data values, respectively. As the filters process the output through the effective transient, the reference filter becomes more likely (in a Bayesian sense) to be the best filter to represent the data, and the MMAE mean estimator is influenced increasingly towards the assumed steady-state mean. The estimated truncation point is selected when the MMAE mean estimate is within a small tolerance of the assumed steady-state mean.
### Link:
- https://doi.org/10.1287/mnsc.42.4.559

## 7. A Queuing Network Model of a Single-Operator Manufacturing Workcell with Machine/Operator Interference
### Author(s):
- Paul Desruelle
- Harold J. Steudel
### Published:
- 1 Apr 1996
### Abstract:
We present an analytical approach to evaluate the performance of a manufacturing workcell tended by a single operator when operator-induced machine interference occurs. Each part must be processed at every workstation in the workcell. The fact that one or more machines can request an operator service while the operator is busy at another machine induces machine interference. If the reduction of the workcell's capacity due to this interference becomes too great, then the customer demand may not be satisfied. Our approach determines quickly whether the workcell can meet a required demand under its current configuration and operating parameters. We do this by modeling the workcell as two interacting queuing networks: an open part/machine network, and a closed machine/operator network. In the open network, parts arrive in batches of a fixed size for each part type, but with exponentially distributed interarrival times between parts. In both networks, service times follow general distributions that are characterized by their first two moments.
### Link:
- https://doi.org/10.1287/mnsc.42.4.576

## 8. Optimal Shift Scheduling with Multiple Break Windows
### Author(s):
- Turgut Aykin
### Published:
- 1 Apr 1996
### Abstract:
This paper presents a new integer programming model for optimal shift scheduling with multiple rest and lunch breaks, and break windows. A set-covering approach for this problem was originally developed by Dantzig (1954). Since then, a number of set-covering-based formulations have been proposed in the literature. These formulations require an integer variable for every shift type, shift start time, and rest/lunch break placement combination. Unfortunately, the number of integer variables required is rather large, making them impractical to solve for an optimal solution in most applications. We present a new approach in which a set of break variables is introduced for every shift-break type combination to determine the break placements. This approach leads to a significantly improved integer programming model requiring substantially smaller number of variables and computer memory. We tested the proposed approach with 40 test problems involving between 1,728 and 8,640 shift variations, and five demand patterns. Our results showed that the proposed formulation is very useful in solving large shift scheduling problems optimally.
### Link:
- https://doi.org/10.1287/mnsc.42.4.591

## 9. A Stochastic Optimization Model to Improve Production Planning and R&D Resource Allocation in Biopharmaceutical Production Processes
### Author(s):
- Robert L. Schmidt
### Published:
- 1 Apr 1996
### Abstract:
The increasing cost of health care has brought pressure to reduce pharmaceutical costs, and because manufacturing and R&D are significant cost factors, these areas have been targeted as potential sources of cost reduction. Manufacturing costs are particularly high in the biotechnology industry because process technologies are relatively new. Contamination, genetic instability, and other factors complicate production planning and make bioprocess systems unreliable. This paper presents a Markov decision process model that combines features of engineering design models and aggregate production planning models to obtain a hybrid model that links biological and engineering parameters to optimize operations performance. Using tissue plasminogen activator as a specific example, the paper shows how the hybrid modeling approach not only improves production planning, but also provides accurate information on the operating performance of bioprocesses that can be used to predict the financial impact of process changes. Therefore, the model can be used to guide investments in manufacturing process improvement and R&D (e.g., genetic modifications). Although stochastic production models are not commonly used in process design, this paper shows how a combined engineering/production model can facilitate a concurrent design approach to reduce cost in bioprocess development.
### Link:
- https://doi.org/10.1287/mnsc.42.4.603

## 10. On the Advantage of Being the First Server
### Author(s):
- Refael Hassin
### Published:
- 1 Apr 1996
### Abstract:
The following example illustrates the problem treated in this paper: Two gas stations are located one after the other on a main road. A driver who needs to fill his rank sees the queue situation at the first station but not at the second one. The driver estimates the expected waiting time at the first station, compares it to the conditional expected waiting time at the second one, and decides which station to enter. The second station is assumed to be on the driver's route so that no extra cost is involved in choosing it. Is it true that the first station always gets a higher share of the demand than the second one? We model the situation in terms of queueing theory and answer the question.
### Link:
- https://doi.org/10.1287/mnsc.42.4.618

## 11. Maximising a Function Over a Finite Set of ActionsTechnical Note
### Author(s):
- D. J. White
### Published:
- 1 Apr 1996
### Abstract:
In this technical note we examine a method of extending a problem over a finite set of actions, to a problem of maximising a function over a bi-product set. The solution set is characterised in terms of fixed point solutions and partial solutions, and two improvement algorithms are given.
### Link:
- https://doi.org/10.1287/mnsc.42.4.624

