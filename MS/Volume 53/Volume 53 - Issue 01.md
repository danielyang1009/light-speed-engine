# Volume 53, Issue 1
- January 2007
- Pages iv-168
- David Simchi-Levi

## 1. Management Insights
### Author(s):
### Published:
- 1 Jan 2007
### Abstract:
None
### Link:
- https://doi.org/10.1287/mnsc.1070.0698

## 2. Past Success and Creativity over Time: A Study of Inventors in the Hard Disk Drive Industry
### Author(s):
- Pino G. Audia
- Jack A. Goncalo
### Published:
- 1 Jan 2007
### Abstract:
We integrate psychological theories of individual creativity with organizational theories of exploration versus exploitation to examine the relationship between past success and creativity over time. A key prediction derived from this theoretical integration is that successful people should be more likely to generate new ideas, but these ideas will tend to be less divergent as they favor the exploitation of familiar knowledge at the expense of the exploration of new domains. This prediction departs from the often-held view that people who generate more ideas will also generate ideas that are more divergent. Analyses of patenting in the hard disk drive industry support our prediction and indicate that collaboration with other inventors and organizational norms for exploration attenuate the tendency for successful individuals to generate increasingly incremental ideas.
### Link:
- https://doi.org/10.1287/mnsc.1060.0593

## 3. Vicarious Learning in New Product Introductions in the Early Years of a Converging Market
### Author(s):
- Raji Srinivasan
- Pamela Haunschild
- Rajdeep Grewal
### Published:
- 1 Jan 2007
### Abstract:
Technological developments combine previously distinct technologies that result in converging markets. In converging markets, firms from different industries compete against each other, often for the first time. We propose that firms introducing new products in converging markets will learn vicariously from other firms in the market. Further, we propose that this learning will vary across the dual-technology frontier (DTF), where the high-technology frontier (HTF) and low-technology frontier (LTF) map onto innovative activities driven by technological opportunity and user needs. We propose that at the HTF, local search will dominate and firms will be influenced by HTF product introductions of similarly sized, successful firms. At the LTF, learning will occur across the DTF, vary by origin industry of the firm, and be affected by complementarities in routines and capabilities and market competition among firms. We test the proposed model of vicarious learning using panel data on new product introductions of 67 firms in the U.S. digital camera market in the 1990s. Findings generally support our proposed model of vicarious learning in this market. They show heterogeneity in vicarious learning across the technology frontier and firm characteristicsincluding the origin industry of target firms. Our results show that vicarious learning in new product introductions in converging marketswhich includes both mimetic and nonmimetic learningis similar in some ways, but different from more traditional markets. We conclude with a discussion of the implications of our findings for theories of organizational learning, new product development, and converging markets.
### Link:
- https://doi.org/10.1287/mnsc.1060.0608

## 4. Stable Farsighted Coalitions in Competitive Markets
### Author(s):
- Mahesh Nagarajan
- Greys Soi
### Published:
- 1 Jan 2007
### Abstract:
In this paper, we study dynamic alliance formation among agents in competitive markets. We look at n agents selling substitutable products competing in a market. In this setting, we examine models with deterministic and stochastic demand, and we use a two-stage approach. In Stage 1, agents form alliances (coalitions), and in Stage 2, coalitions make decisions (price and inventory) and compete against one another. To analyze the stability of coalition structures in Stage 1, we use two notions from cooperative gamesthe largest consistent set (LCS) and the equilibrium process of coalition formation (EPCF)which allow players to be farsighted. Thus, in forming alliances, players consider two key phenomena: First, players trade off the size of the total profit of the system versus their allocation of this total pie, and second, they weigh the possibility that an immediate beneficial defection can trigger further counter defections that in the end may prove to be worse than the status quo. In particular, one such example is that of the grand coalitionwhich we show to be stable in the farsighted senseeven though players benefit myopically by defecting from it. We also provide conditions under which a situation of a few lone players competing against a large coalition is stable. We examine the impact of the size of the market (n), the degree of competition, the effect of cost parameters, and the variability of the demand process on the prices, inventory levels, and structure of the market. We discuss the possible strategic implications of our results to firms in a competitive market and for new entrants.
### Link:
- https://doi.org/10.1287/mnsc.1060.0605

## 5. Optimal Advertising and Promotion Budgets in Dynamic Markets with Brand Equity as a Mediating Variable
### Author(s):
- S. Sriram
- Manohar U. Kalwani
### Published:
- 1 Jan 2007
### Abstract:
We study the optimal levels of advertising and promotion budgets in dynamic markets with brand equity as a mediating variable. To this end, we develop and estimate a state-space model based on the Kalman filter that captures the dynamics of brand equity as influenced by its drivers, such as the brands advertising and sales promotion expenditures. By integrating the Kalman filter with the random coefficients logit demand model, our estimation allows us to capture the dynamics of brand equity as well as to model consumer heterogeneity using store-level data. Using these demand model estimates, we determine the Markov perfect equilibrium advertising and promotion strategies. Our empirical analysis is based on store-level scanner data in the orange juice category, which comprises two major brandsTropicana and Minute Maid. As expected, we find that sales promotions have a significant positive effect on consumers utility and induce consumers to switch to the promoted brand. However, there is also a negative effect of promotions on brand equity that carries over from period to period. Overall, we find that while sales promotions have a net positive impact both in the short term and in the long term, the implied total profit elasticity including the long-term effect is smaller than the short-term profit elasticity. Correspondingly, we expect myopic decision makers to allocate higher than optimal expenditures to sales promotions. Our results from the supply-side analysis reveal that the actual promotion levels for both brands are indeed higher than the optimal budgets for the forward-looking (long-term orientation) as well as the two-year planning horizon scenarios. Hence, it may be profitable for both brands to reduce their promotion levels. Further, we find that although the forward-looking promotional spending levels are higher for the smaller brand, Minute Maid, it is market leader Tropicana that spends more on sales promotions. Turning to optimal advertising budgets, we find that the equilibrium forward-looking advertising levels are higher for Tropicana, the brand that has higher brand equity and a higher responsiveness to advertising. Further, as expected, the optimal forward-looking advertising levels are higher than the myopic levels and the two-year planning horizon levels for both brands. However, the forward-looking advertising levels are lower than the actual advertising expenditures for both brands. This implies that even when we consider the long-term effects of advertising, the brands are overspending on advertising.
### Link:
- https://doi.org/10.1287/mnsc.1060.0604

## 6. Operations Systems with Discretionary Task Completion
### Author(s):
- Wallace J. Hopp
- Seyed M. R. Iravani
- Gigi Y. Yuen
### Published:
- 1 Jan 2007
### Abstract:
Most performance evaluation models in the operations management literature implicitly assume that tasks possess standardized completion criteria. However, in many systems, particularly service and professional work, judgment is frequently required to determine how much time to allocate to a task. In this paper, we show that introducing discretion in task completion adds a fourth variability buffer, quality, to the well-known buffers of capacity, inventory and time. To gain insight into the managerial implications of this difference, we model the work of one- and two-worker systems with discretionary task completion as controlled queues. After characterizing the optimal control policy and identifying some practical heuristics, we use this model to examine the differences between discretionary and nondiscretionary work. We show that in systems with discretionary task completion, (i) adding capacity may actually increase congestion, and (ii) task variability in service time can improve system performance. This implies that it may be suboptimal to expect shorter delays as a result of a capacity increase, and that task variability reduction may not be an appropriate goal in systems with discretionary task completion. We also find that the benefit of queue pooling is smaller in systems with discretionary task completion than in systems with nondiscretionary task completion.
### Link:
- https://doi.org/10.1287/mnsc.1060.0598

## 7. Shipment Consolidation: Who Pays for It and How Much?
### Author(s):
- Moshe Dror
- Bruce C. Hartman
### Published:
- 1 Jan 2007
### Abstract:
This paper examines the subject of cost allocation in a multiple product inventory system, allowing for consolidation of shipments. If we order multiple items using an economic order quantity (EOQ) policy, and consolidate shipments, part of the ordering cost is shared, and part is specific to each item; we want to find the consolidation choice with optimal total cost and divide the cost fairly among the individual items. Such a fair division is central to a costing system in which no group of items subsidizes the others; there are no free riders! We use a cooperative inventory game to determine when this can be done. This game is usually not concave, so we want to know what consolidation combinations determine when this cost can be fairly divided, using the core of the game. We prove that consolidation of all the items is cheaper exactly if there are fair cost allocations (core of the game is not empty), which happens when the portion of the ordering cost common to all items is not too small. We further show how sensitive the nonempty core result is to adjustments in the cost parameters and show how to determine a threshold value for the shared ordering cost, which assures the existence of a fair cost allocation.
### Link:
- https://doi.org/10.1287/mnsc.1060.0607

## 8. The Economics of Remanufacturing Under Limited Component Durability and Finite Product Life Cycles
### Author(s):
- Roland Geyer
- Luk N. Van Wassenhove
- Atalay Atasu
### Published:
- 1 Jan 2007
### Abstract:
This paper models and quantifies the cost-savings potential of production systems that collect, remanufacture, and remarket end-of-use products as perfect substitutes while facing the fundamental supply-loop constraints of limited component durability and finite product life cycles. The results demonstrate the need to carefully coordinate production cost structure, collection rate, product life cycle, and component durability to create or maximize production cost savings from remanufacturing.
### Link:
- https://doi.org/10.1287/mnsc.1060.0600

## 9. Minimizing Information Loss and Preserving Privacy
### Author(s):
- Syam Menon
- Sumit Sarkar
### Published:
- 1 Jan 2007
### Abstract:
The need to hide sensitive information before sharing databases has long been recognized. In the context of data mining, sensitive information often takes the form of itemsets that need to be suppressed before the data is released. This paper considers the problem of minimizing the number of nonsensitive itemsets lost while concealing sensitive ones. It is shown to be an intractably large version of an NP-hard problem. Consequently, a two-phased procedure that involves the solution of two smaller NP-hard problems is proposed as a practical and effective alternative. In the first phase, a procedure to solve a sanitization problem identifies how the support for sensitive itemsets could be eliminated from a specific transaction by removing the fewest number of items from it. This leads to a modified frequent itemset hiding problem, where transactions to be sanitized are selected such that the number of nonsensitive itemsets lost, while concealing sensitive ones, is minimized. Heuristic procedures are developed for these problems using intuition derived from their integer programming formulations. Results from computational experiments conducted on a publicly available retail data set and three large data sets generated using IBMs synthetic data generator indicate that these approaches are very effective, solving problems involving up to 10 million transactions in a short period of time. The results also show that the process of sanitization has considerable bearing on the quality of solutions obtained.
### Link:
- https://doi.org/10.1287/mnsc.1060.0603

## 10. A Good Sign for Multivariate Risk Taking
### Author(s):
- Louis Eeckhoudt
- Batrice Rey
- Harris Schlesinger
### Published:
- 1 Jan 2007
### Abstract:
Decisions under risk are often multidimensional, where the preferences of the decision maker depend on several attributes. For example, an individual might be concerned about both her level of wealth and the condition of her health. Many times the signs of successive cross-derivatives of a utility function play an important role in these models. However, there has not been a simple and intuitive interpretation for the meaning of such derivatives. The purpose of this paper is to give such an interpretation. In particular, we provide an equivalence between the signs of these cross-derivatives and individual preference within a particular class of simple lotteries.
### Link:
- https://doi.org/10.1287/mnsc.1060.0606

## 11. Equivalent Information for Multiobjective Interactive Procedures
### Author(s):
- Mariano Luque
- Rafael Caballero
- Julian Molina
- Francisco Ruiz
### Published:
- 1 Jan 2007
### Abstract:
Despite the mathematical properties and algorithmic features of an interactive method, that methods success usually lies in the kind of information it requires from the decision maker. In some cases, this information constrains the decision maker. If she does not find it easy and comfortable to answer the questions posed by the algorithm, then she will very likely give inconsistent answers, and the method will fail to find her most preferred solution. Therefore, it is of interest to find relations among the different kinds of information (local weights, local trade-offs, reference points, etc.) to allow the decision maker to choose what kind of questions he wants to answer, and to provide him with enough information to give such answers. In this paper, we define equivalent informationthat is, different kinds of informationthat produces the same solution when used in their corresponding interactive schemes.
### Link:
- https://doi.org/10.1287/mnsc.1060.0595

## 12. Mean-Variance-Skewness Portfolio Performance Gauging: A General Shortage Function and Dual Approach
### Author(s):
- Walter Briec
- Kristiaan Kerstens
- Octave Jokung
### Published:
- 1 Jan 2007
### Abstract:
This paper proposes a nonparametric efficiency measurement approach for the static portfolio selection problem in mean-variance-skewness space. A shortage function is defined that looks for possible increases in return and skewness and decreases in variance. Global optimality is guaranteed for the resulting optimal portfolios. We also establish a link to a proper indirect mean-variance-skewness utility function. For computational reasons, the optimal portfolios resulting from this dual approach are only locally optimal. This framework permits to differentiate between portfolio efficiency and allocative efficiency, and a convexity efficiency component related to the difference between the primal, nonconvex approach and the dual, convex approach. Furthermore, in principle, information can be retrieved about the revealed risk aversion and prudence of investors. An empirical section on a small sample of assets serves as an illustration.
### Link:
- https://doi.org/10.1287/mnsc.1060.0596

## 13. Research NoteThe Role of Production Lead Time and Demand Uncertainty in Marketing Durable Goods
### Author(s):
- Preyas S. Desai
- Oded Koenigsberg
- Devavrat Purohit
### Published:
- 1 Jan 2007
### Abstract:
Firms often have to make their production decisions under conditions of demand uncertainty. This is especially true for product categories such as automobiles and technology goods where the lead time needed for manufacturing forces firms to make production decisions well in advance of the selling season. Once the firm has produced the goods, the available production volume affects the firms subsequent marketing decisions. In this paper, we study the relationship between the firms production and marketing decisions for a durable goods manufacturer. We develop a dynamic model of a durable product market in which the demand functions are developed from a micromodeling of consumer utility functions and an equilibrium analysis of consumer strategies. After taking into account the demand uncertainty as well as the potential for cannibalization of future sales, the manufacturer makes its production and sales decisions. We find that the firms optimal inventory level is U-shaped in the durability of the product and that the firm suffers a larger loss due to uncertainty when it is leases rather than sells its products. Furthermore, unlike the case for nondurables, for durable goods we find that the effect of uncertainty persists even after the uncertainty has been resolved.
### Link:
- https://doi.org/10.1287/mnsc.1060.0599

## 14. Research NoteCompetitive Bundling and Counterbundling with Generalist and Specialist Firms
### Author(s):
- Bikram Ghosh
- Subramanian Balachander
### Published:
- 1 Jan 2007
### Abstract:
Bundling, which is the practice of selling two or more products or services in a package, is a pervasive marketing practice and is often used as a strategic competitive tool. However, there has not been enough consideration of competitive bundling situations in which exit of a competitor is not a concern. In this paper, we address this issue by identifying conditions under which strategic competitors may or may not resort to bundling when competitor exit considerations are absent. We study competition between a multiproduct generalist firm and two single-product specialist firms in two product categories, one of which has undifferentiated products and the other has differentiated products. In our model, the specialist firms can form an alliance to bundle their products in competing with the generalist firm. In contrast to the previous literature, we find that concurrent bundling by competitors, if it occurs in equilibrium, is profitable. We also find that when one competitor bundles and the other does not, the bundling firm gains a greater share of customers and makes a higher profit. However, when conditions favor counterbundling by a competitor, such counterbundling helps the competitor retain its customers. Finally, we note that under other market conditions, concurrent bundling by competitors escalates price competition to the extent that retaining customers through bundling is not profitable. In such a case, we show that strategic competitors are better off having asymmetric product lines with one competitor bundling and the other selling unbundled.
### Link:
- https://doi.org/10.1287/mnsc.1060.0601

