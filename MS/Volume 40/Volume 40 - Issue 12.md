# Volume 40, Issue 12
- December 1994
- Pages 1579-1763
- David Simchi-Levi

## 1. Metagraphs: A Tool for Modeling Decision Support Systems
### Author(s):
- Amit Basu
- Robert W. Blanning
### Published:
- 1 Dec 1994
### Abstract:
Most decision support systems (DSS) contain stored data, data analysis procedures, and decision models. However, many DSS have grown to the point that the average end user is presented with a bewildering array of information resources that are difficult to manage in an effective manner. As a result users often gravitate to a few familiar models and are unaware of the data resources available to them and how these resources relate to the various models. For example, they may think that a model requires data that is unavailable, when in fact that data has recently been added to the data base or could be calculated from another model. Or they may believe that all of the data needed to execute a set of models is available and find out well into the analysis that it is not. Existing tools for DSS design do not provide an effective and comprehensive foundation for modeling all the components of a DSS, or for addressing all the important DSS analysis and design issues. In this paper we show how a new graph-theoretic structure, called a metagraph, can be used as a unifying basis for addressing many important questions in DSS development and use.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1579

## 2. Development of Measures to Assess the Extent to Which an Information Technology Application Provides Competitive Advantage
### Author(s):
- Vijay Sethi
- William R. King
### Published:
- 1 Dec 1994
### Abstract:
In order to measures the extent to which information technology provides competitive advantages, the construct Competitive Advantage Provided by an Information Application (CAPITA) was operationalized. A field survey gathered data from 185 top information systems executives regarding information technology applications which had been developed to gain competitive advantage. A confirmatory analysis revealed that CAPITA may be conceptualized in terms of nine dimensions which satisfy key measurement criteria including unidimensionality and convergent validity, discriminant validity, predictive validity, and reliability.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1601

## 3. Does Information Technology Lead to Smaller Firms?
### Author(s):
- Erik Brynjolfsson
- Thomas W. Malone
- Vijay Gurbaxani
- Ajit Kambil
### Published:
- 1 Dec 1994
### Abstract:
Many changes in the organization of work in the United States since 1975 have been attributed to the increased capabilities and use of information technology (IT) in business. However, few studies have attempted to empirically examine these relationships. The primary goal of this paper is to assess the hypothesis that investments in information technology are at least partially responsible for the important organizational change, the shift of economic activity to smaller firms. We examine this hypothesis using industry-level data on IT capital and four measures of firm size, including employees and sales per firm. We find broad evidence that investment in IT is significantly associated with subsequent decreases in the average size of firms. We also find that these decreases in firm size are most pronounced two to three years after the IT investment is made.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1628

## 4. Information Assets, Technology and Organization
### Author(s):
- Erik Brynjolfsson
### Published:
- 1 Dec 1994
### Abstract:
Although there is good reason to expect that the growth of information work and information technology will significantly affect the trade-offs inherent in different structures for organizing work, the theoretical basis for these changes remains poorly understood. This paper seeks to address this gap by analyzing the incentive effects of different ownership arrangement in the spirit of the Grossman-Hart-Moore (GHM) incomplete contracts theory of the firm. A key departure from earlier approaches is the inclusion of a role for an information asset, analogous to the GHM treatment of property. This approach highlights the organizational significance of information ownership and information technology. For instance, using this framework, one can determine when 1) informed workers are more likely to be owners than employees of firms, 2) increased flexibility of assets will facilitate decentralization, and 3) the need for centralized coordination will lead to centralized ownership. The framework developed sheds light on some of the empirical findings regarding the relationship between information technology and firm size and clarifies the relationship between coordination mechanisms and the optimal distribution of asset ownership. While many implications are still unexplored and untested, building on the incomplete contracts approach appears to be a promising avenue for the careful, methodical analysis of human organizations and the impact of new technologies.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1645

## 5. Business and Technology Strategies and New Venture Performance: A Study of the Telecommunications Equipment Industry
### Author(s):
- Michael J. Dowling
- Jeffrey E. McGee
### Published:
- 1 Dec 1994
### Abstract:
In this paper, a set of hypotheses relating competitive and cooperative business strategies and technology strategies to new venture performance are developed. These hypotheses are tested using data collected from the Initial Public Offering (IPO) documents of a sample of 52 new ventures in the telecommunications equipment industry. This industry has experienced a great deal of technological change as computer and telephone technologies have merged allowing a variety of new ventures to successfully enter the industry. The results suggest that new ventures pursuing broad cost leadership strategies were more successful. Investments in innovation in terms of relative R&D expenditures were also related to higher performance. Finally, significant interaction effects between investments in innovation and competitive strategies and performance were found.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1663

## 6. Safety Stock versus Safety Time in MRP Controlled Production Systems
### Author(s):
- J. A. Buzacott
- J. G. Shanthikumar
### Published:
- 1 Dec 1994
### Abstract:
The two management set parameters which determine the performance of a material requirements planning (MRP) system are the lead time and the safety stock. The appropriate values of these parameters are influenced by the accuracy of forecasts over the lead time, the variability of processing time and the degree of congestion, together with the costs of inventory and shortages. These influences are explored using stochastic models of a single stage manufacturing system for which work release is controlled using MRP. The major conclusion is that safety time is usually only preferable to safety stock when it is possible to make accurate forecasts of future required shipments over the lead time, otherwise safety stock is more robust in coping with changes in customer requirements in the lead time or with fluctuations in forecasts of lead time demand.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1678

## 7. The Strategic Use of Capacity Slack in the Economic Lot Scheduling Problem with Random Demand
### Author(s):
- Karla E. Bourland
- Candace A. Yano
### Published:
- 1 Dec 1994
### Abstract:
Growing interest in designing systems with capacity slack as one form of flexibility raises many questions about its use and its usefulness. In the framework of the economic lot scheduling problem with stochastic demand, we develop on optimization-based model that considers capacity slack, safety stock, and overtime explicitly, and has the objective of minimizing the expected cost per unit time of inventory, overtime, and, where applicable, setup costs. The solution is a continuous-time production plan that consists of a time-dependent inventory trajectory for each of the parts, including the placement of planned idle time in the schedule. We consider schedule stability to be desirable because of potential effects on upstream and downstream operations in multistage production settings. Thus, the plan also has certain characteristics that contribute to achieving stability.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1690

## 8. Valuing Asian and Portfolio Options by Conditioning on the Geometric Mean Price
### Author(s):
- Michael Curran
### Published:
- 1 Dec 1994
### Abstract:
The valuation of Asian, or a average price, options and of European options on portfolios in a Black-Scholes environment has given researchers trouble. The difficulty with these problems is that the probability distribution of the variable which determines the option payoff at expiration, a sum of correlated lognormal random variables, has no closed-form representation. For the Asian case the approach generally taken has been to approximate the distribution of the arithmetic average price, while for the portfolio option case, attempts have focused on discretizing the joint distribution of the terminal prices of the assets comprising the portfolio and approximating the expected risk-neutral option payoff with a discrete sum. These approaches are not entirely satisfactory. The distribution-approximating procedures for Asian options are not very accurate for some cases, while the computational requirements for obtaining a reasonably accurate estimate using the discretizing or multinomial approaches for portfolio options become excessive as the number of assets rises above four or five, because the computation time is exponential in the number of assets. This paper presents a method based on conditioning on the geometric mean price which results in a far more efficient technique for valuing these options.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1705

## 9. Single Machine Scheduling with Deadlines to Minimize the Weighted Number of Tardy Jobs
### Author(s):
- A. M. A. Hariri
- C. N. Potts
### Published:
- 1 Dec 1994
### Abstract:
This paper considers as single machine scheduling problem in which jobs have due dates and deadlines. A job may be completed after its due date, but not after its deadline, in which case it is tardy. A branch and bound algorithm is proposed to find a schedule which minimizes the weighted number of tardy jobs. It uses lower bounds which are derived using the dynamic programming state-space relaxation method. Computational experience with test problems having up to 300 jobs indicates that the lower bounds are extremely effective in restricting the size of the branch and bound search tree.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1712

## 10. Evolutionary Trajectories in Petroleum Firm R&D
### Author(s):
- Constance E. Helfat
### Published:
- 1 Dec 1994
### Abstract:
Tacit knowledge and cumulative learning underlie an evolutionary theory of business firm development and strategy. As one test case of the theory, this study examines firms' applied research and development activities. Evolutionary theory suggests that firms within an industry will tend both to persist and to differ in the amount of effort they devote to various R&D applications. A test of the hypothesis of presistent differences in R&D, using uniquely detailed data from the petroleum industry, provides support for evolutionary theory.
### Link:
- https://doi.org/10.1287/mnsc.40.12.1720

## 11. Distribution-Free Confidence Intervals for Conditional Probabilities and Ratios of Expectations
### Author(s):
- Christos Alexopoulos
### Published:
- 1 Dec 1994
### Abstract:
Many simulation experiments are concerned with the estimation of a ratio of two unknown means, the estimation of a conditional probability being an example. We propose confidence intervals for the case in which the ratio is estimated by using independent, identically distributed random pairs with bounded and ordered components. Emphasis is given to the case in which each component can be expressed as the product of a Bernoulli and a bounded random variable. The proposed intervals result from distribution-free bounds on error probabilities, are valid for every sample size, and their asymptotic width decreases at the same rate as that of confidence intervals based on the central limit theorem. We evaluate their performance by means of two experiments. The first considers the estimation of the probability that a path in a directed a network is shortest while the second considers the estimation of the distribution of the inventory level in a stationary inventory system with periodic review. The experiments show that the intervals are conservative with superior coverage for small sample sizes (50).
### Link:
- https://doi.org/10.1287/mnsc.40.12.1748

