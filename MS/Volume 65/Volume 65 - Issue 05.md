# Volume 65, Issue 05
- May 2019
- Pages 1949-2443
- David Simchi-Levi

## 1. Regulation and Market Liquidity
### Author(s):
- Francesco Trebbi
- Kairong Xiao
### Published:
- 19 Dec 2017
### Abstract:
We examine the effects of postcrisis financial regulation, encompassing the Dodd–Frank Act and Basel III, on market liquidity of the U.S. fixed-income market. We estimate structural breaks in a large panel of liquidity measures of corporate and Treasury bonds. Our methodology does not require a priori knowledge of the timing of breaks, can capture not only sudden jumps but also breaks in slow-moving trends, and displays excellent power properties. Against the popular claim that postcrisis regulation hurt liquidity, we find no evidence of liquidity deterioration during periods of regulatory intervention. Instead, breaks toward higher liquidity are often detected.
### Link:
- https://doi.org/10.1287/mnsc.2017.2876

## 2. The Impact of Delay Announcements on Hospital Network Coordination and Waiting Times
### Author(s):
- Jing Dong
- Elad Yom-Tov
- Galit B. Yom-Tov
### Published:
- 30 Jul 2018
### Abstract:
We investigate the impact of delay announcements on the coordination within hospital networks using a combination of empirical observations and numerical experiments. We offer empirical evidence that suggests that patients take delay information into account when choosing emergency service providers and that such information can help increase coordination in the network, leading to improvements in the performance of the network, as measured by emergency department wait times. Our numerical results indicate that the level of coordination that can be achieved is limited by the patients’ sensitivity to waiting, the load of the system, the heterogeneity among hospitals, and, importantly, the method hospitals use to estimate delays. We show that delay estimators that are based on historical averages may cause oscillation in the system and lead to higher average wait times when patients are sensitive to delay. We provide empirical evidence that suggests that such oscillations occur in hospital networks in the United States.
### Link:
- https://doi.org/10.1287/mnsc.2018.3048

## 3. Your Uber Is Arriving: Managing On-Demand Workers Through Surge Pricing, Forecast Communication, and Worker Incentives
### Author(s):
- Harish Guda
- Upender Subramanian
### Published:
- 12 Feb 2019
### Abstract:
On-demand platforms (e.g., Uber, Lyft) often rely on independent workers, who are not directly under the platform’s control, to be available at the “right” time and locations to serve consumers at short notice. To manage fluctuating demand across market locations (zones), on-demand platforms share market forecasts with workers to inform them where they should be available, and use surge pricing—wherein the price at a particular zone is temporarily raised above the regular price. We analyze these platform strategies in an on-demand marketplace where independent workers can move between adjacent zones, explicitly accounting for the strategic interaction in their moving decisions. We show that, contrary to conventional wisdom, surge pricing can be useful even in zones where supply exceeds demand. Specifically, because workers are strategic agents facing costs to move and competition from other workers who move, simply informing workers where they should be available may not ensure that enough workers move to that zone. Interestingly, more workers can be made to move from a zone with excess supply of workers by strategically using a surge price to throttle demand in that zone. Such strategic surge pricing can increase total platform profit across zones, and even be more profitable than offering workers bonuses to move. Surge pricing in a zone with excess supply can also be useful to credibly communicate the need for more workers to move. In other instances, such surge pricing may be useful to avoid too many workers from moving. Our analysis offers insights for effectively managing on-demand service with independentworkers.
### Link:
- https://doi.org/10.1287/mnsc.2018.3050

## 4. Dynamic Portfolio Execution
### Author(s):
- Gerry Tsoukalas
- Jiang Wang
- Kay Giesecke
### Published:
- 27 Oct 2017
### Abstract:
We analyze the optimal execution problem of a portfolio manager trading multiple assets. In addition to the liquidity and risk of each individual asset, we consider cross asset interactions in these two dimensions, which substantially enriches the nature of the problem. Focusing on the market microstructure, we develop a tractable order book model to capture liquidity supply/demand dynamics in a multiasset setting, which allows us to formulate and solve the optimal portfolio execution problem. We find that cross asset risk and liquidity considerations are of critical importance in constructing the optimal execution policy. We show that even when the goal is to trade a single asset, its optimal execution may involve transitory trades in other assets. In general, optimally managing the risk of the portfolio during the execution process affects the time synchronization of trading in different assets. Moreover, links in the liquidity across assets lead to complex patterns in the optimal execution policy. In particular, we highlight cases where aggregate costs can be reduced by temporarily “overshooting” one’s target portfolio.
### Link:
- https://doi.org/10.1287/mnsc.2017.2865

## 5. Saving Patient Ryan—Can Advanced Electronic Medical Records Make Patient Care Safer?
### Author(s):
- Muhammad Zia Hydari
- Rahul Telang
- William M. Marella
### Published:
- 31 Jul 2018
### Abstract:
The risk of patient harm resulting from medical care affects hundreds of thousands of patients and costs tens of billions of dollars every year. Advanced electronic medical records (EMRs) are expected to improve patient safety, but the evidence of their impact on patient safety is inconclusive. A key challenge to evaluating advanced EMRs’ impact has been the lack of reliable patient safety data. We address this issue by analyzing a new patient safety data set from the Pennsylvania Patient Safety Authority (PSA), a state agency that aggregates patient safety data from Pennsylvania hospitals. Using a 2005–2014 panel from PSA, we identify advanced EMRs’ effect using the difference-in-differences method. We find that advanced EMRs lead to a 17.5% decline in patient safety events, driven by reductions in medication errors, falls, and complication errors. Further, our analysis shows a decline in medium- and high-severity events.
### Link:
- https://doi.org/10.1287/mnsc.2018.3042

## 6. Crop Planning in Sustainable Agriculture: Dynamic Farmland Allocation in the Presence of Crop Rotation Benefits
### Author(s):
- Onur Boyabatlı
- Javad Nasiry
- Yangfang (Helen) Zhou
### Published:
- 25 Jan 2019
### Abstract:
This paper examines crop planning decisions in sustainable agriculture—that is, how to allocate farmland among multiple crops in each growing season when the crops have rotation benefits across growing seasons. We consider a farmer who periodically allocates the farmland between two crops in the presence of revenue uncertainty where revenue is stochastically larger and farming cost is lower when a crop is grown on rotated farmland (where the other crop was grown in the previous season). We characterize the optimal dynamic farmland allocation policy and perform sensitivity analysis to investigate how revenue uncertainty of each crop affects the farmer’s optimal allocation decision and profitability. Using a calibration based on a farmer growing corn and soybeans in Iowa, we show that growing only one crop over the entire planning horizon, as employed in industrial agriculture, leads to a considerable profit loss—that is, crop planning based on principles of sustainable agriculture has substantial value. We propose a simple heuristic allocation policy, which we characterize in closed form. Using our model calibration, we show that (i) the proposed policy not only outperforms the commonly suggested heuristic policies in the literature, but also provides a near-optimal performance and (ii) compared with the optimal policy, the proposed policy has a higher allocation of crops to rotated farmland, and thus, it is potentially more environmentally friendly.
### Link:
- https://doi.org/10.1287/mnsc.2018.3044

## 7. The More You Know: Information Effects on Job Application Rates in a Large Field Experiment
### Author(s):
- Laura K. Gee
### Published:
- 20 Apr 2018
### Abstract:
This paper presents the results from a 2.3-million-person field experiment that varies whether or not a job seeker sees the number of applicants for a job posting on a large job-posting website, LinkedIn. This intervention increases the likelihood that a person will finish an application by 3.5%. Women have a larger increase in their likelihood of finishing an application than men. Overall, adding this information to a job posting may offer a light-touch way to both increase application rates and alter the diversity of the applicant pool.
### Link:
- https://doi.org/10.1287/mnsc.2017.2994

## 8. A Dynamic Clustering Approach to Data-Driven Assortment Personalization
### Author(s):
- Fernando Bernstein
- Sajad Modaresi
- Denis Sauré
### Published:
- 5 Sep 2018
### Abstract:
We consider an online retailer facing heterogeneous customers with initially unknown product preferences. Customers are characterized by a diverse set of demographic and transactional attributes. The retailer can personalize the customers’ assortment offerings based on available profile information to maximize cumulative revenue. To that end, the retailer must estimate customer preferences by observing transaction data. This, however, may require a considerable amount of data and time given the broad range of customer profiles and large number of products available. At the same time, the retailer can aggregate (pool) purchasing information among customers with similar product preferences to expedite the learning process. We propose a dynamic clustering policy that estimates customer preferences by adaptively adjusting customer segments (clusters of customers with similar preferences) as more transaction information becomes available. We test the proposed approach with a case study based on a data set from a large Chilean retailer. The case study suggests that the benefits of the dynamic clustering policy under the MNL model can be substantial and result (on average) in more than 37% additional transactions compared to a data-intensive policy that treats customers independently and in more than 27% additional transactions compared to a linear-utility policy that assumes that product mean utilities are linear functions of available customer attributes. We support the insights derived from the numerical experiments by analytically characterizing settings in which pooling transaction information is beneficial for the retailer, in a simplified version of the problem. We also show that there are diminishing marginal returns to pooling information from an increasing number of customers.
### Link:
- https://doi.org/10.1287/mnsc.2018.3031

## 9. The Implications of Credit Risk Modeling for Banks’ Loan Loss Provisions and Loan-Origination Procyclicality
### Author(s):
- Gauri Bhat
- Stephen G. Ryan
- Dushyantkumar Vyas
### Published:
- 27 Dec 2018
### Abstract:
Economic policymakers express concern that procyclical lending by banks imperils financial stability. Prior research finds that banks that record timelier loan loss provisions originate more loans during downturns, consistent with loan loss–provision timeliness mitigating loan-origination procyclicality. Motivated by this concern and research, we examine whether banks’ credit risk modeling disciplines both their loan loss provisions and loan origination. We identify two forms of credit risk modeling from banks’ financial report disclosures: statistical modeling of the drivers of past loan losses and stress testing of future loan losses to adverse scenarios. We show that banks’ credit risk–modeling disclosures are positively associated with their loan loss–provision timeliness, with the ability of their provisions to predict future loan charge-offs, and with their loan origination during downturns. We further show that these associations vary in predictable ways across the two forms of credit risk modeling when we distinguish homogeneous from heterogeneous loans and stable periods from downturns.
### Link:
- https://doi.org/10.1287/mnsc.2018.3041

## 10. Population Monotonicity in Newsvendor Games
### Author(s):
- Xin Chen
- Xiangyu Gao
- Zhenyu Hu
- Qiong Wang
### Published:
- 17 Jan 2019
### Abstract:
A newsvendor game allows the players to collaborate on inventory pooling and share the resulting total cost. There are several possible ways to allocate the cost. Previous studies have focused on the core of the game. It is known that the core of the newsvendor game is nonempty, and one can use duality theory in stochastic programming to construct an allocation—referred to as the dual-based allocation—belonging to the core. Yet, an allocation that lies in the core does not necessarily guarantee the unhindered formation of a coalition, as some existing members’ allocated costs may increase when new members are added in the process. In this work, we use the concept of population monotonic allocation scheme (PMAS), which requires the cost allocated to every member of a coalition to decrease as the coalition grows, to study allocation schemes in a growing population. We show that when the demands faced by the newsvendors are independent, log-concavity of their distributions is sufficient to guarantee the existence of a PMAS. Specifically, for continuous demands, log-concavity ensures that the game is convex, which in turn implies a PMAS exists. We also show that under the same condition the dual-based allocation scheme is a PMAS. For discrete and log-concave demands, however, the game may no longer be convex, but we manage to show that, even so, the dual-based allocation scheme is a PMAS. When the demands are dependent, the game is in general not convex. We derive a sufficient condition based on the dependence structure, measured by the copula, to ensure that the dual-based allocation scheme is still a PMAS. We also include an example of a game with no PMAS.
### Link:
- https://doi.org/10.1287/mnsc.2018.3053

## 11. Why Markdown as a Pricing Modality?
### Author(s):
- Elodie Adida
- Özalp Özer
### Published:
- 20 Sep 2018
### Abstract:
Markdown as a pricing modality is ubiquitous in retail whereas everyday low price (EDLP) remains relatively rare (despite its several advantages, such as simplicity). This paper explores whether and why retailers can use either of these pricing modalities as an effective defense against a competitor entering the market with the alternative pricing modality. Various studies have shown that consumers are strategic and heterogeneous in their valuation of a product. Consumers are also shown to be regret-prone, and anticipation of regret affects their purchase decisions. Consumers experience availability regret when they are unable to purchase products due to stockouts and high-price regret when they miss an opportunity to purchase products at low prices. Considering such factors, consumers decide whether, when, and from which retailer to purchase the product. In such a market environment, we find that the possible entry of a competitor should deter retailers from using the EDLP pricing modality but not markdown. We also identify a new reason for the markdown retailer to ration stock (in addition to the reason for discouraging consumers to wait for the markdown). In particular, we show that the markdown retailer can use inventory rationing to preclude a cutthroat competition and bankruptcy after the entry of an EDLP retailer. We also quantify how consumer regret affects both retailers’ decisions and resulting profits. In particular, in a competitive market, the EDLP retailer cannot simply disregard consumers’ availability and high-price regret (even when it stocks ample inventory and does not discount prices). We show that high-price regret and availability regret have complementary effects on the markdown retailer’s rationing strategy and the EDLP retailer’s price decision. Finally, using a proprietary price data set from a large department store, we show that ignoring regret factors causes the markdown retailer to leave up to 20% of its profits on the table. In addition, in a competitive market, the markdown retailer rations too aggressively when regret is ignored and, as a result, leaves some of the forgone profit to its competitor—the EDLP retailer. The retail industry is often characterized by its slim profit margins. In such an environment, the aforementioned results also suggest that retailers should seriously consider investing in developing the capacity to estimate and quantify the role of regret in consumers’ purchase decisions.
### Link:
- https://doi.org/10.1287/mnsc.2018.3046

## 12. Drivers of Product Expiration in Consumer Packaged Goods Retailing
### Author(s):
- Arzum Akkas
- Vishal Gaur
- David Simchi-Levi
### Published:
- 28 Nov 2018
### Abstract:
Product expiration is an important problem in the consumer packaged goods (CPG) industry costing 1%–2% of gross retail sales and eroding industry profits substantially. It can be caused by several factors related to store operations, supply chain practices, and product characteristics. Existing methods used in the industry are inadequate to identify the causes of expiration, leading to inadequate efforts to reduce expiration. Using retail data for 768 SKUs and 10,000 stores (745,638 store-SKU–level observations), as well as upstream supply chain data from a CPG manufacturer, we show the extent to which expiration of products in retail stores is driven by case size, inventory aging in the supply chain, minimum order rules, manufacturers’ incentive programs for the sales force, replenishment workload, and many control variables. A counterfactual analysis based on the model shows that our subject manufacturer can reduce expiration by up to $38.82 million per year by implementing four selected initiatives involving case size, supply chain aging, minimum order rules, and sales incentives. Further, targeted initiatives can be designed using combinations of these variables for subsets of products with the highest occurrence of expiration.
### Link:
- https://doi.org/10.1287/mnsc.2018.3051

## 13. The Limit of Rationality in Choice Modeling: Formulation, Computation, and Implications
### Author(s):
- Srikanth Jagabathula
- Paat Rusmevichientong
### Published:
- 1 Aug 2018
### Abstract:
Customer preferences may not be rational, so we focus on quantifying the limit of rationality (LoR) in choice modeling applications. We define LoR as the cost of approximating the observed choice fractions from a collection of offer sets with those from the best-fitting probability distribution over rankings. Computing LoR is intractable in the worst case. To deal with this challenge, we introduce two new concepts, rational separation and choice graph, through which we reduce the problem to solving a dynamic program on the choice graph and express the computational complexity in terms of the structural properties of the graph. By exploiting the graph structure, we provide practical methods to compute LoR efficiently for a large class of applications. We apply our methods to real-world grocery sales data and identify product categories for which going beyond rational choice models is necessary to obtain an acceptable performance.
### Link:
- https://doi.org/10.1287/mnsc.2018.3030

## 14. Sunk Cost as a Self-Management Device
### Author(s):
- Fuhai Hong
- Wei Huang
- Xiaojian Zhao
### Published:
- 1 Aug 2018
### Abstract:
The sunk cost effect has been widely observed in individual decisions. Building on an intrapersonal self-management game, the paper theoretically shows that the sunk cost effect may stem from an attempt to overcome the underinvestment problem associated with a high degree of present bias or to resolve the multi-selves coordination problem when the degree of present bias is low. Especially for individuals with severe present bias, the current self may take a costly action (which is a sunk cost for the future self) to signal the individual’s high success probability that motivates his future self-disciplining behaviors. In equilibrium, a higher level of sunk cost is more likely to give rise to a higher probability for the individual to continue the project. We then conduct a laboratory experiment. The empirical findings are consistent with our theoretical implications.
### Link:
- https://doi.org/10.1287/mnsc.2018.3032

## 15. Referral Priority Program: Leveraging Social Ties via Operational Incentives
### Author(s):
- Luyi Yang
- Laurens Debo
### Published:
- 1 Aug 2018
### Abstract:
The referral priority program—an emerging business practice adopted by a growing number of technology companies that manage a waitlist of customers—enables existing customers on the waitlist to gain priority access if they successfully refer new customers to the waitlist. Unlike more commonly used referral reward programs, this novel mechanism does not offer monetary compensation to referring customers, but leverages customers’ own disutility of delays to create referral incentives. Despite this appealing feature, our queueing-game-theoretic analysis finds that the effectiveness of such a scheme as a marketing tool for customer acquisition and an operational approach for waitlist management depends crucially on the underlying market conditions, particularly the base market size of spontaneous customers. The referral priority program does not generate referrals when the base market size is either too large or too small. When customers do refer, the program could actually backfire—namely, by reducing the system throughput and customer welfare—if the base market size is intermediately large. This phenomenon occurs because the presence of referred customers severely cannibalizes the demand of spontaneous customers. We also compare the referral priority program with the referral reward program when the service provider optimally sets the admission price. Numerical study suggests that the referral priority program is more profitable than the referral reward program when the base market size is intermediately small.
### Link:
- https://doi.org/10.1287/mnsc.2018.3034

## 16. The Effect of Financial Reporting Quality on Corporate Investment Efficiency: Evidence from the Adoption of SFAS No. 123R
### Author(s):
- Yiwei Dou
- M. H. Franco Wong
- Baohua Xin
### Published:
- 7 Feb 2019
### Abstract:
We test for changes in investment efficiency around a shock to financial reporting quality—the adoption of SFAS No. 123R, which requires that employee stock option (ESO) costs be recognized rather than disclosed at fair value. We predict and find a reduction in underinvestment for firms heavily affected by the new standard, and these firms exhibit a decrease in the bid–ask spread and an increase in new capital raised in the post-SFAS No. 123R period. The reduction in underinvestment is more pronounced for firms whose ESO estimates are more unreliable before SFAS No. 123R, for firms that are financially constrained, and for firms with more entrenched managers. These findings are consistent with recognition of ESO costs at fair value improving financial reporting quality, which, in turn, enhances investment efficiency through the mitigation of the adverse selection problem for underinvesting firms.
### Link:
- https://doi.org/10.1287/mnsc.2018.3045

## 17. Choice Architecture, Framing, and Cascaded Privacy Choices
### Author(s):
- Idris Adjerid
- Alessandro Acquisti
- George Loewenstein
### Published:
- 5 Nov 2018
### Abstract:
For consumers, managing privacy online requires navigating a complex process of interrelated choices. This process may be conceived of as “cascaded,” in that a combination of upstream choices (e.g., of privacy settings on a social network site) and downstream choices (e.g., of what to reveal on the site) together determine ultimate privacy outcomes. In a series of experiments, we examine the potential impact of choice architecture in cascaded privacy choice settings. We investigate how changes in choice frames implemented by service providers can influence consumers’ upstream disclosure settings, often in ways that they are unaware of and that may be destructive to them. Whether the effects of choice frames upstream are ultimately detrimental to individuals’ privacy, however, depends on whether they are offset by more or less protective downstream choices. Thus, we also examine whether such upstream effects of choice architecture are “mitigated” through changes in downstream self-disclosure. We find, first, that various manipulations of decision frames, common in privacy contexts, significantly impact participants’ upstream choice of disclosure settings. Second, we do not find evidence that the impact of choice architecture upstream is mitigated downstream: participants’ self-disclosure rates do not adjust or change in response to choice architecture-induced changes in upstream choices. These findings call into question both policy makers’ and industry advocates’ reliance on choice-based privacy protection mechanisms, contribute to an emerging behavioral perspective on privacy decision making, and highlight the importance of accounting for the cascaded nature of privacy decision making in both policy and managerial settings.
### Link:
- https://doi.org/10.1287/mnsc.2018.3028

## 18. Extracting the Wisdom of Crowds When Information Is Shared
### Author(s):
- Asa B. Palley
- Jack B. Soll
### Published:
- 21 Feb 2019
### Abstract:
Using the wisdom of crowds—combining many individual judgments to obtain an aggregate estimate—can be an effective technique for improving judgment accuracy. In practice, however, accuracy is limited by the presence of correlated judgment errors, which often emerge because information is shared. To address this problem, we propose an elicitation procedure in which respondents are asked to provide both their own best judgment and an estimate of the average judgment that will be given by all other respondents. We develop an aggregation method, called pivoting, which separates individual judgments into shared and private information and then recombines these results in the optimal manner. In several studies, we investigate the method and examine the accuracy of the aggregate estimates. Overall, the empirical data suggest that the pivoting method provides an effective judgment aggregation procedure that can significantly outperform the simple crowd average.
### Link:
- https://doi.org/10.1287/mnsc.2018.3047

## 19. Going for Gold: An Analysis of Morningstar Analyst Ratings
### Author(s):
- Will J. Armstrong
- Egemen Genc
- Marno Verbeek
### Published:
- 22 Dec 2017
### Abstract:
We investigate Morningstar’s new qualitative, forward-looking analyst ratings, which reflect independent analysts’ expectations of a fund’s future performance. We find relatively higher flows to funds receiving higher ratings, suggesting that the average investor values the analyst’s subjective views when allocating their wealth. Performance tests show that investors would have earned significantly higher returns over our sample period by investing in funds with the highest analyst conviction. These results suggest that independent research that expands the information set to include qualitative elements may help investors make better investment allocation decisions.
### Link:
- https://doi.org/10.1287/mnsc.2017.2884

## 20. Process Utility and the Effect of Inaction Frames
### Author(s):
- Ioannis Evangelidis
- Jonathan Levav
### Published:
- 19 Jun 2018
### Abstract:
We introduce a new type of utility that we call “process utility,” which pertains to individuals’ preference about how they want to obtain an outcome. We posit that decision makers derive utility not only from the outcome itself, but also from the process through which that outcome is obtained. We focus on two normatively equivalent processes for obtaining an outcome: action and inaction. We argue that inducing differences in how outcomes are obtained can lead to significant preference reversals. We examine process utility in binary choice where one outcome is predominantly preferred over the other. We find that when the frequently selected (“advantaged”) alternative is framed as an inaction, its choice share decreases, but that when the infrequently selected (“disadvantaged”) alternative is framed as an inaction, its choice share increases. Finally, we discuss potential moderators of our effects.
### Link:
- https://doi.org/10.1287/mnsc.2017.3013

## 21. Imperfect Renegotiations in Interbank Financial Networks
### Author(s):
- Alexander David
- Alfred Lehar
### Published:
- 4 Dec 2017
### Abstract:
Interbank financial networks enable banks to share the risks in their assets but potentially also increase systemic spillovers of insolvency from one bank to others in the network. We model a renegotiation game to explicitly examine the forgiveness of commitments of insolvent banks by solvent banks to limit the systemic transmission of financial distress. The assets of the insolvent bank can be appropriated by the forgiving bank in the two-bank network, but not the three-bank network, where they may be appropriated by the third bank, leading to a renegotiation breakdown. We also show how banks can ex ante optimally construct networks from interbank loans and derivatives to minimize the costs of such inefficient financial distress.
### Link:
- https://doi.org/10.1287/mnsc.2017.2869

## 22. The Pricing of Jump Propagation: Evidence from Spot and Options Markets
### Author(s):
- Du Du
- Dan Luo
### Published:
- 22 Dec 2017
### Abstract:
This paper examines the joint time series of the S&P 500 index and its options with a two-factor Hawkes jump-diffusion model that captures jump propagation (i.e., the phenomenon in which the strike of one jump substantially raises the probability for more to follow). The propagation effect uncovered from the joint data is severe but short lived. On average, this component takes up more than two-thirds of the total jump risks. Our jump specification proves crucial not only in reconciling the dynamics implied from the joint data, but also in explaining the time series of option-implied volatility skew.
### Link:
- https://doi.org/10.1287/mnsc.2017.2885

## 23. “Hello Jumbo!” The Spatio-Temporal Rollout and Traffic to a New Grocery Chain After Acquisition
### Author(s):
- Arjen van Lin
- Els Gijsbrechts
### Published:
- 17 Jan 2019
### Abstract:
Grocery retailers increasingly use acquisitions to expand their presence. Such acquisitions are risky, especially when retailers decide to subsume the acquired stores under their own banner, which can take years and demands careful planning. We show how the dynamics of consumer valuations of the old and new banner affect the traffic implications of various (spatio-temporal) rollouts, and how this can be incorporated in the conversion planning. In a store-choice model with Bayesian learning, consumers update their perceptions about the old banner as its value deteriorates, and learn about the new banner through visits. Our model thus captures consumers’ responses to store conversion over time, in function of the local presence of other (own and competitive) outlets and new-banner advertising. An application to the national rollout of a Dutch EDLP player after its acquisition of a HILO chain, analyzes the shopping patterns of about 1,500 households over four years, involving over 100 store conversions. Our findings show that (i) uncertainty about the new banner dampens traffic to converted stores initially, while (ii) value deterioration of the old banner jeopardizes traffic to stores converted late, and (iii) the magnitude of these effects strongly depends on local-market characteristics, that is, competition and access to other old-banner and new-banner stores. With simulations, we show that to attract and keep customers, (i) outlets in competitive markets should not always get precedence and (ii) in locations with multiple outlets, conversions are better separated. Retailers can use these demand-side effects to their benefit in planning the rollout.
### Link:
- https://doi.org/10.1287/mnsc.2018.3054

## 24. An Analysis of Search and Authentication Strategies for Online Matching Platforms
### Author(s):
- Amit Basu
- Sreekumar Bhaskaran
- Rajiv Mukherjee
### Published:
- 11 Feb 2019
### Abstract:
Compared to offline matching markets, online matching platforms improve search in the matching process but at the same time increase the problem of authenticating the features and credentials of prospective matches. This paper examines the interplay between these two processes in online matching, using game-theoretic models. We examine whether an online matching platform should target a broad market of match-seekers or an exclusive group of high-value match-seekers, and how the platform should price its search and authentication services. Our results provide valuable insights for online matching platforms regarding the decision to offer authentication services in addition to search services, and guidelines for the pricing and positioning of these services. For instance, we show that the complementarity of the platform’s optimal pricing for search and authentication services can justify the platform’s offering an authentication service as a loss leader, and that higher-quality authentication services may not always justify higher authentication fees. We also develop guidelines for the platform’s optimal strategies for different market conditions.
### Link:
- https://doi.org/10.1287/mnsc.2018.3056

## 25. The Role of Market Evolution in Channel Contracting
### Author(s):
- Long Gao
- Birendra K. Mishra
### Published:
- 4 Feb 2019
### Abstract:
Real markets evolve over time. They often exhibit complex behaviors, such as autocorrelation, continuity, and nonstationarity. How do these behaviors affect channel contracting? We study the problem in a bilateral channel where the retailer has private information on evolving market conditions. We characterize the optimal contract under arbitrary market evolution. The central notion is market inertia: it prices retailer’s information advantage, dictates price and quantity response over time, and determines the contract complexity. Using market inertia, we identify a general property—stochastic linearity—that justifies the use of simple contracts for a much larger class of channel conditions. For practitioners, we offer refined guidance: (i) when the market has linear dynamics, simple contracts are sufficient; (ii) when the market is continuous, the quantity distortion should be pervasive; and (iii) when the market is nonstationary, the distortion can vanish, intensify, stay constant, or even go nonmonotonic over time. By highlighting the central role of realistic market behaviors, this paper advances our understanding of channel theory and practice.
### Link:
- https://doi.org/10.1287/mnsc.2018.3057

## 26. Comment on “Naiveté, Projection Bias, and Habit Formation in Gym Attendance”
### Author(s):
- Oliver März
### Published:
- 29 Jun 2018
### Abstract:
I show that a central result in Acland and Levy [Acland D, Levy MR (2015) Naiveté, projection bias, and habit formation in gym attendance. Management Sci. 61(1):146–160] is based on erroneously reported statistical estimates. In an experimental study, the authors provide financial incentives for regular attendance at a gym and report that these incentives induce a habit formation effect, resulting in sustained increased gym attendance after incentives are removed. This habit formation effect is not predicted by participants ex ante. The correct statistical estimates, however, do not confirm a habit formation effect. Participants’ ex ante expectations are thus correct in that they do not predict a habit formation effect, as there is none.
### Link:
- https://doi.org/10.1287/mnsc.2017.3022

